[{"path":[]},{"path":"https://queelius.github.io/compositional.mle/AGENTS.html","id":"project-structure--module-organization","dir":"","previous_headings":"","what":"Project Structure & Module Organization","title":"Repository Guidelines","text":"Package source lives R/ (solvers, composition operators, tracing, configuration). Keep new APIs exported via roxygen comments (@export) rely devtools::document() refresh NAMESPACE man/. Tests tests/testthat/; prefer test-<topic>.R files mirror module names (e.g., test-solvers.R, test-transformers.R). Documentation sources: README.Rmd (rendered README.md), vignettes vignettes/, pkgdown site output docs/ driven _pkgdown.yml. Additional references: DESIGN.md architecture context TESTING_SUMMARY.md historical coverage notes.","code":""},{"path":"https://queelius.github.io/compositional.mle/AGENTS.html","id":"build-test-and-development-commands","dir":"","previous_headings":"","what":"Build, Test, and Development Commands","title":"Repository Guidelines","text":"Load package interactive dev: R -q -e \"devtools::load_all()\". Run unit + integration tests: R -q -e \"devtools::test()\" (uses tests/testthat). Full check PRs: Regenerate docs API changes: R -q -e \"devtools::document()\". Rebuild site docs change: R -q -e \"pkgdown::build_site()\".","code":"R CMD build . R CMD check --as-cran compositional.mle_*.tar.gz"},{"path":"https://queelius.github.io/compositional.mle/AGENTS.html","id":"coding-style--naming-conventions","dir":"","previous_headings":"","what":"Coding Style & Naming Conventions","title":"Repository Guidelines","text":"Use base R style 2-space indents, tabs. Keep line length reasonable (~100 chars) prefer explicit argument names. Functions variables use snake_case; operators stay descriptive (%>>%, %|%, with_restarts()). Validate inputs early stopifnot()/stop(), keep solver outputs consistent (theta.hat, loglike, trace). Write roxygen comments exported functions, including examples set seeds reproducibility.","code":""},{"path":"https://queelius.github.io/compositional.mle/AGENTS.html","id":"testing-guidelines","dir":"","previous_headings":"","what":"Testing Guidelines","title":"Repository Guidelines","text":"Framework: testthat (edition 3). Name tests behavior test, grouping module. Use deterministic seeds small synthetic data avoid flaky convergence. Quick targeted run: R -q -e \"testthat::test_file('tests/testthat/test-solvers.R')\". adding solvers, include unit coverage constraints, tracing, failure modes; add integration paths test-integration.R appropriate.","code":""},{"path":"https://queelius.github.io/compositional.mle/AGENTS.html","id":"commit--pull-request-guidelines","dir":"","previous_headings":"","what":"Commit & Pull Request Guidelines","title":"Repository Guidelines","text":"Commit messages follow short, imperative summaries (e.g., Add Remotes field algebraic.mle dependency). Squash fixup noise locally. PRs describe change, note new commands tuning flags, list tests executed. Link related issues include output snippets convergence tuning changes behavior. Avoid committing generated artifacts unless intentional (docs/ pkgdown output versioned); never edit README.md directly—update README.Rmd.","code":""},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":null,"dir":"","previous_headings":"","what":"CLAUDE.md","title":"CLAUDE.md","text":"file provides guidance Claude Code (claude.ai/code) working code repository.","code":""},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"package-overview","dir":"","previous_headings":"","what":"Package Overview","title":"CLAUDE.md","text":"compositional.mle R package composable maximum likelihood estimation. Solvers first-class functions combine via operators: sequential chaining (%>>%), parallel racing (%|%), random restarts (with_restarts). design follows SICP principles combining solvers yields solver (closure property). Key dependency: algebraic.mle provides base mle class results.","code":""},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"development-commands","dir":"","previous_headings":"","what":"Development Commands","title":"CLAUDE.md","text":"","code":"# Load for development devtools::load_all()  # Run all tests devtools::test()  # Run specific test file testthat::test_file(\"tests/testthat/test-solvers.R\")  # Generate documentation (roxygen2) devtools::document()  # Full package check devtools::check()  # Test coverage analysis covr::package_coverage()  # Build pkgdown site pkgdown::build_site()"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"core-design-pattern","dir":"","previous_headings":"Architecture","what":"Core Design Pattern","title":"CLAUDE.md","text":"Solvers factory functions return solver functions uniform signature: enables composition:","code":"(problem, theta0, trace) -> mle_result # Coarse-to-fine: grid -> gradient -> Newton strategy <- grid_search(n = 5) %>>% gradient_ascent() %>>% newton_raphson()  # Race different methods, pick best strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()  # Multiple random restarts strategy <- gradient_ascent() %>% with_restarts(n = 20, sampler = uniform_sampler(lower, upper))"},{"path":[]},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"result-objects","dir":"","previous_headings":"Architecture","what":"Result Objects","title":"CLAUDE.md","text":"solvers return mle_numerical objects (extending algebraic.mle::mle) : - $theta.hat - MLE estimate - $loglike - log-likelihood MLE - $converged - convergence flag - $iterations - iteration count - $solver - solver name - $trace_data - optimization trace (tracing enabled)","code":""},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"typical-workflow","dir":"","previous_headings":"","what":"Typical Workflow","title":"CLAUDE.md","text":"","code":"# 1. Define the problem problem <- mle_problem(   loglike = function(theta) sum(dnorm(data, theta[1], theta[2], log = TRUE)),   score = function(theta) {...},  # Optional, computed numerically if NULL   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-8))   ) )  # 2. Create solver strategy solver <- gradient_ascent() %>>% newton_raphson()  # 3. Solve result <- solver(problem, theta0 = c(0, 1))"},{"path":"https://queelius.github.io/compositional.mle/CLAUDE.html","id":"testing-notes","dir":"","previous_headings":"","what":"Testing Notes","title":"CLAUDE.md","text":"Tests tests/testthat/ test files major component Standard normal MLE used canonical test case Solvers tested convergence known true values tolerance Tests depend algebraic.mle installed","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"philosophy","dir":"","previous_headings":"","what":"Philosophy","title":"compositional.mle Design Document","text":"Following SICP principles: 1. Primitive expressions - Basic solvers (gradient ascent, Newton-Raphson, simulated annealing, etc.) 2. Means combination - Composition operators (%>>%, %|%, with_restarts) 3. Means abstraction - Solver factories, problem specification Key property: Closure - combining solvers yields solver.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"id_1-mle_problem","dir":"","previous_headings":"Core Abstractions","what":"1. mle_problem","title":"compositional.mle Design Document","text":"Encapsulates statistical estimation problem, separate optimization strategy. Key features: - Lazy numerical differentiation analytic forms provided - Immutable - create new problems via update(problem, ...) - Validates inputs construction","code":"problem <- mle_problem(   loglike,   score = NULL,           # Auto-computed via numDeriv if NULL   fisher = NULL,          # Auto-computed via numDeriv if NULL   constraint = NULL,      # mle_constraint object   theta_names = NULL,     # Parameter names for nice output   n_obs = NULL            # For AIC/BIC )"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"id_2-solver-functions","dir":"","previous_headings":"Core Abstractions","what":"2. Solver Functions","title":"compositional.mle Design Document","text":"solver function: (problem, theta0, trace) -> mle_result Solver factories return solver functions: means: - gradient_ascent() returns solver - gradient_ascent(max_iter = 200) returns configured solver - solvers signature: (problem, theta0, trace) -> result","code":"# Factory pattern gradient_ascent <- function(   learning_rate = 1.0,   line_search = TRUE,   max_iter = 100,   tol = 1e-8 ) {   # Returns a solver function   function(problem, theta0, trace = mle_trace()) {     # ... optimization logic ...     # Returns mle_result   } }"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"id_3-composition-operators","dir":"","previous_headings":"Core Abstractions","what":"3. Composition Operators","title":"compositional.mle Design Document","text":"Sequential (%>>%): Chain solvers, passing result next starting point Parallel/Race (%|%): Run , select best log-likelihood Restarts: Multiple starting points Conditional:","code":"grid_search(lower, upper, n = 10) %>>% gradient_ascent() %>>% newton_raphson() gradient_ascent() %|% nelder_mead() %|% bfgs() with_restarts(gradient_ascent(), n = 20, sampler = uniform_sampler(lower, upper)) unless_converged(gradient_ascent(), newton_raphson())"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"id_4-tracing-system","dir":"","previous_headings":"Core Abstractions","what":"4. Tracing System","title":"compositional.mle Design Document","text":"","code":"trace <- mle_trace(   values = TRUE,      # Track log-likelihood   path = TRUE,        # Track parameter values   gradients = TRUE,   # Track gradient norms   timing = TRUE       # Track wall-clock time )  result <- solver(problem, theta0, trace = trace)  # Visualize plot(result)                    # Convergence diagnostics optimization_path(result)       # Data frame of path"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"id_5-results-mle_numerical","dir":"","previous_headings":"Core Abstractions","what":"5. Results: mle_numerical","title":"compositional.mle Design Document","text":"Extends algebraic.mle::mle_numerical : - $converged - logical - $iterations - count - $trace_data - optimization trace (requested) - $chain - composed solvers, list intermediate results - $solver - solver produced result - $strategy - composition type (“sequential”, “race”, “restarts”)","code":""},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"file-organization","dir":"","previous_headings":"","what":"File Organization","title":"compositional.mle Design Document","text":"","code":"R/   numerical.mle.R       # Package documentation, imports   problem.R             # mle_problem(), update.mle_problem()   config.R              # mle_constraint(), mle_config*()   compose.R             # %>>%, %|%, with_restarts(), unless_converged(), samplers   trace.R               # mle_trace(), recorder, finalize   plot.R                # plot.mle_numerical(), optimization_path()   transformers.R        # with_penalty(), with_subsampling(), penalty_*()   generic_functions.R   # is_converged(), num_iterations(), is_mle_*()    solver_gradient.R     # gradient_ascent()   solver_newton.R       # newton_raphson(), fisher_scoring()   solver_optim.R        # bfgs(), lbfgsb(), nelder_mead()   solver_grid.R         # grid_search(), random_search()   solver_annealing.R    # sim_anneal()   solver_coordinate.R   # coordinate_ascent()"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"example-usage","dir":"","previous_headings":"","what":"Example Usage","title":"compositional.mle Design Document","text":"","code":"library(compositional.mle)  # Generate data set.seed(42) data <- rnorm(100, mean = 5, sd = 2)  # Define the problem problem <- mle_problem(   loglike = function(theta) {     sum(dnorm(data, theta[1], theta[2], log = TRUE))   },   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-8))   ),   theta_names = c(\"mu\", \"sigma\"),   n_obs = length(data) )  # Simple solve result <- gradient_ascent()(problem, c(0, 1))  # Composed strategy: coarse to fine strategy <-   grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 5) %>>%   gradient_ascent(max_iter = 50) %>>%   newton_raphson(max_iter = 20)  result <- strategy(problem, c(0, 1))  # Robust global search strategy <- with_restarts(   gradient_ascent(),   n = 10,   sampler = uniform_sampler(c(-10, 0.1), c(10, 5)) )  result <- strategy(problem, c(0, 1))  # Race different methods strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead() result <- strategy(problem, c(0, 1))  # With tracing and visualization result <- gradient_ascent()(   problem,   c(0, 1),   trace = mle_trace(path = TRUE, values = TRUE, gradients = TRUE) ) plot(result) optimization_path(result)"},{"path":"https://queelius.github.io/compositional.mle/DESIGN.html","id":"future-directions","dir":"","previous_headings":"","what":"Future Directions","title":"compositional.mle Design Document","text":"Parallel execution: Make %|% actually run parallel via future package Automatic differentiation: Support autodiff packages score/fisher Derivative caching: Memoize numerical derivatives avoid redundant computation Verbose output: Progress bars via cli package long-running optimizations Early stopping: Callback-based termination composed solvers","code":""},{"path":"https://queelius.github.io/compositional.mle/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2022 algebraic.mle authors Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":null,"dir":"","previous_headings":"","what":"API Refactoring Summary for numerical.mle","title":"API Refactoring Summary for numerical.mle","text":"Date: 2025-11-24 Status: Complete (Phase 1 - New API Implementation)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"API Refactoring Summary for numerical.mle","text":"numerical.mle package undergone comprehensive API refactoring create cohesive, consistent, expressive interface. refactoring follows recommendations elegant-api-architect agent implements layered architecture clear separation concerns.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_1-type-safe-configuration-system","dir":"","previous_headings":"Key Changes","what":"1. Type-Safe Configuration System","title":"API Refactoring Summary for numerical.mle","text":"(raw lists): (typed configuration objects):","code":"result <- mle_gradient_ascent(   theta0 = c(0, 1),   score = score_fn,   options = list(     loglike = loglike_fn,     line_search = TRUE,     eta = 1.0,     max_iter = 100   ) ) result <- mle_gradient_ascent(   loglike = loglike_fn,   score = score_fn,   theta0 = c(0, 1),   config = mle_config_linesearch(     max_step = 1.0,     max_iter = 100   ) )"},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_2-unified-solver-interface","dir":"","previous_headings":"Key Changes","what":"2. Unified Solver Interface","title":"API Refactoring Summary for numerical.mle","text":"solvers now follow consistent pattern: Gradient Ascent: mle_gradient_ascent(loglike, score, theta0, config, constraint) Newton-Raphson: mle_newton_raphson(loglike, score, fisher, theta0, config, constraint, inverted) Grid Search: mle_grid_search(loglike, lower, upper, grid_size, refine_solver, ...) Random Restart: mle_random_restart(loglike, solver, theta0_sampler, n_trials, ...)","code":"solver(loglike, ..., theta0, config, constraint)"},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_3-composable-function-transformers","dir":"","previous_headings":"Key Changes","what":"3. Composable Function Transformers","title":"API Refactoring Summary for numerical.mle","text":"(unclear composition): (elegant pipeline):","code":"stoch_ll <- stochastic_loglike(log_density, data, m = 50) loglike_transformed <- loglike %>%   with_subsampling(data, subsample_size = 50) %>%   with_penalty(penalty_l2(), lambda = 0.1)"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"core-configuration-rconfigr","dir":"","previous_headings":"New Files Created","what":"Core Configuration (R/config.R)","title":"API Refactoring Summary for numerical.mle","text":"mle_config() - Base configuration solvers mle_config_gradient() - Configuration gradient-based methods mle_config_linesearch() - Configuration backtracking line search mle_constraint() - Domain constraint specification Helper functions: is_mle_config(), is_mle_constraint()","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"internal-optimizer-rinternal_optimizer","dir":"","previous_headings":"New Files Created","what":"Internal Optimizer (R/internal_optimize.R)","title":"API Refactoring Summary for numerical.mle","text":".mle_optimize_direction() - Unified internal optimizer used gradient-based solvers .make_convergence_checker() - Creates convergence check functions .print_iteration() - Debug output formatting .backtracking_step() - Improved line search implementation .generate_grid() - Grid generation grid search","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"function-transformers-rtransformersr","dir":"","previous_headings":"New Files Created","what":"Function Transformers (R/transformers.R)","title":"API Refactoring Summary for numerical.mle","text":"with_subsampling() - Stochastic gradient descent via subsampling with_penalty() - Add penalty terms (regularization) penalty_l1() - L1/LASSO penalty penalty_l2() - L2/Ridge penalty penalty_elastic_net() - Combined L1+L2 penalty compose() - Function composition utility","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"convenience-wrappers-rconveniencer","dir":"","previous_headings":"New Files Created","what":"Convenience Wrappers (R/convenience.R)","title":"API Refactoring Summary for numerical.mle","text":"mle_grad() - Quick gradient ascent defaults mle_nr() - Quick Newton-Raphson defaults with_constraint() - Simplified constrained optimization","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"rmle_gradient_ascentr","dir":"","previous_headings":"Files Refactored","what":"R/mle_gradient_ascent.R","title":"API Refactoring Summary for numerical.mle","text":"New signature: (loglike, score, theta0, config, constraint) Old signature: (theta0, score, options) Uses internal .mle_optimize_direction() Automatic Fisher information computation via numerical Hessian Comprehensive documentation examples","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"rmle_newton_raphsonr","dir":"","previous_headings":"Files Refactored","what":"R/mle_newton_raphson.R","title":"API Refactoring Summary for numerical.mle","text":"New signature: (loglike, score, fisher, theta0, config, constraint, inverted) Old signature: (score, fim, theta0, inverted, options) Consistent parameter ordering across solvers Clearer handling FIM vs. covariance matrix","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"rmle_random_restartr","dir":"","previous_headings":"Files Refactored","what":"R/mle_random_restart.R","title":"API Refactoring Summary for numerical.mle","text":"New signature: (loglike, solver, theta0_sampler, n_trials, ...) Old signature: (rtheta0, mle_solver, ntrials, ...) Better error handling reporting Tracks successful vs. failed trials Fixed bug loglik_val() function call","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"rmle_grid_searchr","dir":"","previous_headings":"Files Refactored","what":"R/mle_grid_search.R","title":"API Refactoring Summary for numerical.mle","text":"Complete rewrite (original incomplete/buggy) New signature: (loglike, lower, upper, grid_size, refine_solver, ...) Supports pure grid search grid+local refinement Variable resolution per dimension Robust error handling","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"description","dir":"","previous_headings":"Files Refactored","what":"DESCRIPTION","title":"API Refactoring Summary for numerical.mle","text":"Critical fix: Added algebraic.mle Imports (missing!)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"namespace","dir":"","previous_headings":"Files Refactored","what":"NAMESPACE","title":"API Refactoring Summary for numerical.mle","text":"Organized exports category Added new configuration, transformer, convenience functions Marked legacy functions","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"test-coverage","dir":"","previous_headings":"","what":"Test Coverage","title":"API Refactoring Summary for numerical.mle","text":"Created tests/testthat/test-new-api.R comprehensive tests: - ✅ Configuration class creation validation (7 tests) - ✅ Constraint objects (4 tests) - ✅ Refactored gradient ascent (3 tests) - ✅ Refactored Newton-Raphson (3 tests) - ✅ Function transformers (4 tests) - ✅ Convenience wrappers (2 tests) - ⚠️ Random restart (1 test - warnings due missing algebraic.mle) - ⚠️ Grid search (1 test - skipped due missing algebraic.mle) Results: 23 PASSED | 4 SKIPPED | 1 FAILED | 5 WARNINGS skips warnings expected since algebraic.mle installed test environment.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_1-consistent-interfaces","dir":"","previous_headings":"Design Principles","what":"1. Consistent Interfaces","title":"API Refactoring Summary for numerical.mle","text":"solvers follow calling convention loglike first, theta0 config.","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_2-type-safety","dir":"","previous_headings":"Design Principles","what":"2. Type Safety","title":"API Refactoring Summary for numerical.mle","text":"Configuration objects provide validation clear documentation available options.","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_3-composability","dir":"","previous_headings":"Design Principles","what":"3. Composability","title":"API Refactoring Summary for numerical.mle","text":"Function transformers can chained using pipes explicit composition.","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_4-single-responsibility","dir":"","previous_headings":"Design Principles","what":"4. Single Responsibility","title":"API Refactoring Summary for numerical.mle","text":"file clear purpose: - config.R - Configuration constraints - internal_optimize.R - Core optimization algorithms - transformers.R - Function adapters - convenience.R - User-friendly wrappers - Individual mle_*.R files - Specific solvers","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"id_5-clear-abstraction","dir":"","previous_headings":"Design Principles","what":"5. Clear Abstraction","title":"API Refactoring Summary for numerical.mle","text":"Users never see implementation details like “direction functions” - work intuitive concepts like score Fisher information.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"phase-1--complete","dir":"","previous_headings":"Migration Path","what":"Phase 1: ✅ Complete","title":"API Refactoring Summary for numerical.mle","text":"New API implemented alongside existing code new functions exported Legacy functions remain available Comprehensive tests new API","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"phase-2-future-optional-breaking-changes","dir":"","previous_headings":"Migration Path","what":"Phase 2: Future (Optional Breaking Changes)","title":"API Refactoring Summary for numerical.mle","text":"Add deprecation warnings old interfaces Update documentation vignettes Create migration guide Eventually remove old implementations (major version bump)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"benefits","dir":"","previous_headings":"","what":"Benefits","title":"API Refactoring Summary for numerical.mle","text":"Easier Learn: Consistent interfaces reduce cognitive load Easier Use: Type-safe configs catch errors early Powerful: Composable transformers enable complex workflows Better Tested: New API comprehensive test coverage Maintainable: Clear separation concerns, DRY principle Flexible: Easy add new solvers following established patterns","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"gradient-ascent","dir":"","previous_headings":"Example Usage Comparison","what":"Gradient Ascent","title":"API Refactoring Summary for numerical.mle","text":"Old API: New API (full control): New API (convenience):","code":"result <- mle_gradient_ascent(   theta0 = c(0, 1),   score = score_fn,   options = list(     loglike = loglike_fn,     line_search = TRUE,     eta = 1.0,     max_iter = 100,     rel_tol = 1e-5   ) ) result <- mle_gradient_ascent(   loglike = loglike_fn,   score = score_fn,   theta0 = c(0, 1),   config = mle_config_linesearch(     max_step = 1.0,     max_iter = 100,     rel_tol = 1e-5   ) ) result <- mle_grad(loglike_fn, score_fn, theta0 = c(0, 1))"},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"constrained-optimization","dir":"","previous_headings":"Example Usage Comparison","what":"Constrained Optimization","title":"API Refactoring Summary for numerical.mle","text":"Old API: New API:","code":"result <- mle_newton_raphson(   score = score_fn,   fim = fisher_fn,   theta0 = c(0, 1),   options = list(     loglike = loglike_fn,     sup = function(theta) all(theta > 0),     proj = function(theta) pmax(theta, 1e-8)   ) ) constraint <- mle_constraint(   support = function(theta) all(theta > 0),   project = function(theta) pmax(theta, 1e-8) )  result <- mle_newton_raphson(   loglike = loglike_fn,   score = score_fn,   fisher = fisher_fn,   theta0 = c(0, 1),   constraint = constraint )"},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"regularized-stochastic-optimization","dir":"","previous_headings":"Example Usage Comparison","what":"Regularized Stochastic Optimization","title":"API Refactoring Summary for numerical.mle","text":"Old API: (easily achievable) New API:","code":"# Compose transformations loglike_final <- loglike %>%   with_subsampling(data, subsample_size = 100) %>%   with_penalty(penalty_l2(), lambda = 0.1)  # Optimize result <- mle_grad(loglike_final, score_fn, theta0 = c(0, 1))"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"new-files-6","dir":"","previous_headings":"Files Modified Summary","what":"New Files (6)","title":"API Refactoring Summary for numerical.mle","text":"R/config.R (253 lines) R/internal_optimize.R (240 lines) R/transformers.R (259 lines) R/convenience.R (148 lines) tests/testthat/test-new-api.R (193 lines) REFACTORING_SUMMARY.md (file)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"modified-files-6","dir":"","previous_headings":"Files Modified Summary","what":"Modified Files (6)","title":"API Refactoring Summary for numerical.mle","text":"R/mle_gradient_ascent.R - Complete rewrite (134 lines) R/mle_newton_raphson.R - Complete rewrite (154 lines) R/mle_random_restart.R - Complete rewrite (113 lines) R/mle_grid_search.R - Complete rewrite (139 lines) DESCRIPTION - Added algebraic.mle dependency NAMESPACE - Organized added new exports","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"total-lines-of-code","dir":"","previous_headings":"Files Modified Summary","what":"Total Lines of Code","title":"API Refactoring Summary for numerical.mle","text":"New code: ~1,100 lines Refactored code: ~540 lines Documentation: ~500 lines (roxygen comments)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"next-steps","dir":"","previous_headings":"","what":"Next Steps","title":"API Refactoring Summary for numerical.mle","text":"✅ Core refactoring complete ⏳ Update CLAUDE.md new API information ⏳ Create migration guide vignette ⏳ Update README new examples ⏳ Run R CMD check dependencies available ⏳ Update existing tests use new API (optional) ⏳ Add deprecation warnings old API (Phase 2)","code":""},{"path":"https://queelius.github.io/compositional.mle/REFACTORING_SUMMARY.html","id":"conclusion","dir":"","previous_headings":"","what":"Conclusion","title":"API Refactoring Summary for numerical.mle","text":"refactoring successfully transforms numerical.mle inconsistent, hard--use API elegant, composable, type-safe interface follows R best practices. new design makes package easier learn, use, extend, maintain preserving backward compatibility legacy code.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Testing Summary for numerical.mle Package","text":"Comprehensive test suite created numerical.mle R package, provides numerical maximum likelihood estimation solvers.","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"test-infrastructure-setup","dir":"","previous_headings":"","what":"Test Infrastructure Setup","title":"Testing Summary for numerical.mle Package","text":"Created tests/testthat.R entry point Created tests/testthat/ directory 6 test files Created helper-mock-mle.R mock algebraic.mle dependency testing Total: 53 test cases across 1,524 lines test code","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_1-generic_functionsr-line-78","dir":"","previous_headings":"Bugs Fixed During Testing","what":"1. generic_functions.R (Line 78)","title":"Testing Summary for numerical.mle Package","text":"Bug: replace = resample (undefined variable) Fix: Changed replace = replace Impact: Fixed stochastic_loglike function","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_2-mle_newton_raphsonr-line-41","dir":"","previous_headings":"Bugs Fixed During Testing","what":"2. mle_newton_raphson.R (Line 41)","title":"Testing Summary for numerical.mle Package","text":"Bug: sol$theta (field doesn’t exist) Fix: Changed sol$theta.hat Impact: Fixed accessing MLE estimate Newton-Raphson solver","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_3-mle_gradient_ascentr-line-19","dir":"","previous_headings":"Bugs Fixed During Testing","what":"3. mle_gradient_ascent.R (Line 19)","title":"Testing Summary for numerical.mle Package","text":"Bug: (options$loglike) (doesn’t check NULL) Fix: Changed (!.null(options$loglike)) Impact: Prevents error loglike NULL","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_4-mle_local_searchr-line-163","dir":"","previous_headings":"Bugs Fixed During Testing","what":"4. mle_local_search.R (Line 163)","title":"Testing Summary for numerical.mle Package","text":"Bug: loglike = max (incorrect value assignment) Fix: Changed evaluate log-likelihood solution: options$loglike(theta0) Impact: Fixed log-likelihood value result object","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_5-generic_functionsr-missing-generic-functions","dir":"","previous_headings":"Bugs Fixed During Testing","what":"5. generic_functions.R (Missing generic functions)","title":"Testing Summary for numerical.mle Package","text":"Bug: S3 methods is_converged num_iterations defined without generics Fix: Added generic function declarations UseMethod() Impact: Functions now properly dispatched S3 methods","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_6-mle_newton_raphsonr-line-35","dir":"","previous_headings":"Bugs Fixed During Testing","what":"6. mle_newton_raphson.R (Line 35)","title":"Testing Summary for numerical.mle Package","text":"Bug: Direction function returns matrix instead vector Fix: Wrapped .vector(): dir <- function(x) .vector(covar(x) %*% score(x)) Impact: Prevents dimension mismatches optimization","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_1-test-generic_functionsr-128-lines-9-tests","dir":"","previous_headings":"Test Files Created","what":"1. test-generic_functions.R (128 lines, 9 tests)","title":"Testing Summary for numerical.mle Package","text":"mle_numerical constructor validation is_mle_numerical() functionality is_converged() num_iterations() methods stochastic_loglike() function sampling (/without replacement) Input validation tests","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_2-test-utilsr-233-lines-10-tests","dir":"","previous_headings":"Test Files Created","what":"2. test-utils.R (233 lines, 10 tests)","title":"Testing Summary for numerical.mle Package","text":"clip_step(): step size limiting edge cases backtracking_line_search(): line search support constraints projection grad_descent(): gradient descent 1D multidimensional problems Support constraint enforcement Max iteration handling","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_3-test-mle_local_searchr-257-lines-11-tests","dir":"","previous_headings":"Test Files Created","what":"3. test-mle_local_search.R (257 lines, 11 tests)","title":"Testing Summary for numerical.mle Package","text":"Local search gradient direction Line search vs. fixed step size modes Initial guess validation Projection functions constrained optimization Path tracing (trace=TRUE) Multidimensional parameters Absolute vs. relative tolerance Custom norm functions","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_4-test-mle_gradient_ascentr-241-lines-8-tests","dir":"","previous_headings":"Test Files Created","what":"4. test-mle_gradient_ascent.R (241 lines, 8 tests)","title":"Testing Summary for numerical.mle Package","text":"Normal distribution MLE estimation Multidimensional parameter estimation Poisson distribution MLE Constrained optimization projection Score function validation Fisher information matrix computation Convergence iteration counts","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_5-test-mle_newton_raphsonr-314-lines-10-tests","dir":"","previous_headings":"Test Files Created","what":"5. test-mle_newton_raphson.R (314 lines, 10 tests)","title":"Testing Summary for numerical.mle Package","text":"Newton-Raphson normal distribution Inverted FIM (covariance) mode Multidimensional problems Poisson distribution Constrained optimization Input validation (score, fim, inverted parameters) Convergence speed comparison gradient ascent Score near zero MLE verification","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"id_6-test-integrationr-351-lines-10-tests","dir":"","previous_headings":"Test Files Created","what":"6. test-integration.R (351 lines, 10 tests)","title":"Testing Summary for numerical.mle Package","text":"Complete workflows multiple solvers Normal distribution MLE gradient ascent Newton-Raphson Poisson distribution end--end Bivariate normal distribution Constrained optimization projection Stochastic gradient ascent subsampling Multiple starting points robustness Path tracing validation Absolute tolerance mode","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"current-status","dir":"","previous_headings":"Test Results","what":"Current Status","title":"Testing Summary for numerical.mle Package","text":"Total test cases: 53 Unit tests passing: ~43 (component tests) Integration tests: 10 tests convergence issues Skipped: 1 (empty test placeholder) Warnings: 151 (mostly deprecation warnings R vector-array arithmetic)","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"known-issues","dir":"","previous_headings":"Test Results","what":"Known Issues","title":"Testing Summary for numerical.mle Package","text":"expected behavior - optimization algorithms require tuning Unit tests confirm individual components work correctly Failures indicate need better default parameters iterations affect correctness Can addressed explicitly using c() .vector()","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"testing-best-practices-demonstrated","dir":"","previous_headings":"","what":"Testing Best Practices Demonstrated","title":"Testing Summary for numerical.mle Package","text":"Comprehensive unit testing: component tested isolation Integration testing: Complete workflows tested end--end Edge case coverage: Boundary conditions, constraints, invalid inputs Positive negative tests: success failure modes tested Statistical correctness: MLE estimates verified known distributions Multiple distributions: Normal, Poisson, multivariate normal Constrained optimization: Support constraints projection functions Algorithm comparison: Gradient ascent vs. Newton-Raphson convergence Robustness testing: Multiple starting points, different tolerances","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"high-coverage-80","dir":"","previous_headings":"Test Coverage Analysis (Estimated)","what":"High Coverage (>80%)","title":"Testing Summary for numerical.mle Package","text":"R/generic_functions.R: Constructor, S3 methods, stochastic_loglike R/utils.R: clip_step, backtracking_line_search, grad_descent R/mle_local_search.R: Core local search algorithm R/mle_gradient_ascent.R: Gradient ascent solver R/mle_newton_raphson.R: Newton-Raphson solver","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"moderate-coverage-40-80","dir":"","previous_headings":"Test Coverage Analysis (Estimated)","what":"Moderate Coverage (40-80%)","title":"Testing Summary for numerical.mle Package","text":"Integration multiple solvers Edge cases convergence","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"low-coverage-40","dir":"","previous_headings":"Test Coverage Analysis (Estimated)","what":"Low Coverage (<40%)","title":"Testing Summary for numerical.mle Package","text":"R/mle_grid_search.R: tested (incomplete implementation) R/mle_random_search.R: tested R/mle_random_restart.R: tested R/mle_sim_anneal.R: tested R/mle_optim.R: tested","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"recommendations-for-future-testing","dir":"","previous_headings":"","what":"Recommendations for Future Testing","title":"Testing Summary for numerical.mle Package","text":"Grid search Random search Random restart Simulated annealing optim() wrapper Increase max_iter complex problems Add better starting point selection Test distributions (exponential, gamma, etc.) Benchmark convergence speed Memory usage tests Scalability data size Save expected results known problems Ensure updates don’t break existing functionality Use covr package generate detailed coverage reports Aim 90%+ coverage core functionality","code":""},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"how-to-run-tests","dir":"","previous_headings":"","what":"How to Run Tests","title":"Testing Summary for numerical.mle Package","text":"","code":"# Install dependencies install.packages(c(\"testthat\", \"MASS\", \"numDeriv\"))  # Load and source package source_files <- list.files(\"R\", pattern = \"\\\\.R$\", full.names = TRUE) lapply(source_files, source)  # Run all tests testthat::test_dir(\"tests/testthat\")  # Run specific test file testthat::test_file(\"tests/testthat/test-generic_functions.R\")  # With coverage (requires covr package) covr::package_coverage()"},{"path":"https://queelius.github.io/compositional.mle/TESTING_SUMMARY.html","id":"summary","dir":"","previous_headings":"","what":"Summary","title":"Testing Summary for numerical.mle Package","text":"numerical.mle package now solid foundation 53 test cases covering core MLE solvers. major bugs identified fixed. test suite demonstrates : Unit tests work: Individual components function correctly Integration needs tuning: workflows need parameter optimization Code quality improved: 6 bugs fixed, including critical logic errors Testing infrastructure complete: Ready continuous testing development package now much better shape alpha release development.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"why-automatic-differentiation","dir":"Articles","previous_headings":"","what":"Why Automatic Differentiation?","title":"Automatic Differentiation with dualr","text":"Maximum likelihood estimation requires derivatives log-likelihood: score (gradient) first-order methods Hessian (observed information) second-order methods like Newton-Raphson. three ways supply : Following SICP principle specification separate mechanism, log-likelihood function specification statistical model. Derivatives mechanical consequences specification—derived automatically rather hand-coded. dualr package provides forward-mode automatic differentiation R via dual numbers, giving exact derivatives minimal code changes.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"setup","dir":"Articles","previous_headings":"","what":"Setup","title":"Automatic Differentiation with dualr","text":"","code":"library(compositional.mle) library(dualr) #>  #> Attaching package: 'dualr' #> The following object is masked from 'package:stats': #>  #>     deriv"},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"the-three-approaches","dir":"Articles","previous_headings":"","what":"The Three Approaches","title":"Automatic Differentiation with dualr","text":"Consider Poisson model. log-likelihood λ\\lambda given data x1,…,xnx_1, \\ldots, x_n : ℓ(λ)=(∑=1nxi)logλ−nλ\\ell(\\lambda) = \\left(\\sum_{=1}^n x_i\\right) \\log \\lambda - n\\lambda define log-likelihood : Now create three problem specifications using different derivative strategies: Notice AD analytic problems report “analytic” score Fisher information. solver’s perspective, identical—solver doesn’t know (care) whether derivatives hand-coded computed AD. power mle_problem abstraction: derivatives pluggable.","code":"set.seed(42) x <- rpois(100, lambda = 3.5) ll_poisson <- function(theta) {   lambda <- theta[1]   n <- length(x)   # Accumulate sum in a loop for dualr compatibility   sx <- 0   for (i in seq_along(x)) sx <- sx + x[i]   sx * log(lambda) - n * lambda } # 1. No derivatives — numDeriv fallback (the default) p_numerical <- mle_problem(loglike = ll_poisson)  # 2. Hand-coded analytical derivatives p_analytic <- mle_problem(   loglike = ll_poisson,   score = function(theta) sum(x) / theta[1] - length(x),   fisher = function(theta) matrix(sum(x) / theta[1]^2, 1, 1) )  # 3. Automatic differentiation via dualr p_ad <- mle_problem(   loglike = ll_poisson,   score = function(theta) dualr::score(ll_poisson, theta),   fisher = function(theta) dualr::observed_information(ll_poisson, theta) ) p_numerical #> MLE Problem #>   Parameters: unnamed  #>   Score: numerical  #>   Fisher: numerical  #>   Constraints: yes p_ad #> MLE Problem #>   Parameters: unnamed  #>   Score: analytic  #>   Fisher: analytic  #>   Constraints: yes"},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"comparison","dir":"Articles","previous_headings":"","what":"Comparison","title":"Automatic Differentiation with dualr","text":"Let’s run solver three: three converge estimate. key differences : numDeriv introduces small O(h2)O(h^2) errors gradient, may cause minor differences iteration paths (usually negligible) Analytic dualr AD provide exact gradients, leading identical optimization paths dualr AD requires manual derivative derivation","code":"solver <- bfgs(max_iter = 200)  r_num <- solver(p_numerical, theta0 = 1) r_ana <- solver(p_analytic, theta0 = 1) r_ad  <- solver(p_ad, theta0 = 1)  results <- data.frame(   Method     = c(\"numDeriv\", \"Analytic\", \"dualr AD\"),   Estimate   = c(r_num$theta.hat, r_ana$theta.hat, r_ad$theta.hat),   LogLik     = c(r_num$loglike, r_ana$loglike, r_ad$loglike),   Converged  = c(r_num$converged, r_ana$converged, r_ad$converged),   Iterations = c(r_num$iterations, r_ana$iterations, r_ad$iterations) ) results #>     Method Estimate   LogLik Converged Iterations #> 1 numDeriv     3.64 106.2821      TRUE         21 #> 2 Analytic     3.64 106.2821      TRUE         23 #> 3 dualr AD     3.64 106.2821      TRUE         23 cat(\"True MLE (sample mean):\", mean(x), \"\\n\") #> True MLE (sample mean): 3.64"},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"multivariate-example-normal-distribution","dir":"Articles","previous_headings":"","what":"Multivariate Example: Normal Distribution","title":"Automatic Differentiation with dualr","text":"Normal(μ,σ)(\\mu, \\sigma) model, two parameters positivity constraint σ\\sigma. log-likelihood : ℓ(μ,σ)=−nlogσ−12σ2∑=1n(yi−μ)2\\ell(\\mu, \\sigma) = -n \\log \\sigma - \\frac{1}{2\\sigma^2}\\sum_{=1}^n (y_i - \\mu)^2 Note: use loop-based sum instead vectorized sum((y - mu)^2). dualr’s Hessian computation currently requires scalar accumulation mixing dual numbers data vectors. score function works either way, Hessian needs pattern. minor syntactic cost exact second derivatives. Hessian matrix dualr provides full curvature information:","code":"set.seed(123) y <- rnorm(200, mean = 5, sd = 2) # Log-likelihood with loop-based sum for dualr Hessian support ll_normal <- function(theta) {   mu <- theta[1]   sigma <- theta[2]   n <- length(y)   ss <- 0   for (i in seq_along(y)) {     ss <- ss + (y[i] - mu)^2   }   -n * log(sigma) - 0.5 * ss / sigma^2 } # AD-powered problem with box constraints via L-BFGS-B p_normal <- mle_problem(   loglike = ll_normal,   score = function(theta) dualr::score(ll_normal, theta),   fisher = function(theta) dualr::observed_information(ll_normal, theta) )  solver <- lbfgsb(lower = c(-Inf, 1e-4), upper = c(Inf, Inf)) result <- solver(p_normal, theta0 = c(0, 1)) cat(\"Estimated mu:   \", round(result$theta.hat[1], 4), \"\\n\") #> Estimated mu:    4.9829 cat(\"Estimated sigma:\", round(result$theta.hat[2], 4), \"\\n\") #> Estimated sigma: 1.8816 cat(\"Converged:      \", result$converged, \"\\n\") #> Converged:       TRUE  # Compare with true MLE cat(\"\\nTrue MLE mu:   \", round(mean(y), 4), \"\\n\") #>  #> True MLE mu:    4.9829 cat(\"True MLE sigma:\", round(sd(y) * sqrt((length(y)-1)/length(y)), 4), \"\\n\") #> True MLE sigma: 1.8816 H <- dualr::hessian(ll_normal, result$theta.hat) cat(\"Hessian at MLE:\\n\") #> Hessian at MLE: print(round(H, 2)) #>        [,1]    [,2] #> [1,] -56.49    0.00 #> [2,]   0.00 -112.98  cat(\"\\nObserved information at MLE:\\n\") #>  #> Observed information at MLE: I_obs <- dualr::observed_information(ll_normal, result$theta.hat) print(round(I_obs, 2)) #>       [,1]   [,2] #> [1,] 56.49   0.00 #> [2,]  0.00 112.98  cat(\"\\nApproximate standard errors (from observed information):\\n\") #>  #> Approximate standard errors (from observed information): se <- sqrt(diag(solve(I_obs))) cat(\"  SE(mu):   \", round(se[1], 4), \"\\n\") #>   SE(mu):    0.133 cat(\"  SE(sigma):\", round(se[2], 4), \"\\n\") #>   SE(sigma): 0.0941"},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"composition-with-ad","dir":"Articles","previous_headings":"","what":"Composition with AD","title":"Automatic Differentiation with dualr","text":"real power emerges combining AD solver composition. dualr-derived derivatives just functions, compose seamlessly:","code":"# Coarse grid search, then refine with L-BFGS-B strategy <- grid_search(   lower = c(0, 0.5), upper = c(10, 5), n = 5 ) %>>% lbfgsb(lower = c(-Inf, 1e-4), upper = c(Inf, Inf))  result_composed <- strategy(p_normal, theta0 = c(0, 1)) cat(\"Grid -> L-BFGS-B estimate:\",     round(result_composed$theta.hat, 4), \"\\n\") #> Grid -> L-BFGS-B estimate: 4.9829 1.8816 cat(\"Converged:\", result_composed$converged, \"\\n\") #> Converged: TRUE"},{"path":"https://queelius.github.io/compositional.mle/articles/automatic-differentiation.html","id":"when-to-use-what","dir":"Articles","previous_headings":"","what":"When to Use What","title":"Automatic Differentiation with dualr","text":"general recommendation start default (explicit derivatives) model development, switch dualr need accuracy performance production use. Hand-coding worthwhile simple models derivatives obvious.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Case Studies: MLE for Common Distributions","text":"vignette demonstrates using compositional.mle fit various probability distributions data. case study shows: Problem definition mle_problem() Composable solver strategies Comparison analytical solutions","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"case-study-1-exponential-distribution","dir":"Articles","previous_headings":"","what":"Case Study 1: Exponential Distribution","title":"Case Studies: MLE for Common Distributions","text":"exponential distribution one parameter: rate λ>0\\lambda > 0.","code":"# Generate data n <- 100 true_rate <- 2.5 x_exp <- rexp(n, rate = true_rate)  # Define the problem problem_exp <- mle_problem(   loglike = function(lambda) {     if (lambda <= 0) return(-Inf)     n * log(lambda) - lambda * sum(x_exp)   },   score = function(lambda) n / lambda - sum(x_exp),   constraint = mle_constraint(     support = function(lambda) lambda > 0,     project = function(lambda) max(lambda, 1e-8)   ) )  # Solve result_exp <- gradient_ascent(max_iter = 50)(problem_exp, theta0 = 1)  # Compare with analytical MLE: 1/mean(x) mle_analytical <- 1 / mean(x_exp)  cat(\"Numerical MLE:  \", round(result_exp$theta.hat, 4), \"\\n\") #> Numerical MLE:   2.2236 cat(\"Analytical MLE: \", round(mle_analytical, 4), \"\\n\") #> Analytical MLE:  2.2236 cat(\"True rate:      \", true_rate, \"\\n\") #> True rate:       2.5 lambda_grid <- seq(0.1, 5, length.out = 100) ll_values <- sapply(lambda_grid, problem_exp$loglike)  plot(lambda_grid, ll_values, type = \"l\", lwd = 2,      xlab = expression(lambda), ylab = \"Log-likelihood\",      main = \"Exponential Distribution Log-Likelihood\") abline(v = result_exp$theta.hat, col = \"red\", lwd = 2, lty = 2) abline(v = true_rate, col = \"blue\", lwd = 2, lty = 3) legend(\"topright\", c(\"MLE\", \"True\"), col = c(\"red\", \"blue\"), lty = c(2, 3), lwd = 2)"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"case-study-2-gamma-distribution","dir":"Articles","previous_headings":"","what":"Case Study 2: Gamma Distribution","title":"Case Studies: MLE for Common Distributions","text":"Two parameters: shape α>0\\alpha > 0 rate β>0\\beta > 0.","code":"# Generate data true_shape <- 3 true_rate <- 2 x_gamma <- rgamma(200, shape = true_shape, rate = true_rate)  # Define the problem problem_gamma <- mle_problem(   loglike = function(theta) {     alpha <- theta[1]; beta <- theta[2]     if (alpha <= 0 || beta <= 0) return(-Inf)     n <- length(x_gamma)     n * (alpha * log(beta) - lgamma(alpha)) +       (alpha - 1) * sum(log(x_gamma)) - beta * sum(x_gamma)   },   score = function(theta) {     alpha <- theta[1]; beta <- theta[2]     n <- length(x_gamma)     c(n * (log(beta) - digamma(alpha)) + sum(log(x_gamma)),       n * alpha / beta - sum(x_gamma))   },   constraint = mle_constraint(     support = function(theta) all(theta > 0),     project = function(theta) pmax(theta, 1e-6)   ),   theta_names = c(\"alpha\", \"beta\") )"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"composing-solvers-grid-search-gradient-ascent","dir":"Articles","previous_headings":"Case Study 2: Gamma Distribution","what":"Composing Solvers: Grid Search + Gradient Ascent","title":"Case Studies: MLE for Common Distributions","text":"","code":"# Coarse-to-fine strategy strategy <- grid_search(lower = c(0.5, 0.5), upper = c(10, 10), n = 10) %>>%   gradient_ascent(max_iter = 100)  result_gamma <- strategy(problem_gamma, theta0 = c(1, 1))  cat(\"MLE:  shape =\", round(result_gamma$theta.hat[1], 4),     \" rate =\", round(result_gamma$theta.hat[2], 4), \"\\n\") #> MLE:  shape = 2.6662  rate = 1.852 cat(\"True: shape =\", true_shape, \" rate =\", true_rate, \"\\n\") #> True: shape = 3  rate = 2 alpha_grid <- seq(1, 6, length.out = 50) beta_grid <- seq(0.5, 4, length.out = 50) ll_gamma <- outer(alpha_grid, beta_grid, function(a, b) {   mapply(function(ai, bi) problem_gamma$loglike(c(ai, bi)), a, b) })  contour(alpha_grid, beta_grid, ll_gamma, nlevels = 20,         xlab = expression(alpha ~ \"(shape)\"),         ylab = expression(beta ~ \"(rate)\"),         main = \"Gamma Distribution Log-Likelihood\") points(result_gamma$theta.hat[1], result_gamma$theta.hat[2],        pch = 19, col = \"red\", cex = 1.5) points(true_shape, true_rate, pch = 4, col = \"blue\", cex = 1.5, lwd = 2) legend(\"topright\", c(\"MLE\", \"True\"), pch = c(19, 4), col = c(\"red\", \"blue\"))"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"case-study-3-beta-distribution","dir":"Articles","previous_headings":"","what":"Case Study 3: Beta Distribution","title":"Case Studies: MLE for Common Distributions","text":"Shape parameters α>0\\alpha > 0 β>0\\beta > 0 data [0,1][0, 1].","code":"# Generate data true_alpha <- 2 true_beta <- 5 x_beta <- rbeta(150, shape1 = true_alpha, shape2 = true_beta)  # Define the problem problem_beta <- mle_problem(   loglike = function(theta) {     a <- theta[1]; b <- theta[2]     if (a <= 0 || b <= 0) return(-Inf)     n <- length(x_beta)     n * (lgamma(a + b) - lgamma(a) - lgamma(b)) +       (a - 1) * sum(log(x_beta)) + (b - 1) * sum(log(1 - x_beta))   },   score = function(theta) {     a <- theta[1]; b <- theta[2]     n <- length(x_beta)     psi_ab <- digamma(a + b)     c(n * (psi_ab - digamma(a)) + sum(log(x_beta)),       n * (psi_ab - digamma(b)) + sum(log(1 - x_beta)))   },   constraint = mle_constraint(     support = function(theta) all(theta > 0),     project = function(theta) pmax(theta, 1e-6)   ) )  # Method of moments for starting values m <- mean(x_beta); v <- var(x_beta) alpha_start <- m * (m * (1 - m) / v - 1) beta_start <- (1 - m) * (m * (1 - m) / v - 1)  result_beta <- gradient_ascent(max_iter = 200)(   problem_beta,   theta0 = c(max(alpha_start, 0.5), max(beta_start, 0.5)) )  cat(\"MLE:  alpha =\", round(result_beta$theta.hat[1], 4),     \" beta =\", round(result_beta$theta.hat[2], 4), \"\\n\") #> MLE:  alpha = 1.6398  beta = 4.3577 cat(\"True: alpha =\", true_alpha, \" beta =\", true_beta, \"\\n\") #> True: alpha = 2  beta = 5 hist(x_beta, breaks = 20, freq = FALSE, col = \"lightgray\",      main = \"Beta Distribution Fit\", xlab = \"x\") curve(dbeta(x, result_beta$theta.hat[1], result_beta$theta.hat[2]),       add = TRUE, col = \"red\", lwd = 2) curve(dbeta(x, true_alpha, true_beta), add = TRUE, col = \"blue\", lwd = 2, lty = 2) legend(\"topright\", c(\"Fitted\", \"True\"), col = c(\"red\", \"blue\"), lwd = 2, lty = c(1, 2))"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"case-study-4-weibull-distribution","dir":"Articles","previous_headings":"","what":"Case Study 4: Weibull Distribution","title":"Case Studies: MLE for Common Distributions","text":"Shape k>0k > 0 scale λ>0\\lambda > 0, using Newton-Raphson.","code":"# Generate data true_k <- 2; true_lambda <- 3 x_weibull <- rweibull(100, shape = true_k, scale = true_lambda)  # Define the problem (score only, Fisher computed numerically) problem_weibull <- mle_problem(   loglike = function(theta) {     k <- theta[1]; lambda <- theta[2]     if (k <= 0 || lambda <= 0) return(-Inf)     n <- length(x_weibull)     n * log(k) - n * k * log(lambda) +       (k - 1) * sum(log(x_weibull)) - sum((x_weibull / lambda)^k)   },   score = function(theta) {     k <- theta[1]; lambda <- theta[2]     n <- length(x_weibull)     x_scaled <- x_weibull / lambda     x_scaled_k <- x_scaled^k     c(n / k - n * log(lambda) + sum(log(x_weibull)) - sum(x_scaled_k * log(x_scaled)),       -n * k / lambda + k * sum(x_scaled_k) / lambda)   },   constraint = mle_constraint(     support = function(theta) all(theta > 0),     project = function(theta) pmax(theta, 1e-6)   ) )  # Newton-Raphson with numerical Fisher result_weibull <- newton_raphson(max_iter = 50)(problem_weibull, theta0 = c(1, 1))  cat(\"MLE:  shape =\", round(result_weibull$theta.hat[1], 4),     \" scale =\", round(result_weibull$theta.hat[2], 4), \"\\n\") #> MLE:  shape = 2.0466  scale = 2.8588 cat(\"True: shape =\", true_k, \" scale =\", true_lambda, \"\\n\") #> True: shape = 2  scale = 3 hist(x_weibull, breaks = 15, freq = FALSE, col = \"lightgray\",      main = \"Weibull Distribution Fit\", xlab = \"x\") curve(dweibull(x, shape = result_weibull$theta.hat[1],                scale = result_weibull$theta.hat[2]),       add = TRUE, col = \"red\", lwd = 2) curve(dweibull(x, shape = true_k, scale = true_lambda),       add = TRUE, col = \"blue\", lwd = 2, lty = 2) legend(\"topright\", c(\"Fitted\", \"True\"), col = c(\"red\", \"blue\"), lwd = 2, lty = c(1, 2))"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"case-study-5-mixture-of-normals","dir":"Articles","previous_headings":"","what":"Case Study 5: Mixture of Normals","title":"Case Studies: MLE for Common Distributions","text":"Multimodal likelihood requires good initialization restarts.","code":"# Generate mixture data n1 <- 60; n2 <- 40 x_mix <- c(rnorm(n1, mean = 0, sd = 1), rnorm(n2, mean = 4, sd = 1.5))  # Parameters: (mu1, sigma1, mu2, sigma2, pi) problem_mix <- mle_problem(   loglike = function(theta) {     mu1 <- theta[1]; s1 <- theta[2]     mu2 <- theta[3]; s2 <- theta[4]     pi1 <- theta[5]     if (s1 <= 0 || s2 <= 0 || pi1 <= 0 || pi1 >= 1) return(-Inf)     # Log-sum-exp for numerical stability     log_p1 <- log(pi1) + dnorm(x_mix, mu1, s1, log = TRUE)     log_p2 <- log(1 - pi1) + dnorm(x_mix, mu2, s2, log = TRUE)     log_max <- pmax(log_p1, log_p2)     sum(log_max + log(exp(log_p1 - log_max) + exp(log_p2 - log_max)))   },   constraint = mle_constraint(     support = function(theta) theta[2] > 0 && theta[4] > 0 && theta[5] > 0 && theta[5] < 1,     project = function(theta) c(theta[1], max(theta[2], 0.1), theta[3],                                  max(theta[4], 0.1), min(max(theta[5], 0.01), 0.99))   ) )  # Use k-means for initialization km <- kmeans(x_mix, centers = 2) mu1_init <- min(km$centers); mu2_init <- max(km$centers) s1_init <- sd(x_mix[km$cluster == which.min(km$centers)]) s2_init <- sd(x_mix[km$cluster == which.max(km$centers)]) pi_init <- mean(km$cluster == which.min(km$centers))  result_mix <- gradient_ascent(learning_rate = 0.5, max_iter = 300)(   problem_mix,   theta0 = c(mu1_init, s1_init, mu2_init, s2_init, pi_init) )  cat(\"Fitted:\\n\") #> Fitted: cat(\"  Component 1: mu =\", round(result_mix$theta.hat[1], 2),     \" sigma =\", round(result_mix$theta.hat[2], 2), \"\\n\") #>   Component 1: mu = -0.13  sigma = 0.9 cat(\"  Component 2: mu =\", round(result_mix$theta.hat[3], 2),     \" sigma =\", round(result_mix$theta.hat[4], 2), \"\\n\") #>   Component 2: mu = 4.18  sigma = 1.53 cat(\"  Mixing proportion:\", round(result_mix$theta.hat[5], 2), \"\\n\") #>   Mixing proportion: 0.58 hist(x_mix, breaks = 25, freq = FALSE, col = \"lightgray\",      main = \"Gaussian Mixture Fit\", xlab = \"x\")  x_seq <- seq(min(x_mix) - 1, max(x_mix) + 1, length.out = 200) fitted_density <- result_mix$theta.hat[5] *   dnorm(x_seq, result_mix$theta.hat[1], result_mix$theta.hat[2]) +   (1 - result_mix$theta.hat[5]) *   dnorm(x_seq, result_mix$theta.hat[3], result_mix$theta.hat[4]) lines(x_seq, fitted_density, col = \"red\", lwd = 2)  true_density <- (n1/(n1+n2)) * dnorm(x_seq, 0, 1) + (n2/(n1+n2)) * dnorm(x_seq, 4, 1.5) lines(x_seq, true_density, col = \"blue\", lwd = 2, lty = 2) legend(\"topright\", c(\"Fitted\", \"True\"), col = c(\"red\", \"blue\"), lwd = 2, lty = c(1, 2))"},{"path":"https://queelius.github.io/compositional.mle/articles/case-studies.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Case Studies: MLE for Common Distributions","text":"Key takeaways: Separate problem solver - mle_problem() encapsulates model Compose strategies - Use %>>% coarse--fine optimization Use constraints - Keep parameters valid ranges Good initialization - Critical multimodal problems","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Getting Started with compositional.mle","text":"compositional.mle package provides composable optimization strategies maximum likelihood estimation (MLE). Following SICP principles, offers: Primitive solvers - gradient_ascent(), newton_raphson(), bfgs(), nelder_mead(), etc. Composition operators - %>>% (sequential), %|% (race), with_restarts() Closure property - Combining solvers yields solver","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"installation","dir":"Articles","previous_headings":"","what":"Installation","title":"Getting Started with compositional.mle","text":"","code":"devtools::install_github(\"queelius/compositional.mle\") library(compositional.mle)"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"quick-start-normal-distribution-mle","dir":"Articles","previous_headings":"","what":"Quick Start: Normal Distribution MLE","title":"Getting Started with compositional.mle","text":"","code":"# Generate sample data set.seed(123) data <- rnorm(100, mean = 5, sd = 2)  # Define the problem (separate from solver strategy) problem <- mle_problem(   loglike = function(theta) {     if (theta[2] <= 0) return(-Inf)     sum(dnorm(data, theta[1], theta[2], log = TRUE))   },   score = function(theta) {     mu <- theta[1]; sigma <- theta[2]; n <- length(data)     c(sum(data - mu) / sigma^2,       -n / sigma + sum((data - mu)^2) / sigma^3)   },   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-6))   ),   theta_names = c(\"mu\", \"sigma\") )  # Solve with gradient ascent result <- gradient_ascent()(problem, theta0 = c(0, 1))  cat(\"Estimated mean:\", result$theta.hat[1], \"(true: 5)\\n\") #> Estimated mean: 5.180812 (true: 5) cat(\"Estimated sd:\", result$theta.hat[2], \"(true: 2)\\n\") #> Estimated sd: 1.816481 (true: 2)"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"the-problem-solver-separation","dir":"Articles","previous_headings":"","what":"The Problem-Solver Separation","title":"Getting Started with compositional.mle","text":"key design principle separating ’re estimating estimate :","code":"# The problem encapsulates the statistical model print(problem) #> MLE Problem #>   Parameters: mu, sigma  #>   Score: analytic  #>   Fisher: numerical  #>   Constraints: yes  # Solvers are independent strategies solver1 <- gradient_ascent(max_iter = 100) solver2 <- newton_raphson(max_iter = 50) solver3 <- bfgs()  # Same problem, different solvers result1 <- solver1(problem, c(0, 1)) result2 <- solver2(problem, c(0, 1)) result3 <- solver3(problem, c(0, 1))  cat(\"Gradient ascent:\", result1$theta.hat, \"\\n\") #> Gradient ascent: 5.180812 1.816481 cat(\"Newton-Raphson:\", result2$theta.hat, \"\\n\") #> Newton-Raphson: 0 1 cat(\"BFGS:\", result3$theta.hat, \"\\n\") #> BFGS: 100.7711 567.4039"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"sequential-chaining","dir":"Articles","previous_headings":"Composing Solvers","what":"Sequential Chaining (%>>%)","title":"Getting Started with compositional.mle","text":"Chain solvers coarse--fine optimization:","code":"# Grid search finds a good region, then gradient ascent refines strategy <- grid_search(lower = c(-10, 0.5), upper = c(10, 5), n = 5) %>>%   gradient_ascent(max_iter = 50)  result <- strategy(problem, theta0 = c(0, 1)) cat(\"Result:\", result$theta.hat, \"\\n\") #> Result: 5.180812 1.816481"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"three-stage-refinement","dir":"Articles","previous_headings":"Composing Solvers","what":"Three-Stage Refinement","title":"Getting Started with compositional.mle","text":"","code":"# Coarse grid -> gradient ascent -> Newton-Raphson polish strategy <- grid_search(lower = c(-10, 0.5), upper = c(10, 5), n = 5) %>>%   gradient_ascent(max_iter = 30) %>>%   newton_raphson(max_iter = 10)  result <- strategy(problem, theta0 = c(0, 1)) cat(\"Result:\", result$theta.hat, \"\\n\") #> Result: 5.180812 1.816481 cat(\"Converged:\", result$converged, \"\\n\") #> Converged: FALSE"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"parallel-racing","dir":"Articles","previous_headings":"Composing Solvers","what":"Parallel Racing (%|%)","title":"Getting Started with compositional.mle","text":"Race multiple methods keep best result:","code":"# Try gradient-based and derivative-free methods strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()  result <- strategy(problem, theta0 = c(0, 1)) cat(\"Winner:\", result$solver, \"\\n\") #> Winner: gradient_ascent cat(\"Result:\", result$theta.hat, \"\\n\") #> Result: 5.180812 1.816481"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"random-restarts","dir":"Articles","previous_headings":"Composing Solvers","what":"Random Restarts","title":"Getting Started with compositional.mle","text":"Escape local optima multiple starting points:","code":"strategy <- with_restarts(   gradient_ascent(),   n = 10,   sampler = uniform_sampler(c(-10, 0.5), c(10, 5)) )  result <- strategy(problem, theta0 = c(0, 1)) cat(\"Best restart:\", result$best_restart, \"of\", result$n_restarts, \"\\n\") #> Best restart: 1 of 10 cat(\"Result:\", result$theta.hat, \"\\n\") #> Result: 5.180812 1.816481"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"conditional-refinement","dir":"Articles","previous_headings":"Composing Solvers","what":"Conditional Refinement","title":"Getting Started with compositional.mle","text":"refine first solver didn’t converge:","code":"strategy <- unless_converged(   gradient_ascent(max_iter = 10),  # Quick attempt    newton_raphson(max_iter = 50)     # Refine if needed )  result <- strategy(problem, theta0 = c(0, 1)) cat(\"Result:\", result$theta.hat, \"\\n\") #> Result: 5.180812 1.816481"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"constraints","dir":"Articles","previous_headings":"","what":"Constraints","title":"Getting Started with compositional.mle","text":"Define domain constraints support checking projection:","code":"# Positive parameters pos_constraint <- mle_constraint(   support = function(theta) all(theta > 0),   project = function(theta) pmax(theta, 1e-8) )  # Box constraints [0, 10] box_constraint <- mle_constraint(   support = function(theta) all(theta >= 0 & theta <= 10),   project = function(theta) pmax(0, pmin(10, theta)) )  # Use in problem definition problem_constrained <- mle_problem(   loglike = function(theta) -sum((theta - 5)^2),   constraint = pos_constraint )"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"stochastic-gradient-mini-batching","dir":"Articles","previous_headings":"Function Transformers","what":"Stochastic Gradient (Mini-batching)","title":"Getting Started with compositional.mle","text":"large datasets, subsample observations:","code":"# Original log-likelihood uses all data loglike_full <- function(theta, obs = large_data) {   sum(dnorm(obs, theta[1], theta[2], log = TRUE)) }  # Stochastic version uses random subsets loglike_sgd <- with_subsampling(loglike_full, data = large_data, subsample_size = 100)"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"regularization","dir":"Articles","previous_headings":"Function Transformers","what":"Regularization","title":"Getting Started with compositional.mle","text":"Add penalty terms regularization:","code":"loglike <- function(theta) -sum(theta^2)  # L1 (Lasso), L2 (Ridge), Elastic Net loglike_l1 <- with_penalty(loglike, penalty_l1(), lambda = 0.1) loglike_l2 <- with_penalty(loglike, penalty_l2(), lambda = 0.1) loglike_enet <- with_penalty(loglike, penalty_elastic_net(alpha = 0.5), lambda = 0.1)  theta <- c(1, 2, 3) cat(\"Original:\", loglike(theta), \"\\n\") #> Original: -14 cat(\"With L1:\", loglike_l1(theta), \"\\n\") #> With L1: -14.6 cat(\"With L2:\", loglike_l2(theta), \"\\n\") #> With L2: -15.4"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"tracing-optimization","dir":"Articles","previous_headings":"","what":"Tracing Optimization","title":"Getting Started with compositional.mle","text":"Track optimization path diagnostics:","code":"trace_config <- mle_trace(values = TRUE, path = TRUE, gradients = TRUE)  result <- gradient_ascent(max_iter = 20)(   problem,   theta0 = c(0, 1),   trace = trace_config )  if (!is.null(result$trace_data)) {   cat(\"Iterations:\", result$trace_data$total_iterations, \"\\n\")   cat(\"Final log-likelihood:\", tail(result$trace_data$values, 1), \"\\n\") } #> Iterations: 20  #> Final log-likelihood: -201.5839"},{"path":"https://queelius.github.io/compositional.mle/articles/getting-started.html","id":"api-summary","dir":"Articles","previous_headings":"","what":"API Summary","title":"Getting Started with compositional.mle","text":"Problem Specification: - mle_problem() - Define estimation problem - mle_constraint() - Domain constraints Solver Factories: - gradient_ascent(), newton_raphson(), bfgs(), lbfgsb(), nelder_mead() - grid_search(), random_search() Composition: - %>>% - Sequential chaining - %|% - Parallel racing - with_restarts() - Multiple starting points - unless_converged() - Conditional refinement - compose() - Compose multiple solvers Samplers: - uniform_sampler(), normal_sampler() Transformers: - with_subsampling(), with_penalty() - penalty_l1(), penalty_l2(), penalty_elastic_net()","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Designing Optimization Strategies","text":"vignette shows design effective optimization strategies composing solvers. ’ll cover: Diagnosing convergence problems Building robust pipelines Benchmarking solver combinations Handling common failure modes","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"the-problem-why-composition","dir":"Articles","previous_headings":"","what":"The Problem: Why Composition?","title":"Designing Optimization Strategies","text":"Consider fitting mixture normals - notoriously multi-modal problem:","code":"# Generate mixture data x_mix <- c(rnorm(70, mean = 0, sd = 1), rnorm(30, mean = 5, sd = 1.5))  # Log-likelihood for 2-component Gaussian mixture mixture_loglike <- function(theta) {   mu1 <- theta[1]; s1 <- theta[2]   mu2 <- theta[3]; s2 <- theta[4]   pi1 <- theta[5]    if (s1 <= 0 || s2 <= 0 || pi1 <= 0 || pi1 >= 1) return(-Inf)    # Log-sum-exp for numerical stability   log_p1 <- log(pi1) + dnorm(x_mix, mu1, s1, log = TRUE)   log_p2 <- log(1 - pi1) + dnorm(x_mix, mu2, s2, log = TRUE)   log_max <- pmax(log_p1, log_p2)   sum(log_max + log(exp(log_p1 - log_max) + exp(log_p2 - log_max))) }  problem_mix <- mle_problem(   loglike = mixture_loglike,   constraint = mle_constraint(     support = function(theta) theta[2] > 0 && theta[4] > 0 &&                               theta[5] > 0 && theta[5] < 1,     project = function(theta) c(theta[1], max(theta[2], 0.1), theta[3],                                 max(theta[4], 0.1), min(max(theta[5], 0.01), 0.99))   ) )"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"single-solver-often-fails","dir":"Articles","previous_headings":"The Problem: Why Composition?","what":"Single Solver: Often Fails","title":"Designing Optimization Strategies","text":"result depends heavily starting point, often get stuck local optima.","code":"# Random starting point theta0 <- c(-2, 1, 3, 1, 0.5)  result_simple <- gradient_ascent(max_iter = 100)(problem_mix, theta0)  cat(\"Simple gradient ascent:\\n\") #> Simple gradient ascent: cat(\"  mu1 =\", round(result_simple$theta.hat[1], 2),     \" mu2 =\", round(result_simple$theta.hat[3], 2), \"\\n\") #>   mu1 = 0.12  mu2 = 2.66 cat(\"  Log-likelihood:\", round(result_simple$loglike, 2), \"\\n\") #>   Log-likelihood: -219.25"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"strategy-1-coarse-to-fine","dir":"Articles","previous_headings":"","what":"Strategy 1: Coarse-to-Fine","title":"Designing Optimization Strategies","text":"Start rough global search, refine:","code":"# K-means for smart initialization km <- kmeans(x_mix, centers = 2) mu1_init <- min(km$centers) mu2_init <- max(km$centers) s1_init <- sd(x_mix[km$cluster == which.min(km$centers)]) s2_init <- sd(x_mix[km$cluster == which.max(km$centers)]) pi_init <- mean(km$cluster == which.min(km$centers))  theta_init <- c(mu1_init, s1_init, mu2_init, s2_init, pi_init)  # Coarse-to-fine: random search -> gradient ascent strategy <- random_search(   sampler = function() c(runif(1, -5, 10), runif(1, 0.5, 3),                          runif(1, -5, 10), runif(1, 0.5, 3),                          runif(1, 0.2, 0.8)),   n = 50 ) %>>% gradient_ascent(max_iter = 200)  result_coarse <- strategy(problem_mix, theta_init)  cat(\"Coarse-to-fine strategy:\\n\") #> Coarse-to-fine strategy: cat(\"  mu1 =\", round(result_coarse$theta.hat[1], 2),     \" mu2 =\", round(result_coarse$theta.hat[3], 2), \"\\n\") #>   mu1 = 0.08  mu2 = 4.96 cat(\"  Log-likelihood:\", round(result_coarse$loglike, 2), \"\\n\") #>   Log-likelihood: -215.73"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"strategy-2-multiple-restarts","dir":"Articles","previous_headings":"","what":"Strategy 2: Multiple Restarts","title":"Designing Optimization Strategies","text":"Run gradient ascent many starting points:","code":"# Custom sampler for mixture parameters mixture_sampler <- function() {   c(runif(1, -5, 10),    # mu1     runif(1, 0.5, 3),     # sigma1     runif(1, -5, 10),     # mu2     runif(1, 0.5, 3),     # sigma2     runif(1, 0.2, 0.8))   # pi }  strategy <- with_restarts(   gradient_ascent(max_iter = 100),   n = 20,   sampler = mixture_sampler )  result_restarts <- strategy(problem_mix, theta_init)  cat(\"Random restarts (20 starts):\\n\") #> Random restarts (20 starts): cat(\"  mu1 =\", round(result_restarts$theta.hat[1], 2),     \" mu2 =\", round(result_restarts$theta.hat[3], 2), \"\\n\") #>   mu1 = 0.08  mu2 = 4.96 cat(\"  Log-likelihood:\", round(result_restarts$loglike, 2), \"\\n\") #>   Log-likelihood: -215.73 cat(\"  Best restart:\", result_restarts$best_restart, \"of\", result_restarts$n_restarts, \"\\n\") #>   Best restart: 1 of 20"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"strategy-3-racing-solvers","dir":"Articles","previous_headings":"","what":"Strategy 3: Racing Solvers","title":"Designing Optimization Strategies","text":"unsure method works best, race :","code":"strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()  result_race <- strategy(problem_mix, theta_init)  cat(\"Racing strategy:\\n\") #> Racing strategy: cat(\"  Winner:\", result_race$solver, \"\\n\") #>   Winner: gradient_ascent cat(\"  mu1 =\", round(result_race$theta.hat[1], 2),     \" mu2 =\", round(result_race$theta.hat[3], 2), \"\\n\") #>   mu1 = 0.08  mu2 = 4.96 cat(\"  Log-likelihood:\", round(result_race$loglike, 2), \"\\n\") #>   Log-likelihood: -215.73"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"strategy-4-global-local","dir":"Articles","previous_headings":"","what":"Strategy 4: Global + Local","title":"Designing Optimization Strategies","text":"Combine simulated annealing global exploration gradient ascent local refinement:","code":"strategy <- sim_anneal(temp_init = 10, cooling_rate = 0.95, max_iter = 500) %>>%   gradient_ascent(max_iter = 100)  result_global <- strategy(problem_mix, theta_init)  cat(\"Global + local strategy:\\n\") #> Global + local strategy: cat(\"  mu1 =\", round(result_global$theta.hat[1], 2),     \" mu2 =\", round(result_global$theta.hat[3], 2), \"\\n\") #>   mu1 = 0.08  mu2 = 4.96 cat(\"  Log-likelihood:\", round(result_global$loglike, 2), \"\\n\") #>   Log-likelihood: -215.73"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"diagnosing-convergence","dir":"Articles","previous_headings":"","what":"Diagnosing Convergence","title":"Designing Optimization Strategies","text":"Use tracing understand optimization behavior:","code":"# Enable full tracing trace_cfg <- mle_trace(values = TRUE, gradients = TRUE, path = TRUE)  # Simple problem for clear visualization simple_problem <- mle_problem(   loglike = function(theta) -sum((theta - c(3, 2))^2),   score = function(theta) -2 * (theta - c(3, 2)),   constraint = mle_constraint(support = function(theta) TRUE) )  result_traced <- gradient_ascent(max_iter = 30)(   simple_problem, c(-2, -1), trace = trace_cfg )  # Visualize convergence plot(result_traced, which = c(\"loglike\", \"path\"))"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"extracting-trace-data","dir":"Articles","previous_headings":"Diagnosing Convergence","what":"Extracting Trace Data","title":"Designing Optimization Strategies","text":"","code":"path_df <- optimization_path(result_traced) head(path_df) #>   iteration     loglike grad_norm    theta_1     theta_2 #> 1         1 -34.0000000 11.661904 -2.0000000 -1.00000000 #> 2         2 -23.3380962  9.661904 -1.1425071 -0.48550424 #> 3         3 -14.6761924  7.661904 -0.2850141  0.02899151 #> 4         4  -8.0142886  5.661904  0.5724788  0.54348727 #> 5         5  -3.3523848  3.661904  1.4299717  1.05798302 #> 6         6  -0.6904811  1.661904  2.2874646  1.57247878  # Check convergence rate if (nrow(path_df) > 5) {   improvement <- diff(path_df$loglike)   cat(\"\\nLog-likelihood improvement per iteration:\\n\")   print(round(improvement[1:min(5, length(improvement))], 4)) } #>  #> Log-likelihood improvement per iteration: #> [1] 10.6619  8.6619  6.6619  4.6619  2.6619"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"benchmarking-strategies","dir":"Articles","previous_headings":"","what":"Benchmarking Strategies","title":"Designing Optimization Strategies","text":"Compare different strategies problem:","code":"# Test problem: bimodal likelihood bimodal <- mle_problem(   loglike = function(theta) {     log(0.3 * dnorm(theta, 2, 0.5) + 0.7 * dnorm(theta, 7, 0.5))   },   constraint = mle_constraint(support = function(theta) TRUE) )  # Strategies to compare strategies <- list(   \"Gradient Ascent\" = gradient_ascent(max_iter = 100),   \"BFGS\" = bfgs(),   \"Nelder-Mead\" = nelder_mead(),   \"SA + GA\" = sim_anneal(max_iter = 200) %>>% gradient_ascent(),   \"Restarts (5)\" = with_restarts(gradient_ascent(), n = 5,                                   sampler = function() runif(1, -5, 15)) )  # Run each strategy multiple times results <- data.frame(   Strategy = character(),   LogLike = numeric(),   Theta = numeric(),   stringsAsFactors = FALSE )  for (name in names(strategies)) {   for (rep in 1:3) {     set.seed(rep * 100)     theta0 <- runif(1, -5, 15)     result <- tryCatch(       strategies[[name]](bimodal, theta0),       error = function(e) NULL     )     if (!is.null(result)) {       results <- rbind(results, data.frame(         Strategy = name,         LogLike = result$loglike,         Theta = result$theta.hat[1],         stringsAsFactors = FALSE       ))     }   } } #> Warning in optim(par = theta0, fn = fn, method = \"Nelder-Mead\", control = list(maxit = max_iter, : one-dimensional optimization by Nelder-Mead is unreliable: #> use \"Brent\" or optimize() directly #> Warning in optim(par = theta0, fn = fn, method = \"Nelder-Mead\", control = list(maxit = max_iter, : one-dimensional optimization by Nelder-Mead is unreliable: #> use \"Brent\" or optimize() directly #> Warning in optim(par = theta0, fn = fn, method = \"Nelder-Mead\", control = list(maxit = max_iter, : one-dimensional optimization by Nelder-Mead is unreliable: #> use \"Brent\" or optimize() directly  # Summarize results library(dplyr) #>  #> Attaching package: 'dplyr' #> The following objects are masked from 'package:stats': #>  #>     filter, lag #> The following objects are masked from 'package:base': #>  #>     intersect, setdiff, setequal, union results %>%   group_by(Strategy) %>%   summarize(     MeanLogLike = round(mean(LogLike), 2),     BestTheta = round(Theta[which.max(LogLike)], 2),     .groups = \"drop\"   ) %>%   arrange(desc(MeanLogLike)) #> # A tibble: 5 × 3 #>   Strategy        MeanLogLike BestTheta #>   <chr>                 <dbl>     <dbl> #> 1 Restarts (5)          -0.58         7 #> 2 BFGS                  -0.86         7 #> 3 Gradient Ascent       -0.86         7 #> 4 Nelder-Mead           -0.86         7 #> 5 SA + GA               -0.86         7"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"start-simple-add-complexity","dir":"Articles","previous_headings":"Best Practices","what":"1. Start Simple, Add Complexity","title":"Designing Optimization Strategies","text":"","code":"# First try: simple gradient ascent result <- gradient_ascent()(problem, theta0)  # If it fails, add restarts result <- with_restarts(gradient_ascent(), n = 10, sampler = my_sampler)(problem, theta0)  # If still failing, try global + local result <- (sim_anneal() %>>% gradient_ascent())(problem, theta0)"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"use-domain-knowledge-for-initialization","dir":"Articles","previous_headings":"Best Practices","what":"2. Use Domain Knowledge for Initialization","title":"Designing Optimization Strategies","text":"","code":"# Method of moments for mixture initialization m <- mean(data); v <- var(data) theta0 <- c(m - sqrt(v), sqrt(v), m + sqrt(v), sqrt(v), 0.5)"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"monitor-convergence","dir":"Articles","previous_headings":"Best Practices","what":"4. Monitor Convergence","title":"Designing Optimization Strategies","text":"Always enable tracing development:","code":"result <- solver(problem, theta0, trace = mle_trace(values = TRUE, gradients = TRUE)) plot(result)"},{"path":"https://queelius.github.io/compositional.mle/articles/strategy-design.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Designing Optimization Strategies","text":"compositional approach lets : Combine strengths: Global search + local refinement Handle uncertainty: Race multiple methods Build robustness: Multiple restarts Diagnose issues: Full tracing visualization Start simple strategies add complexity needed.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"what-is-maximum-likelihood-estimation","dir":"Articles","previous_headings":"","what":"What is Maximum Likelihood Estimation?","title":"Theory and Intuition Behind Numerical MLE","text":"Maximum Likelihood Estimation (MLE) fundamental method estimating parameters statistical model. idea simple yet powerful: find parameter values make observed data probable.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"the-likelihood-function","dir":"Articles","previous_headings":"What is Maximum Likelihood Estimation?","what":"The Likelihood Function","title":"Theory and Intuition Behind Numerical MLE","text":"Suppose observe data x1,x2,…,xnx_1, x_2, \\ldots, x_n believe comes probability distribution parameter(s) θ\\theta. likelihood function L(θ)L(\\theta) measures probable observed data , given parameter θ\\theta: L(θ)=P(X1=x1,X2=x2,…,Xn=xn∣θ)L(\\theta) = P(X_1 = x_1, X_2 = x_2, \\ldots, X_n = x_n \\mid \\theta) independent observations: L(θ)=∏=1nf(xi∣θ)L(\\theta) = \\prod_{=1}^{n} f(x_i \\mid \\theta) f(⋅∣θ)f(\\cdot \\mid \\theta) probability density (mass) function.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"why-log-likelihood","dir":"Articles","previous_headings":"What is Maximum Likelihood Estimation?","what":"Why Log-Likelihood?","title":"Theory and Intuition Behind Numerical MLE","text":"Working products numerically unstable mathematically inconvenient. Taking logarithm converts products sums: ℓ(θ)=logL(θ)=∑=1nlogf(xi∣θ)\\ell(\\theta) = \\log L(\\theta) = \\sum_{=1}^{n} \\log f(x_i \\mid \\theta) Since log\\log monotonic, maximizing ℓ(θ)\\ell(\\theta) equivalent maximizing L(θ)L(\\theta). log-likelihood several advantages: Numerical stability: Products small probabilities can underflow zero Computational efficiency: Sums faster products Mathematical convenience: Derivatives sums easier derivatives products Statistical properties: curvature ℓ(θ)\\ell(\\theta) relates estimation uncertainty","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"a-concrete-example","dir":"Articles","previous_headings":"What is Maximum Likelihood Estimation?","what":"A Concrete Example","title":"Theory and Intuition Behind Numerical MLE","text":"Let’s see normal data:  MLE point surface highest value (deepest red contour plot).","code":"set.seed(42) x <- rnorm(50, mean = 3, sd = 1.5)  # Log-likelihood function for normal distribution loglike <- function(theta) {   mu <- theta[1]   sigma <- theta[2]   if (sigma <= 0) return(-Inf)   sum(dnorm(x, mean = mu, sd = sigma, log = TRUE)) }  # Visualize the log-likelihood surface mu_grid <- seq(1, 5, length.out = 50) sigma_grid <- seq(0.5, 3, length.out = 50) ll_surface <- outer(mu_grid, sigma_grid, function(m, s) {   mapply(function(mi, si) loglike(c(mi, si)), m, s) })  # Contour plot contour(mu_grid, sigma_grid, ll_surface, nlevels = 20,         xlab = expression(mu), ylab = expression(sigma),         main = \"Log-Likelihood Surface\") points(mean(x), sd(x), pch = 19, col = \"red\", cex = 1.5) legend(\"topright\", \"MLE\", pch = 19, col = \"red\")"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"the-score-function","dir":"Articles","previous_headings":"","what":"The Score Function","title":"Theory and Intuition Behind Numerical MLE","text":"score function gradient (vector partial derivatives) log-likelihood: s(θ)=∇θℓ(θ)=(∂ℓ∂θ1,…,∂ℓ∂θp)s(\\theta) = \\nabla_\\theta \\ell(\\theta) = \\left( \\frac{\\partial \\ell}{\\partial \\theta_1}, \\ldots, \\frac{\\partial \\ell}{\\partial \\theta_p} \\right) MLE θ̂\\hat{\\theta}, score zero: s(θ̂)=0s(\\hat{\\theta}) = 0.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"intuition","dir":"Articles","previous_headings":"The Score Function","what":"Intuition","title":"Theory and Intuition Behind Numerical MLE","text":"score tells us direction steepest ascent log-likelihood surface. s(θ)≠0s(\\theta) \\neq 0, can increase likelihood moving direction s(θ)s(\\theta).","code":"# Score function for normal distribution score <- function(theta) {   mu <- theta[1]   sigma <- theta[2]   n <- length(x)   c(     sum(x - mu) / sigma^2,                        # d/d_mu     -n / sigma + sum((x - mu)^2) / sigma^3        # d/d_sigma   ) }  # At a point away from the MLE, the score points toward the MLE theta_start <- c(1, 0.8) s <- score(theta_start) cat(\"Score at (1, 0.8):\", round(s, 2), \"\\n\") #> Score at (1, 0.8): 152.07 593.01 cat(\"Direction: move\", ifelse(s[1] > 0, \"right\", \"left\"), \"in mu,\",     ifelse(s[2] > 0, \"up\", \"down\"), \"in sigma\\n\") #> Direction: move right in mu, up in sigma"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"gradient-ascent","dir":"Articles","previous_headings":"","what":"Gradient Ascent","title":"Theory and Intuition Behind Numerical MLE","text":"Gradient ascent simplest optimization algorithm. iteratively moves direction gradient: θ(t+1)=θ(t)+η⋅s(θ(t))\\theta^{(t+1)} = \\theta^{(t)} + \\eta \\cdot s(\\theta^{(t)}) η>0\\eta > 0 learning rate (step size).","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"why-it-works","dir":"Articles","previous_headings":"Gradient Ascent","what":"Why It Works","title":"Theory and Intuition Behind Numerical MLE","text":"score points direction steepest increase. Taking small steps direction guarantees improvement (small enough η\\eta).","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"the-challenge-choosing-the-step-size","dir":"Articles","previous_headings":"Gradient Ascent","what":"The Challenge: Choosing the Step Size","title":"Theory and Intuition Behind Numerical MLE","text":"large: might overshoot oscillate small: Convergence painfully slow","code":"# Demonstrate gradient ascent with different step sizes run_gradient_ascent <- function(eta, max_iter = 50) {   theta <- c(1, 0.8)   path <- matrix(NA, max_iter + 1, 2)   path[1, ] <- theta    for (i in 1:max_iter) {     theta <- theta + eta * score(theta)     if (theta[2] <= 0) theta[2] <- 0.01  # Enforce constraint     path[i + 1, ] <- theta   }   path }  # Compare step sizes path_small <- run_gradient_ascent(0.001) path_good <- run_gradient_ascent(0.01) path_large <- run_gradient_ascent(0.05)  # Plot paths contour(mu_grid, sigma_grid, ll_surface, nlevels = 15,         xlab = expression(mu), ylab = expression(sigma),         main = \"Gradient Ascent: Effect of Step Size\") lines(path_small[, 1], path_small[, 2], col = \"blue\", lwd = 2) lines(path_good[, 1], path_good[, 2], col = \"green\", lwd = 2) lines(path_large[1:20, 1], path_large[1:20, 2], col = \"red\", lwd = 2) points(mean(x), sd(x), pch = 19, cex = 1.5) legend(\"topright\", c(\"Small (0.001)\", \"Good (0.01)\", \"Large (0.05)\"),        col = c(\"blue\", \"green\", \"red\"), lwd = 2)"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"line-search-automatic-step-size-selection","dir":"Articles","previous_headings":"Gradient Ascent","what":"Line Search: Automatic Step Size Selection","title":"Theory and Intuition Behind Numerical MLE","text":"Backtracking line search adaptively finds good step size: Start large step size doesn’t improve objective enough, shrink Repeat find acceptable step","code":"# Define the problem problem <- mle_problem(   loglike = loglike,   score = score,   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-6))   ) )  result <- gradient_ascent(max_iter = 50)(problem, theta0 = c(1, 0.8))  cat(\"Final estimate:\", round(result$theta.hat, 4), \"\\n\") #> Final estimate: 2.9465 1.7099 cat(\"Iterations:\", result$iterations, \"\\n\") #> Iterations: 19 cat(\"Converged:\", result$converged, \"\\n\") #> Converged: FALSE"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"the-fisher-information-matrix","dir":"Articles","previous_headings":"","what":"The Fisher Information Matrix","title":"Theory and Intuition Behind Numerical MLE","text":"Fisher information matrix (θ)(\\theta) measures much information data carries θ\\theta. can defined equivalently : (θ)=−E[∂2ℓ∂θ∂θT]=E[s(θ)s(θ)T](\\theta) = -E\\left[ \\frac{\\partial^2 \\ell}{\\partial \\theta \\partial \\theta^T} \\right] = E\\left[ s(\\theta) s(\\theta)^T \\right] second form shows (θ)(\\theta) equals covariance score (since E[s(θ)]=0E[s(\\theta)] = 0 true parameter).","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"why-it-matters","dir":"Articles","previous_headings":"The Fisher Information Matrix","what":"Why It Matters","title":"Theory and Intuition Behind Numerical MLE","text":"Curvature: (θ)(\\theta) describes curvature log-likelihood surface Uncertainty: asymptotic variance MLE Var(θ̂)≈(θ)−1\\text{Var}(\\hat{\\theta}) \\approx (\\theta)^{-1} (Cramér-Rao bound) Natural scaling: Different parameters may different scales; (θ)(\\theta) accounts ","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"observed-vs-expected-fisher-information","dir":"Articles","previous_headings":"The Fisher Information Matrix","what":"Observed vs Expected Fisher Information","title":"Theory and Intuition Behind Numerical MLE","text":"Expected information: (θ)=−E[∇2ℓ(θ)](\\theta) = -E[\\nabla^2 \\ell(\\theta)] Observed information: J(θ)=−∇2ℓ(θ)J(\\theta) = -\\nabla^2 \\ell(\\theta) (evaluated data) practice, often use observed information, doesn’t require computing expectations.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"newton-raphson","dir":"Articles","previous_headings":"","what":"Newton-Raphson","title":"Theory and Intuition Behind Numerical MLE","text":"Newton-Raphson uses Fisher information take smarter steps: θ(t+1)=θ(t)+(θ(t))−1s(θ(t))\\theta^{(t+1)} = \\theta^{(t)} + (\\theta^{(t)})^{-1} s(\\theta^{(t)})","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"intuition-1","dir":"Articles","previous_headings":"Newton-Raphson","what":"Intuition","title":"Theory and Intuition Behind Numerical MLE","text":"Gradient ascent treats directions equally, directions might “easier” move others. Newton-Raphson pre-multiplies −1I^{-1}, : Takes larger steps flat directions (low curvature) Takes smaller steps curved directions (high curvature) Accounts correlations parameters","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"comparison","dir":"Articles","previous_headings":"Newton-Raphson","what":"Comparison","title":"Theory and Intuition Behind Numerical MLE","text":"Newton-Raphson typically converges much faster, especially near optimum quadratic convergence kicks .","code":"# Fisher information for normal distribution fisher <- function(theta) {   sigma <- theta[2]   n <- length(x)   matrix(c(     n / sigma^2, 0,     0, 2 * n / sigma^2   ), nrow = 2) }  # Define problem with Fisher information problem_with_fisher <- mle_problem(   loglike = loglike,   score = score,   fisher = fisher,   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-6))   ) )  # Run gradient ascent result_ga <- gradient_ascent(max_iter = 100)(problem, theta0 = c(1, 0.8))  # Run Newton-Raphson result_nr <- newton_raphson(max_iter = 100)(problem_with_fisher, theta0 = c(1, 0.8))  cat(\"Gradient Ascent: \", result_ga$iterations, \"iterations\\n\") #> Gradient Ascent:  19 iterations cat(\"Newton-Raphson:  \", result_nr$iterations, \"iterations\\n\") #> Newton-Raphson:   20 iterations"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"composing-solvers","dir":"Articles","previous_headings":"","what":"Composing Solvers","title":"Theory and Intuition Behind Numerical MLE","text":"compositional.mle package lets compose optimization strategies:","code":"# Coarse-to-fine: grid search finds a good region, Newton polishes strategy <- grid_search(lower = c(0, 0.1), upper = c(6, 4), n = 5) %>>%   newton_raphson(max_iter = 20)  result <- strategy(problem_with_fisher, theta0 = c(1, 0.8)) cat(\"Result:\", round(result$theta.hat, 4), \"\\n\") #> Result: 2.9465 1.7099  # Race different methods, pick the best strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead() result <- strategy(problem, theta0 = c(1, 0.8)) cat(\"Winner:\", result$solver, \"\\n\") #> Winner: gradient_ascent"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"constrained-optimization","dir":"Articles","previous_headings":"","what":"Constrained Optimization","title":"Theory and Intuition Behind Numerical MLE","text":"Real problems often constraints parameters: Variance must positive: σ>0\\sigma > 0 Probabilities must [0,1][0, 1] Correlation must satisfy |ρ|<1|\\rho| < 1","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"projection-method","dir":"Articles","previous_headings":"Constrained Optimization","what":"Projection Method","title":"Theory and Intuition Behind Numerical MLE","text":"compositional.mle package uses projection: step takes us outside feasible region, project back nearest feasible point.","code":"# The constraint keeps sigma positive throughout optimization result <- gradient_ascent(max_iter = 100)(problem, theta0 = c(0, 0.1))  cat(\"Final sigma:\", result$theta.hat[2], \"> 0 (constraint satisfied)\\n\") #> Final sigma: 1.709855 > 0 (constraint satisfied)"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"regularization-and-penalized-likelihood","dir":"Articles","previous_headings":"","what":"Regularization and Penalized Likelihood","title":"Theory and Intuition Behind Numerical MLE","text":"Sometimes want penalize certain parameter values : Prevent overfitting Encourage sparsity Incorporate prior beliefs","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"penalized-log-likelihood","dir":"Articles","previous_headings":"Regularization and Penalized Likelihood","what":"Penalized Log-Likelihood","title":"Theory and Intuition Behind Numerical MLE","text":"ℓλ(θ)=ℓ(θ)−λ⋅P(θ)\\ell_\\lambda(\\theta) = \\ell(\\theta) - \\lambda \\cdot P(\\theta) P(θ)P(\\theta) penalty function λ>0\\lambda > 0 controls regularization strength.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"common-penalties","dir":"Articles","previous_headings":"Regularization and Penalized Likelihood","what":"Common Penalties","title":"Theory and Intuition Behind Numerical MLE","text":"L1 (LASSO): P(θ)=∑j|θj|P(\\theta) = \\sum_j |\\theta_j| Encourages sparsity (θj=0\\theta_j = 0) Useful variable selection L2 (Ridge): P(θ)=∑jθj2P(\\theta) = \\sum_j \\theta_j^2 Shrinks parameters toward zero Prevents extreme values Equivalent Gaussian prior Elastic Net: P(θ)=α∑j|θj|+(1−α)∑jθj2P(\\theta) = \\alpha \\sum_j |\\theta_j| + (1-\\alpha) \\sum_j \\theta_j^2 Combines L1 L2 benefits α\\alpha controls mix","code":"# Original log-likelihood (maximum at theta = (3,2)) loglike_simple <- function(theta) -sum((theta - c(3, 2))^2)  # Add L2 penalty loglike_l2 <- with_penalty(loglike_simple, penalty_l2(), lambda = 1)  # Compare theta <- c(3, 2) cat(\"At theta = (3, 2):\\n\") #> At theta = (3, 2): cat(\"  Original:\", loglike_simple(theta), \"\\n\") #>   Original: 0 cat(\"  With L2 penalty:\", loglike_l2(theta), \"\\n\") #>   With L2 penalty: -13 cat(\"  The penalty shrinks the solution toward zero\\n\") #>   The penalty shrinks the solution toward zero"},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"summary","dir":"Articles","previous_headings":"","what":"Summary","title":"Theory and Intuition Behind Numerical MLE","text":"compositional.mle package provides composable solvers can chained (%>>%), raced (%|%), restarted (with_restarts()) handle real-world complexities like constraints, regularization, multimodal surfaces.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/theory-and-intuition.html","id":"further-reading","dir":"Articles","previous_headings":"","what":"Further Reading","title":"Theory and Intuition Behind Numerical MLE","text":"Casella, G. Berger, R.L. (2002). Statistical Inference. Duxbury. Nocedal, J. Wright, S.J. (2006). Numerical Optimization. Springer. Murphy, K.P. (2012). Machine Learning: Probabilistic Perspective. MIT Press.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Fitting models to unknown DGPs","text":"interested generative process gave rise data observed. real world, DGPs quite complex, settle simpler models analytical tractability. , usually assume: sample ..d. way evaluating quality model. way choosing models. Since simulation, know underlying DGP (data generating process). ’s just \\[     T_i = W_i + \\epsilon_i \\] \\[     W_i \\sim \\operatorname{weibull}(k,\\lambda) \\] \\[     \\epsilon_i \\sim \\operatorname{normal}(0,\\sigma). \\] real world, know DGP. study, assume either \\(T_1,\\ldots,T_n\\) comes Weibull Normal. Clearly, true DGF bit complicated still simple compared realistic DGP. , process parametrically modeling observed data may take following steps: Visualize data, e.g., plot histogram data. Guess parametric distribution (components) might fit observed data system lifetime. Use statistical test goodness--fit. Repeat steps 2 3 measure goodness fit satisfactory.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"simulation-parameters-and-generation","dir":"Articles","previous_headings":"","what":"Simulation parameters and generation","title":"Fitting models to unknown DGPs","text":"simulation parameters given : generate data following R code: elements sample given :","code":"library(tibble) library(stats)  sim.n <- 27 sim.err.sd <- 0.05 sim.shape <- 20 sim.scale <- 3 sim.theta = c(sim.shape,sim.scale) set.seed(142334) sim.df <- tibble(lifetime=   rweibull(n=sim.n, shape=sim.shape, scale=sim.scale) +   rnorm(n=sim.n, mean=0, sd=sim.err.sd)) #> # A tibble: 6 × 1 #>   lifetime #>      <dbl> #> 1     2.91 #> 2     2.73 #> 3     3.09 #> 4     2.91 #> 5     3.20 #> 6     2.94"},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"visualizing-the-data","dir":"Articles","previous_headings":"","what":"Visualizing the data","title":"Fitting models to unknown DGPs","text":"Visualizing data good first step analysis data. data univariate bivariate, can plot histogram data pretty easily (’s multivariate, can plot marginal distributions data). show histogram simulated data :","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"parametrically-modeling-the-data","dir":"Articles","previous_headings":"","what":"Parametrically modeling the data","title":"Fitting models to unknown DGPs","text":"sample, might conclude? can difficult problem. case, know simulated data drawn distribution \\(T_i = W_i + \\epsilon_i\\) \\[   W_i \\sim \\operatorname{weibull}(\\lambda = 20,                                 k = 3) \\] \\[   \\epsilon_i \\sim \\operatorname{normal}(\\mu=0,\\sigma=0.05). \\] However, real-world data sets, know distribution. , let us suppose know true distribution data. interested , say, prediction, sufficiently large sample, use non-parametric methods “let data speak .” However, interested inference (e.g., explaining data) sample small, usually need make assumptions data. case, assume data drawn parametric distribution. many well-known, named parametric distributions, e.g., Pareto, Weibull, Normal, name . experience, seems like Weibull normal might good fits data. However, note since normal distribution permits negative values realized, may appropriate choice. Still, since approximations anyway, may big deal.","code":""},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"maximum-likelihood-estimation","dir":"Articles","previous_headings":"","what":"Maximum likelihood estimation","title":"Fitting models to unknown DGPs","text":"First, let us fit Weibull distribution choosing appropriate shape \\(\\lambda\\) scale \\(k\\) parameters using maximum likelihood estimator. find MLE \\(\\theta = (\\lambda,k)'\\), need log-likelihood function, given following R code: MLE point \\((\\hat k,\\hat\\lambda)'\\) maximum loglikelihood function, loglike, support parameters. Typically, closed solutions aren’t possible, normally use sort iterative technique. don’t go details , normally local search method, like Newton-Raphson (finds value makes gradient loglikelihood function zero) used. However, local methods – local – need good starting point. example Newton-raphson code, use since efficient easy understand: use efficient algorithm compute log-likelihood function Weibull distribution. code given :","code":"loglike <- function(theta) sum(dweibull(   sim.df$lifetime, shape=theta[1], scale=theta[2], log=T)) # f is the function we want to find the root of # Jf is the jocabian of f # x0 is the starting point newton_raphson <- function(f, df, x0) {   eta <- 1 # learning rate, not too large to avoid overshooting            # not too small to avoid slow convergence   eps <- 1e-3 # close enough to zero to stop     repeat   {     fx <- f(x0)        # new function value     if (max(abs(fx)) < eps) break # f(x) is close enough to zero     J <- Jf(x0)        # jacobian     d <- solve(J,fx)   # newton-raphson direction (pointing uphill)     x0 <- x0 + eta * d # newton-raphson update (going uphill)   }   x0 } library(algebraic.mle) #>  #> Attaching package: 'algebraic.mle' #> The following object is masked _by_ '.GlobalEnv': #>  #>     loglike ll.wei <- weibull_shape_scale_loglike(sim.df$lifetime)"},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"numerical-considerations","dir":"Articles","previous_headings":"Maximum likelihood estimation","what":"Numerical considerations","title":"Fitting models to unknown DGPs","text":"algebraic.mle package, provide precise efficient local iterative algorithm, mle_weibull_shape_scale, finding MLE Weibull distribution. local search method, needs good starting point shape parameter \\(k\\) close MLE, otherwise may fail converge MLE. find good starting point, use global search method, Simulated Annealing, implemented sim_anneal function. code finding good starting point: Let’s take look plots simulated annealing algorithm: first plot, see history log-likelihood values algorithm progresses. second plot shows path algorithm explores support parameters. third plot shows shape parameter, \\(k\\), algorithm progresses. red line true value \\(k\\). starting point hand, find MLE : function, mle_weibull_shape_scale, returns mle object, API provides number conventient methods, estimating variance-covariance matrix, confidence intervals, bias, . ’s code print summary MLE: Let’s normal distribution. use mle_normal_mu_var function algebraic.mle package: Let’s plot pdfs Weibull normal distributions: purple, true density (DGP). red, Weibull density. green, normal density. plot, ’s hard tell distribution better fit DGP. Interestingly, tails true distribution seem bit heavier tails Weibull Normal. may suggest heavier-tailed model may better fit, lognormal distribution, pursue . choose Weibull Normal distributions? discuss next section.","code":"# find a good starting position start <- sim_anneal(   f=ll.wei,   x0=sim.theta,   options=list(     t_init=100,     t_end=1e-4,     alpha=0.99,     iter_per_temp=200,     sup=function(theta) all(theta > 0),     trace=TRUE)) k0 <- start$argmax[1] cat(\"initial guess for k0 =\",k0,\"\\n\") #> initial guess for k0 = 20.06285 library(algebraic.mle) mle.wei <- mle_weibull_shape_scale(sim.df$lifetime, k0=k0) summary(mle.wei) #> Maximum likelihood estimator of type mle_weibull_shape_scale is normally distributed. #> The estimates of the parameters are given by: #>     shape     scale  #> 20.090236  2.941726  #> The standard error is  3.719537 0.03642942 . #> The asymptotic 95% confidence interval of the parameters are given by: #>            2.5%     97.5% #> shape 13.972143 26.208329 #> scale  2.881805  3.001647 #> The MSE of the estimator is  13.83628 . #> The log-likelihood is  10.99502 . #> The AIC is  -17.99005 . mle.norm <- mle_normal_mu_var(sim.df$lifetime) summary(mle.norm) #> Maximum likelihood estimator of type mle_normal_mu_var is normally distributed. #> The estimates of the parameters are given by: #>         mu        var  #> 2.86797534 0.02500757  #> The standard error is  0.03043364 0.006806199 . #> The asymptotic 95% confidence interval of the parameters are given by: #>           2.5%      97.5% #> mu  2.81791646 2.91803422 #> var 0.01381237 0.03620277 #> The MSE of the estimator is  0.0009733886 . #> The log-likelihood is  11.48444 . #> The AIC is  -18.96889 ."},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"goodness-of-fit","dir":"Articles","previous_headings":"","what":"Goodness of fit","title":"Fitting models to unknown DGPs","text":"fitting model data precisely capture generative model \\(W\\). , good fit ? conduct goodness fit test, \\[\\begin{align}   H_0 &: \\text{data compatible Weibull distribution}\\\\   H_A &: \\text{data compatible Weibull distribution}. \\end{align}\\] perform test, use Cramer-von Mises test. test based Cramer-von Mises statistic, measure distance empirical distribution function data distribution function model. Cramer-von Mises statistic given \\[   \\hat D_n^2 = \\frac{1}{n}\\sum_{=1}^n \\left(\\hat F_n(x_i) - F(x_i)\\right)^2 \\] \\(\\hat F_n\\) empirical distribution function data \\(F\\) distribution function model. Looking \\(p\\)-value, see data compatible Weibull distribution. Now, let’s normal distribution: compatible data. However, Weibull distribution larger \\(p\\)-value, may suggest better fit. also AIC measure goodness fit. AIC given \\[   \\text{AIC} = -2\\log L + 2k, \\] \\(L\\) likelihood model \\(k\\) number parameters model. AIC measure tradeoff goodness fit complexity model. lower AIC value indicates better fit. Thus, according measure, Weibull distribution better fit.","code":"cramer.test <- function(obs.dat,ref.dat) {   stat <- CDFt::CramerVonMisesTwoSamples(obs.dat,ref.dat)   list(p.value=exp(-stat)/6.0,        cramer.stat=stat,        obs.size=length(obs.dat),        ref.size=length(ref.dat)) }  wei.shape <- point(mle.wei)[1] wei.scale <- point(mle.wei)[2] ref.dat <- rweibull(1000000,shape=wei.shape,scale=wei.scale) cramer.test(sim.df$lifetime,ref.dat) #> $p.value #> [1] 0.1632591 #>  #> $cramer.stat #> [1] 0.02065722 #>  #> $obs.size #> [1] 27 #>  #> $ref.size #> [1] 1000000 norm.mu <- point(mle.norm)[1] norm.var <- point(mle.norm)[2] ref.dat <- rnorm(1000000,mean=norm.mu,sd=sqrt(norm.var)) cramer.test(sim.df$lifetime,ref.dat) #> $p.value #> [1] 0.1602598 #>  #> $cramer.stat #> [1] 0.03919976 #>  #> $obs.size #> [1] 27 #>  #> $ref.size #> [1] 1000000 aic(mle.wei) #> [1] -17.99005 aic(mle.norm) #>       var  #> -18.96889"},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"conclusion","dir":"Articles","previous_headings":"","what":"Conclusion","title":"Fitting models to unknown DGPs","text":"post, shown fit Weibull Normal distributions simulated dataset whose true distribution, known, common name. shown compare two models using Cramer-von Mises test AIC measure goodness fit. came definitive conclusion model better, Weibull distribution larger \\(p\\)-value Cramer-von Mises test, lower AIC value, serves evidence better fit. saw true DGP visually different Weibull normal distributions. Notably, DGP longer tails , suggesting even better fit may long-tail distribution like log-normal Pareto distribution.","code":"# store sequence of steps in gradient ascent/newton raphson and plot the points # overlay it with loglike library(tidyverse) library(md.tools) library(stats)  theta <- c(100,2) n <- 17 data <- rweibull(n,shape=theta[1],scale=theta[2]) loglik <- weibull_shape_scale_loglike(data) scr <- weibull_shape_scale_score(data) nfo <- weibull_shape_scale_fim(data)  theta0 <- c(5,15)  sup.weibull <- function(theta) {     all(theta > 0) }  theta.start <- sim_anneal(     f=loglik,     x0=theta0,     options=list(         t_init=100,         t_end=1e-4,         alpha=0.99,         iter_per_temp=200,         sup=sup.weibull,         debug=FALSE,         trace=TRUE))  logliks <- apply(theta.start$path,1,loglik) plot(logliks,type=\"l\",xlab=\"iteration\",ylab=\"log-likelihood\")  theta.mle <- mle_weibull_shape_scale(     data,     k0=theta.start$argmax[1],     eps=1e-10)  theta.nr <- mle_newton_raphson(     ll=loglik,     theta0=theta.start$argmax,     score=scr,     info=nfo,     options=list(         sup=sup.weibull,         rel_tol=1e-12,         eta=.1,         trace=TRUE))  trace.ll <- apply(theta.nr$trace,1,loglik) plot(trace.ll,type=\"l\")  point(theta.nr) mle_local_search  theta.optim <- mle_optim(optim(     par=theta.start$argmax,     fn=loglik,     gr=scr,           hessian=TRUE,     control=list(fnscale=-1,reltol=1e-16, maxit=2000000)))"},{"path":"https://queelius.github.io/compositional.mle/articles/unknow_dgp.html","id":"pis","dir":"Articles","previous_headings":"","what":"PIs","title":"Fitting models to unknown DGPs","text":"","code":"n <- 100 theta <- c(4,2) x <- rnorm(n,mean=theta[1],sd=sqrt(theta[2])) head(x,n=4) hist(x) theta.hat <- mle_normal_mu_var(x) summary(theta.hat) point(theta.hat) fim(theta.hat) vcov(theta.hat) confint(theta.hat) bias(theta.hat,theta) bias(theta.hat) mse(theta.hat)        # estimate of MSE mse(theta.hat,theta)  # true MSE  mle_solver <- function(data, ind)     point(mle_normal_mu_var(data[ind])) R <- 100000 # number of bootstrap replicates  theta.boot <- mle_boot(mle_solver, x, R, parallel=\"multicore\", ncpus=4) bias(theta.boot) bias(theta.hat)  samplr <- function(n=1,theta) rnorm(n,theta[1],theta[2]) pred(x=theta.hat, samp=samplr)"},{"path":"https://queelius.github.io/compositional.mle/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Alexander Towell. Author, maintainer.","code":""},{"path":"https://queelius.github.io/compositional.mle/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Towell (2025). compositional.mle: Compositional Maximum Likelihood Estimation. R package version 0.2.0, https://github.com/queelius/compositional.mle.","code":"@Manual{,   title = {compositional.mle: Compositional Maximum Likelihood Estimation},   author = {Alexander Towell},   year = {2025},   note = {R package version 0.2.0},   url = {https://github.com/queelius/compositional.mle}, }"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"when-to-use-this-package","dir":"","previous_headings":"","what":"When to Use This Package","title":"Compositional Maximum Likelihood Estimation","text":"Use compositional.mle : Multi-modal likelihoods: likelihood surface multiple local optima need global search strategies (simulated annealing, random restarts) Coarse--fine optimization: want start rough global search progressively refine local methods Comparing strategies: ’re unsure optimizer works best want race automatically Building robust pipelines: need reliable estimation handles edge cases gracefully Research/experimentation: want explore optimization strategies visualize convergence Stick optim() : simple, well-behaved likelihood single optimum know exactly method works don’t need composition","code":""},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"example-why-composition-matters","dir":"","previous_headings":"When to Use This Package","what":"Example: Why Composition Matters","title":"Compositional Maximum Likelihood Estimation","text":"","code":"library(compositional.mle)  # A tricky bimodal likelihood set.seed(42) bimodal_loglike <- function(theta) {   # Two peaks: one at theta=2, one at theta=8   log(0.3 * dnorm(theta, 2, 0.5) + 0.7 * dnorm(theta, 8, 0.5)) }  problem <- mle_problem(  loglike = bimodal_loglike,   constraint = mle_constraint(support = function(theta) TRUE) )  # Single gradient ascent gets trapped at local optimum result_local <- gradient_ascent()(problem, theta0 = 0)  # Simulated annealing + gradient ascent finds global optimum strategy <- sim_anneal(temp_init = 5, max_iter = 200) %>>% gradient_ascent() result_global <- strategy(problem, theta0 = 0)  cat(\"Local search found:\", round(result_local$theta.hat, 2),     \"(log-lik:\", round(result_local$loglike, 2), \")\\n\") #> Local search found: 2 (log-lik: -1.43 ) cat(\"Global strategy found:\", round(result_global$theta.hat, 2),     \"(log-lik:\", round(result_global$loglike, 2), \")\\n\") #> Global strategy found: 2 (log-lik: -1.43 )"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Compositional Maximum Likelihood Estimation","text":"","code":"# From CRAN (when available) install.packages(\"compositional.mle\")  # Development version devtools::install_github(\"queelius/compositional.mle\")"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"design-philosophy","dir":"","previous_headings":"","what":"Design Philosophy","title":"Compositional Maximum Likelihood Estimation","text":"Following SICP principles, package provides: 1. Primitive solvers - gradient_ascent(), newton_raphson(), bfgs(), sim_anneal(), etc. 2. Composition operators - %>>% (sequential), %|% (race), with_restarts() 3. Closure property - Combining solvers yields solver","code":""},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"quick-start","dir":"","previous_headings":"","what":"Quick Start","title":"Compositional Maximum Likelihood Estimation","text":"","code":"# Generate sample data set.seed(42) x <- rnorm(100, mean = 5, sd = 2)  # Define the problem (separate from solver strategy) problem <- mle_problem(   loglike = function(theta) {     if (theta[2] <= 0) return(-Inf)     sum(dnorm(x, theta[1], theta[2], log = TRUE))   },   score = function(theta) {     mu <- theta[1]; sigma <- theta[2]; n <- length(x)     c(sum(x - mu) / sigma^2,       -n / sigma + sum((x - mu)^2) / sigma^3)   },   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-8))   ) )  # Simple solve result <- gradient_ascent()(problem, theta0 = c(0, 1)) result$theta.hat #> [1] 5.065030 2.072274"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"sequential-chaining-","dir":"","previous_headings":"Composing Solvers","what":"Sequential Chaining (%>>%)","title":"Compositional Maximum Likelihood Estimation","text":"Chain solvers coarse--fine optimization:","code":"# Grid search -> gradient ascent -> Newton-Raphson strategy <- grid_search(lower = c(-10, 0.5), upper = c(10, 5), n = 5) %>>%   gradient_ascent(max_iter = 50) %>>%   newton_raphson(max_iter = 20)  result <- strategy(problem, theta0 = c(0, 1)) result$theta.hat #>     Var1     Var2  #> 5.065030 2.072274"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"parallel-racing-","dir":"","previous_headings":"Composing Solvers","what":"Parallel Racing (%|%)","title":"Compositional Maximum Likelihood Estimation","text":"Race multiple methods, keep best:","code":"# Try multiple approaches, pick winner by log-likelihood strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()  result <- strategy(problem, theta0 = c(0, 1)) c(result$theta.hat, loglike = result$loglike) #>                             loglike  #>    5.065030    2.072274 -214.758518"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"random-restarts","dir":"","previous_headings":"Composing Solvers","what":"Random Restarts","title":"Compositional Maximum Likelihood Estimation","text":"Escape local optima multiple starting points:","code":"strategy <- with_restarts(   gradient_ascent(),   n = 10,   sampler = uniform_sampler(c(-10, 0.5), c(10, 5)) )  result <- strategy(problem, theta0 = c(0, 1)) result$theta.hat #> [1] 5.065030 2.072274"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"visualization","dir":"","previous_headings":"","what":"Visualization","title":"Compositional Maximum Likelihood Estimation","text":"Track visualize optimization path:  Extract trace data frame custom analysis:","code":"# Enable tracing trace_cfg <- mle_trace(values = TRUE, gradients = TRUE, path = TRUE) result <- gradient_ascent(max_iter = 50)(problem, c(0, 1), trace = trace_cfg)  # Plot convergence plot(result, which = c(\"loglike\", \"gradient\")) path_df <- optimization_path(result) head(path_df) #>   iteration    loglike  grad_norm   theta_1  theta_2 #> 1         1 -1589.3361 2938.86063 0.0000000 1.000000 #> 2         2  -518.7066  334.47435 0.1723467 1.985036 #> 3         3  -344.5384   84.57555 0.5435804 2.913576 #> 4         4  -293.8366   30.83372 1.1733478 3.690360 #> 5         5  -271.7336   18.65296 2.1001220 4.065978 #> 6         6  -254.0618   17.83778 3.0615865 3.791049"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"function-transformers","dir":"","previous_headings":"","what":"Function Transformers","title":"Compositional Maximum Likelihood Estimation","text":"","code":"# Stochastic gradient (mini-batching for large data) loglike_sgd <- with_subsampling(loglike, data = x, subsample_size = 32)  # Regularization loglike_l2 <- with_penalty(loglike, penalty_l2(), lambda = 0.1) loglike_l1 <- with_penalty(loglike, penalty_l1(), lambda = 0.1)"},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"documentation","dir":"","previous_headings":"","what":"Documentation","title":"Compositional Maximum Likelihood Estimation","text":"Full documentation: https://queelius.github.io/compositional.mle/ Getting Started Case Studies Theory Intuition","code":""},{"path":"https://queelius.github.io/compositional.mle/index.html","id":"license","dir":"","previous_headings":"","what":"License","title":"Compositional Maximum Likelihood Estimation","text":"MIT","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":null,"dir":"Reference","previous_headings":"","what":"BFGS Solver — bfgs","title":"BFGS Solver — bfgs","text":"Creates solver using BFGS quasi-Newton method via optim(). BFGS approximates Hessian gradient information, providing second-order-like convergence without computing Hessian directly.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BFGS Solver — bfgs","text":"","code":"bfgs(max_iter = 100L, tol = 1e-08, report = 0L)"},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"BFGS Solver — bfgs","text":"max_iter Maximum number iterations tol Convergence tolerance (passed optim's reltol) report Reporting frequency (0 = reporting)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"BFGS Solver — bfgs","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"BFGS Solver — bfgs","text":"BFGS often good default choice: robust Newton-Raphson (matrix inversion issues) faster gradient ascent (uses curvature information). solver automatically uses score function problem available, otherwise computes gradients numerically.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/bfgs.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BFGS Solver — bfgs","text":"","code":"if (FALSE) { # \\dontrun{ # Basic usage result <- bfgs()(problem, c(0, 1))  # Race BFGS against gradient ascent strategy <- bfgs() %|% gradient_ascent() } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":null,"dir":"Reference","previous_headings":"","what":"Chain Solvers with Early Stopping — chain","title":"Chain Solvers with Early Stopping — chain","text":"Chains multiple solvers sequentially optional early stopping. flexible %>>% operator.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Chain Solvers with Early Stopping — chain","text":"","code":"chain(..., early_stop = NULL)"},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Chain Solvers with Early Stopping — chain","text":"... Solver functions chain early_stop Optional function takes result returns TRUE stop chain early. Default NULL (early stopping).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Chain Solvers with Early Stopping — chain","text":"new solver function runs solvers sequence","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Chain Solvers with Early Stopping — chain","text":"chain runs solvers order, passing result's theta.hat next solver. early_stop provided returns TRUE intermediate result, chain stops early. Common early stopping conditions: Stop converged: function(r) r$converged Stop gradient small: function(r) sqrt(sum(score^2)) < 1e-6 Stop reaching target: function(r) r$loglike > -100","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/chain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Chain Solvers with Early Stopping — chain","text":"","code":"# Chain with early stopping when converged strategy <- chain(   grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 5),   gradient_ascent(max_iter = 50),   newton_raphson(max_iter = 20),   early_stop = function(r) isTRUE(r$converged) )  # Standard chain (no early stopping) strategy <- chain(gradient_ascent(), newton_raphson())"},{"path":"https://queelius.github.io/compositional.mle/reference/clear_cache.html","id":null,"dir":"Reference","previous_headings":"","what":"Clear derivative cache — clear_cache","title":"Clear derivative cache — clear_cache","text":"Clears cached numerical derivatives (score Fisher) mle_problem. useful want force recomputation, example modifying data log-likelihood depends .","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/clear_cache.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Clear derivative cache — clear_cache","text":"","code":"clear_cache(problem)"},{"path":"https://queelius.github.io/compositional.mle/reference/clear_cache.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Clear derivative cache — clear_cache","text":"problem mle_problem object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/clear_cache.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Clear derivative cache — clear_cache","text":"problem object (invisibly), modified place","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/clear_cache.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Clear derivative cache — clear_cache","text":"","code":"if (FALSE) { # \\dontrun{ problem <- mle_problem(loglike, cache_derivatives = TRUE) # ... run some optimization ... clear_cache(problem)  # Force fresh derivative computation } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":null,"dir":"Reference","previous_headings":"","what":"Compose Multiple Solvers Sequentially — compose","title":"Compose Multiple Solvers Sequentially — compose","text":"Chains number solvers sequentially. solver's result becomes starting point next. Alternative using %>>% operator.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compose Multiple Solvers Sequentially — compose","text":"","code":"compose(...)"},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compose Multiple Solvers Sequentially — compose","text":"... Solver functions compose","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compose Multiple Solvers Sequentially — compose","text":"new solver function runs solvers sequence","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compose Multiple Solvers Sequentially — compose","text":"Trace data solvers merged single trace stage boundaries preserved.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compose Multiple Solvers Sequentially — compose","text":"","code":"if (FALSE) { # \\dontrun{ # Three-stage strategy strategy <- compose(   grid_search(n = 5),   gradient_ascent(max_iter = 50),   newton_raphson(max_iter = 20) ) result <- strategy(problem, theta0) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":null,"dir":"Reference","previous_headings":"","what":"Compose Multiple Function Transformations — compose_transforms","title":"Compose Multiple Function Transformations — compose_transforms","text":"Applies transformations right--left (like mathematical composition). allows building complex log-likelihood transformations simple ones.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Compose Multiple Function Transformations — compose_transforms","text":"","code":"compose_transforms(...)"},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Compose Multiple Function Transformations — compose_transforms","text":"... Transformer functions","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Compose Multiple Function Transformations — compose_transforms","text":"Composed transformer function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Compose Multiple Function Transformations — compose_transforms","text":"Note: composing solvers, use compose instead.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compose_transforms.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Compose Multiple Function Transformations — compose_transforms","text":"","code":"if (FALSE) { # \\dontrun{ # Create a composition transform <- compose_transforms(   function(f) with_penalty(f, penalty_l1(), lambda = 0.01),   function(f) with_subsampling(f, data, 50) )  # Apply to log-likelihood loglike_transformed <- transform(loglike)  # Equivalent to: loglike_transformed <- loglike %>%   with_subsampling(data, 50) %>%   with_penalty(penalty_l1(), lambda = 0.01) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":null,"dir":"Reference","previous_headings":"","what":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"Provides composable optimization strategies maximum likelihood estimation (MLE). Solvers first-class functions combine via sequential chaining, parallel racing, random restarts. Implements gradient ascent, Newton-Raphson, quasi-Newton (BFGS), derivative-free methods support constrained optimization tracing. Returns 'mle' objects compatible 'algebraic.mle' downstream analysis. domain-specific language maximum likelihood estimation solvers first-class composable functions. Following SICP principles, solvers combine via sequential chaining, parallel racing, iteration build sophisticated optimization strategies simple primitives.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"the-problem-abstraction","dir":"Reference","previous_headings":"","what":"The Problem Abstraction","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"mle_problem encapsulates statistical estimation problem: Log-likelihood function Optional analytic score Fisher information (computed numerically provided) Domain constraints Metadata (parameter names, observation count)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"solver-factories","dir":"Reference","previous_headings":"","what":"Solver Factories","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"Solver factories return solver functions signature (problem, theta0, trace) -> mle_result: gradient_ascent: First-order gradient method newton_raphson: Second-order Newton's method bfgs: Quasi-Newton BFGS nelder_mead: Derivative-free simplex grid_search: Exhaustive grid search","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"composition-operators","dir":"Reference","previous_headings":"","what":"Composition Operators","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"Combine solvers build complex strategies: %>>%: Sequential chaining (coarse--fine) %|%: Parallel racing (try multiple, pick best) with_restarts: Multiple random starting points","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"tracing","dir":"Reference","previous_headings":"","what":"Tracing","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"mle_trace configures track optimization (values, path, gradients, timing) diagnostics visualization.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"Maintainer: Alexander Towell lex@metafunctor.com (ORCID)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/compositional.mle-package.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"compositional.mle: Compositional Maximum Likelihood Estimation — compositional.mle-package","text":"","code":"if (FALSE) { # \\dontrun{ # Define problem problem <- mle_problem(   loglike = function(theta) sum(dnorm(data, theta[1], theta[2], log = TRUE)),   constraint = mle_constraint(support = function(theta) theta[2] > 0) )  # Simple solve result <- gradient_ascent()(problem, c(0, 1))  # Composed strategy: grid -> gradient -> Newton strategy <- grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 5) %>>%   gradient_ascent() %>>% newton_raphson() result <- strategy(problem, c(0, 1))  # Race different methods strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead() result <- strategy(problem, c(0, 1)) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":null,"dir":"Reference","previous_headings":"","what":"Coordinate Ascent Solver — coordinate_ascent","title":"Coordinate Ascent Solver — coordinate_ascent","text":"Creates solver optimizes one parameter time holding others fixed. useful parameters different scales likelihood decomposes nicely along coordinate directions.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Coordinate Ascent Solver — coordinate_ascent","text":"","code":"coordinate_ascent(   max_cycles = 50L,   tol = 1e-08,   line_search = TRUE,   cycle_order = c(\"sequential\", \"random\"),   verbose = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Coordinate Ascent Solver — coordinate_ascent","text":"max_cycles Maximum number full cycles parameters tol Convergence tolerance log-likelihood change line_search Use line search coordinate (slower robust) cycle_order Order cycling: \"sequential\" (1,2,...,p) \"random\" verbose Logical; TRUE cli package installed, display progress optimization. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Coordinate Ascent Solver — coordinate_ascent","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Coordinate Ascent Solver — coordinate_ascent","text":"cycle consists optimizing coordinate turn using simple golden section search. algorithm converges log-likelihood improvement full cycle less tol. Coordinate ascent can effective : Parameters different scales likelihood axis-aligned ridges Computing full gradient expensive However, may converge slowly problems strong parameter correlations.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/coordinate_ascent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Coordinate Ascent Solver — coordinate_ascent","text":"","code":"# Basic coordinate ascent solver <- coordinate_ascent()  # With more cycles for difficult problems solver <- coordinate_ascent(max_cycles = 100)  # Random cycling to avoid systematic bias solver <- coordinate_ascent(cycle_order = \"random\")"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_line_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Backtracking line search — .backtracking_line_search","title":"Backtracking line search — .backtracking_line_search","text":"Backtracking line search","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_line_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Backtracking line search — .backtracking_line_search","text":"","code":".backtracking_line_search(   loglike,   theta,   direction,   max_step,   backtrack_ratio,   min_step,   constraint )"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_step.html","id":null,"dir":"Reference","previous_headings":"","what":"Backtracking line search step — .backtracking_step","title":"Backtracking line search step — .backtracking_step","text":"Performs backtracking line search find step size improves objective function.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_step.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Backtracking line search step — .backtracking_step","text":"","code":".backtracking_step(   loglike,   direction,   theta_current,   max_step,   constraint,   backtrack_ratio,   max_iter,   min_step,   debug )"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_step.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Backtracking line search step — .backtracking_step","text":"loglike Log-likelihood function direction Search direction vector theta_current Current parameter values max_step Maximum step size constraint Domain constraints backtrack_ratio Backtracking multiplier (0 < r < 1) max_iter Maximum iterations line search min_step Minimum step size threshold debug Print debug information","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-backtracking_step.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Backtracking line search step — .backtracking_step","text":"List success (logical) theta (new parameter values)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-coordinate_line_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Golden section line search along one coordinate — .coordinate_line_search","title":"Golden section line search along one coordinate — .coordinate_line_search","text":"Golden section line search along one coordinate","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-coordinate_line_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Golden section line search along one coordinate — .coordinate_line_search","text":"","code":".coordinate_line_search(   loglike,   theta,   coord,   constraint,   max_iter = 50,   tol = 1e-08 )"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-coordinate_line_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Golden section line search along one coordinate — .coordinate_line_search","text":"loglike Log-likelihood function theta Current parameter vector coord Index coordinate optimize constraint Constraint object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-generate_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate grid of parameter values — .generate_grid","title":"Generate grid of parameter values — .generate_grid","text":"Generate grid parameter values","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-generate_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate grid of parameter values — .generate_grid","text":"","code":".generate_grid(lower, upper, grid_size)"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-generate_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate grid of parameter values — .generate_grid","text":"lower Lower bounds upper Upper bounds grid_size Grid resolution per dimension","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-generate_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate grid of parameter values — .generate_grid","text":"Matrix row parameter vector","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-has_cli.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if cli package is available — .has_cli","title":"Check if cli package is available — .has_cli","text":"Check cli package available","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-has_cli.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if cli package is available — .has_cli","text":"","code":".has_cli()"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-make_convergence_checker.html","id":null,"dir":"Reference","previous_headings":"","what":"Create convergence checker function — .make_convergence_checker","title":"Create convergence checker function — .make_convergence_checker","text":"Create convergence checker function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-make_convergence_checker.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create convergence checker function — .make_convergence_checker","text":"","code":".make_convergence_checker(config)"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-make_convergence_checker.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create convergence checker function — .make_convergence_checker","text":"config Configuration object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-make_convergence_checker.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create convergence checker function — .make_convergence_checker","text":"Function checks convergence","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-mle_optimize_direction.html","id":null,"dir":"Reference","previous_headings":"","what":"Internal direction-based optimizer — .mle_optimize_direction","title":"Internal direction-based optimizer — .mle_optimize_direction","text":"Core optimization algorithm used gradient-based solvers. internal function meant called directly users.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-mle_optimize_direction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Internal direction-based optimizer — .mle_optimize_direction","text":"","code":".mle_optimize_direction(   loglike,   direction_fn,   theta0,   config,   constraint,   use_linesearch )"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-mle_optimize_direction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Internal direction-based optimizer — .mle_optimize_direction","text":"loglike Log-likelihood function direction_fn Function computing search direction theta0 Initial parameters config Configuration object (mle_config subclass) constraint Domain constraints (mle_constraint object) use_linesearch Whether use backtracking line search","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-mle_optimize_direction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Internal direction-based optimizer — .mle_optimize_direction","text":"List optim()-compatible format: par Final parameter estimates value Log-likelihood solution convergence 0 converged, 1 otherwise iterations Number iterations taken path Optimization path (trace=TRUE)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-mle_optimize_direction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Internal direction-based optimizer — .mle_optimize_direction","text":"Returns optim()-compatible list can passed algebraic.mle::mle_numerical().","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-print_iteration.html","id":null,"dir":"Reference","previous_headings":"","what":"Print iteration information — .print_iteration","title":"Print iteration information — .print_iteration","text":"Print iteration information","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-print_iteration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print iteration information — .print_iteration","text":"","code":".print_iteration(iter, theta, direction, loglike)"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-print_iteration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print iteration information — .print_iteration","text":"iter Iteration number theta Current parameters direction Search direction loglike Log-likelihood function (can NULL)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-progress_handler.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a progress handler for optimization — .progress_handler","title":"Create a progress handler for optimization — .progress_handler","text":"Create progress handler optimization","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-progress_handler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a progress handler for optimization — .progress_handler","text":"","code":".progress_handler(   verbose = FALSE,   solver_name = \"Solver\",   max_iter = NULL,   show_every = 1L )"},{"path":"https://queelius.github.io/compositional.mle/reference/dot-progress_handler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a progress handler for optimization — .progress_handler","text":"verbose Logical; whether show progress solver_name Name solver display max_iter Maximum iterations (progress bar) show_every Show progress every N iterations","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/dot-progress_handler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a progress handler for optimization — .progress_handler","text":"list start(), update(), finish() functions","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/finalize_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Finalize trace recorder into trace data — finalize_trace","title":"Finalize trace recorder into trace data — finalize_trace","text":"Finalize trace recorder trace data","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/finalize_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Finalize trace recorder into trace data — finalize_trace","text":"","code":"finalize_trace(recorder)"},{"path":"https://queelius.github.io/compositional.mle/reference/finalize_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Finalize trace recorder into trace data — finalize_trace","text":"recorder Trace recorder","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/finalize_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Finalize trace recorder into trace data — finalize_trace","text":"List trace data NULL","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/fisher_scoring.html","id":null,"dir":"Reference","previous_headings":"","what":"Fisher Scoring Solver — fisher_scoring","title":"Fisher Scoring Solver — fisher_scoring","text":"Variant Newton-Raphson uses expected Fisher information instead observed Fisher. Can stable problems.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/fisher_scoring.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fisher Scoring Solver — fisher_scoring","text":"","code":"fisher_scoring(   line_search = TRUE,   max_iter = 50L,   tol = 1e-08,   backtrack_ratio = 0.5,   min_step = 1e-12,   verbose = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/fisher_scoring.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fisher Scoring Solver — fisher_scoring","text":"line_search Use backtracking line search stability max_iter Maximum number iterations tol Convergence tolerance (parameter change) backtrack_ratio Step size reduction factor line search min_step Minimum step size giving verbose Logical; TRUE cli package installed, display progress optimization. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/fisher_scoring.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fisher Scoring Solver — fisher_scoring","text":"solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/fisher_scoring.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fisher Scoring Solver — fisher_scoring","text":"Fisher scoring identical Newton-Raphson expected observed Fisher information equal (e.g., exponential families). models, may different convergence properties.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_fisher.html","id":null,"dir":"Reference","previous_headings":"","what":"Get Fisher information function from problem — get_fisher","title":"Get Fisher information function from problem — get_fisher","text":"Returns Fisher information matrix function, computing numerically provided. cache_derivatives = TRUE set problem Fisher computed numerically, results cached using single-value cache.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_fisher.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get Fisher information function from problem — get_fisher","text":"","code":"get_fisher(problem)"},{"path":"https://queelius.github.io/compositional.mle/reference/get_fisher.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get Fisher information function from problem — get_fisher","text":"problem mle_problem object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_fisher.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get Fisher information function from problem — get_fisher","text":"Fisher information function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_score.html","id":null,"dir":"Reference","previous_headings":"","what":"Get score function from problem — get_score","title":"Get score function from problem — get_score","text":"Returns score (gradient) function, computing numerically provided. cache_derivatives = TRUE set problem score computed numerically, results cached using single-value cache.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_score.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get score function from problem — get_score","text":"","code":"get_score(problem)"},{"path":"https://queelius.github.io/compositional.mle/reference/get_score.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get score function from problem — get_score","text":"problem mle_problem object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/get_score.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get score function from problem — get_score","text":"Score function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":null,"dir":"Reference","previous_headings":"","what":"Gradient Ascent Solver — gradient_ascent","title":"Gradient Ascent Solver — gradient_ascent","text":"Creates solver uses gradient ascent (steepest ascent) find MLE. Optionally uses backtracking line search adaptive step sizes.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Gradient Ascent Solver — gradient_ascent","text":"","code":"gradient_ascent(   learning_rate = 1,   line_search = TRUE,   max_iter = 100L,   tol = 1e-08,   backtrack_ratio = 0.5,   min_step = 1e-12,   verbose = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Gradient Ascent Solver — gradient_ascent","text":"learning_rate Base learning rate / maximum step size line_search Use backtracking line search adaptive step sizes max_iter Maximum number iterations tol Convergence tolerance (parameter change) backtrack_ratio Step size reduction factor line search (0 < r < 1) min_step Minimum step size giving verbose Logical; TRUE cli package installed, display progress optimization. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Gradient Ascent Solver — gradient_ascent","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Gradient Ascent Solver — gradient_ascent","text":"Gradient ascent iteratively moves direction score (gradient log-likelihood). line search enabled, step size adaptively chosen ensure log-likelihood increases. solver respects constraints defined problem via projection.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/gradient_ascent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Gradient Ascent Solver — gradient_ascent","text":"","code":"# Create a solver with default parameters solver <- gradient_ascent()  # Create a solver with custom parameters solver <- gradient_ascent(   learning_rate = 0.5,   max_iter = 500,   tol = 1e-10 )  # Without line search (fixed step size) solver <- gradient_ascent(learning_rate = 0.01, line_search = FALSE)"},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Sequential Solver Composition — %>>%","title":"Sequential Solver Composition — %>>%","text":"Chains two solvers sequentially. result first solver becomes starting point second. enables coarse--fine strategies.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sequential Solver Composition — %>>%","text":"","code":"s1 %>>% s2"},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sequential Solver Composition — %>>%","text":"s1 First solver function s2 Second solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sequential Solver Composition — %>>%","text":"new solver function runs s1 s2","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Sequential Solver Composition — %>>%","text":"Trace data solvers chain merged single trace stage boundaries preserved.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-greater-than-greater-than-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Sequential Solver Composition — %>>%","text":"","code":"# Coarse-to-fine: grid search to find good region, then gradient ascent strategy <- grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 5) %>>%   gradient_ascent()  # Three-stage refinement strategy <- grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 3) %>>%   gradient_ascent() %>>%   newton_raphson()"},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel Solver Racing — %|%","title":"Parallel Solver Racing — %|%","text":"Runs multiple solvers returns best result (highest log-likelihood). Useful unsure method work best given problem.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel Solver Racing — %|%","text":"","code":"s1 %|% s2"},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-grapes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel Solver Racing — %|%","text":"s1 First solver function s2 Second solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-grapes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel Solver Racing — %|%","text":"new solver function runs picks best","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-grapes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel Solver Racing — %|%","text":"","code":"# Race gradient-based vs derivative-free strategy <- gradient_ascent() %|% nelder_mead()  # Race multiple methods strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()"},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-or-grapes.html","id":null,"dir":"Reference","previous_headings":"","what":"Null coalescing operator — %||%","title":"Null coalescing operator — %||%","text":"Null coalescing operator","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grapes-or-or-grapes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Null coalescing operator — %||%","text":"","code":"x %||% y"},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Grid Search Solver — grid_search","title":"Grid Search Solver — grid_search","text":"Creates solver evaluates log-likelihood grid points returns best. Useful finding good starting points low-dimensional problems.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Grid Search Solver — grid_search","text":"","code":"grid_search(lower, upper, n = 10L)"},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Grid Search Solver — grid_search","text":"lower Lower bounds grid upper Upper bounds grid n Number points per dimension (scalar vector)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Grid Search Solver — grid_search","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Grid Search Solver — grid_search","text":"Grid search deterministic exhaustive within bounds. useful 1-3 dimensional problems first stage multi-stage strategy (e.g., grid_search theta0 argument ignored; grid determined lower/upper/n. Points outside problem's constraint support skipped.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/grid_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Grid Search Solver — grid_search","text":"","code":"if (FALSE) { # \\dontrun{ # Simple grid search solver <- grid_search(lower = c(-10, 0.1), upper = c(10, 5), n = 20) result <- solver(problem, c(0, 1))  # Coarse-to-fine: grid then gradient strategy <- grid_search(c(-10, 0.1), c(10, 5), n = 5) %>>% gradient_ascent() } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/is_converged.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if solver converged — is_converged","title":"Check if solver converged — is_converged","text":"Check solver converged","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_converged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if solver converged — is_converged","text":"","code":"is_converged(x, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_converged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if solver converged — is_converged","text":"x mle result object ... Additional arguments (unused)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_converged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if solver converged — is_converged","text":"Logical indicating convergence","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is an mle_config — is_mle_config","title":"Check if object is an mle_config — is_mle_config","text":"Check object mle_config","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is an mle_config — is_mle_config","text":"","code":"is_mle_config(x)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is an mle_config — is_mle_config","text":"x Object test","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is an mle_config — is_mle_config","text":"Logical","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is an mle_constraint — is_mle_constraint","title":"Check if object is an mle_constraint — is_mle_constraint","text":"Check object mle_constraint","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is an mle_constraint — is_mle_constraint","text":"","code":"is_mle_constraint(x)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is an mle_constraint — is_mle_constraint","text":"x Object test","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_constraint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is an mle_constraint — is_mle_constraint","text":"Logical","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_numerical.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is an mle_numerical — is_mle_numerical","title":"Check if object is an mle_numerical — is_mle_numerical","text":"Check object mle_numerical","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_numerical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is an mle_numerical — is_mle_numerical","text":"","code":"is_mle_numerical(x)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_numerical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is an mle_numerical — is_mle_numerical","text":"x Object test","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_numerical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is an mle_numerical — is_mle_numerical","text":"Logical","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_problem.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if object is an mle_problem — is_mle_problem","title":"Check if object is an mle_problem — is_mle_problem","text":"Check object mle_problem","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_problem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if object is an mle_problem — is_mle_problem","text":"","code":"is_mle_problem(x)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_problem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if object is an mle_problem — is_mle_problem","text":"x Object test","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_mle_problem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if object is an mle_problem — is_mle_problem","text":"Logical","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_tracing.html","id":null,"dir":"Reference","previous_headings":"","what":"Check if tracing is enabled — is_tracing","title":"Check if tracing is enabled — is_tracing","text":"Check tracing enabled","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_tracing.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check if tracing is enabled — is_tracing","text":"","code":"is_tracing(trace)"},{"path":"https://queelius.github.io/compositional.mle/reference/is_tracing.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Check if tracing is enabled — is_tracing","text":"trace mle_trace object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/is_tracing.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Check if tracing is enabled — is_tracing","text":"Logical indicating tracing enabled","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":null,"dir":"Reference","previous_headings":"","what":"L-BFGS-B Solver (Box Constrained) — lbfgsb","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"Creates solver using L-BFGS-B, limited-memory BFGS variant supports box constraints (lower upper bounds parameters).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"","code":"lbfgsb(lower = -Inf, upper = Inf, max_iter = 100L, tol = 1e-08)"},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"lower Lower bounds parameters (can -Inf) upper Upper bounds parameters (can Inf) max_iter Maximum number iterations tol Convergence tolerance","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"Unlike constraint system mle_problem (uses projection), L-BFGS-B handles box constraints natively within algorithm. Use simple bound constraints.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/lbfgsb.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L-BFGS-B Solver (Box Constrained) — lbfgsb","text":"","code":"if (FALSE) { # \\dontrun{ # Positive parameters only solver <- lbfgsb(lower = c(-Inf, 0), upper = c(Inf, Inf)) result <- solver(problem, c(0, 1)) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/merge_traces.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge trace data from multiple results — merge_traces","title":"Merge trace data from multiple results — merge_traces","text":"Concatenates trace data sequence results (e.g., composed solvers). merged trace preserves stage boundaries later analysis.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/merge_traces.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge trace data from multiple results — merge_traces","text":"","code":"merge_traces(results)"},{"path":"https://queelius.github.io/compositional.mle/reference/merge_traces.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge trace data from multiple results — merge_traces","text":"results List mle_numerical results trace_data","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/merge_traces.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge trace data from multiple results — merge_traces","text":"merged mle_trace_data object stage information","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config.html","id":null,"dir":"Reference","previous_headings":"","what":"Create optimization configuration — mle_config","title":"Create optimization configuration — mle_config","text":"Creates base configuration object MLE optimization algorithms. object stores convergence criteria debugging options.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create optimization configuration — mle_config","text":"","code":"mle_config(   max_iter = 100L,   abs_tol = NULL,   rel_tol = 1e-05,   trace = FALSE,   debug = FALSE,   debug_freq = 1L )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create optimization configuration — mle_config","text":"max_iter Maximum iterations (integer, default: 100) abs_tol Absolute tolerance (numeric NULL, default: NULL use rel_tol) rel_tol Relative tolerance (numeric, default: 1e-5) trace Store optimization path (logical, default: FALSE) debug Print debug information (logical, default: FALSE) debug_freq Debug output frequency (integer, default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create optimization configuration — mle_config","text":"mle_config object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create optimization configuration — mle_config","text":"","code":"# Basic configuration config <- mle_config(max_iter = 200, rel_tol = 1e-6)  # Configuration with tracing config <- mle_config(trace = TRUE, debug = TRUE)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_gradient.html","id":null,"dir":"Reference","previous_headings":"","what":"Create gradient-based optimization configuration — mle_config_gradient","title":"Create gradient-based optimization configuration — mle_config_gradient","text":"Extends base configuration gradient-specific parameters like learning rate distance metric.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_gradient.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create gradient-based optimization configuration — mle_config_gradient","text":"","code":"mle_config_gradient(   eta = 1,   norm = function(x) max(abs(x)),   max_iter = 100L,   abs_tol = NULL,   rel_tol = 1e-05,   trace = FALSE,   debug = FALSE,   debug_freq = 1L )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_gradient.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create gradient-based optimization configuration — mle_config_gradient","text":"eta Learning rate / step size (numeric, default: 1.0) norm Distance measure function (default: max absolute value) max_iter Maximum iterations (integer, default: 100) abs_tol Absolute tolerance (numeric NULL, default: NULL use rel_tol) rel_tol Relative tolerance (numeric, default: 1e-5) trace Store optimization path (logical, default: FALSE) debug Print debug information (logical, default: FALSE) debug_freq Debug output frequency (integer, default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_gradient.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create gradient-based optimization configuration — mle_config_gradient","text":"mle_config_gradient object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_gradient.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create gradient-based optimization configuration — mle_config_gradient","text":"","code":"# Basic gradient configuration config <- mle_config_gradient(eta = 0.1, max_iter = 500)  # With custom norm (L2 norm) config <- mle_config_gradient(   eta = 0.01,   norm = function(x) sqrt(sum(x^2)) )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_linesearch.html","id":null,"dir":"Reference","previous_headings":"","what":"Create line search configuration — mle_config_linesearch","title":"Create line search configuration — mle_config_linesearch","text":"Extends gradient configuration backtracking line search parameters. Line search adaptively finds step sizes improve objective.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_linesearch.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create line search configuration — mle_config_linesearch","text":"","code":"mle_config_linesearch(   max_step = 1,   backtrack_ratio = 0.5,   max_iter_ls = 10L,   min_step = 1e-08,   norm = function(x) max(abs(x)),   max_iter = 100L,   abs_tol = NULL,   rel_tol = 1e-05,   trace = FALSE,   debug = FALSE,   debug_freq = 1L )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_linesearch.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create line search configuration — mle_config_linesearch","text":"max_step Maximum step size per iteration (numeric, default: 1.0) backtrack_ratio Backtracking multiplier, must (0,1) (default: 0.5) max_iter_ls Maximum line search iterations (integer, default: 10) min_step Minimum step size threshold (numeric, default: 1e-8) norm Distance measure function (default: max absolute value) max_iter Maximum iterations (integer, default: 100) abs_tol Absolute tolerance (numeric NULL, default: NULL use rel_tol) rel_tol Relative tolerance (numeric, default: 1e-5) trace Store optimization path (logical, default: FALSE) debug Print debug information (logical, default: FALSE) debug_freq Debug output frequency (integer, default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_linesearch.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create line search configuration — mle_config_linesearch","text":"mle_config_linesearch object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_config_linesearch.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create line search configuration — mle_config_linesearch","text":"","code":"# Conservative line search config <- mle_config_linesearch(   max_step = 0.5,   backtrack_ratio = 0.8 )  # Aggressive line search config <- mle_config_linesearch(   max_step = 10.0,   backtrack_ratio = 0.3,   max_iter_ls = 20 )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Create domain constraint specification — mle_constraint","title":"Create domain constraint specification — mle_constraint","text":"Specifies domain constraints optimization. support function checks parameters valid, project function maps invalid parameters back valid ones.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create domain constraint specification — mle_constraint","text":"","code":"mle_constraint(support = function(theta) TRUE, project = function(theta) theta)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create domain constraint specification — mle_constraint","text":"support Function testing theta support (returns TRUE/FALSE) project Function projecting theta onto support","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_constraint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create domain constraint specification — mle_constraint","text":"mle_constraint object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_constraint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create domain constraint specification — mle_constraint","text":"","code":"# Positive parameters only constraint <- mle_constraint(   support = function(theta) all(theta > 0),   project = function(theta) pmax(theta, 1e-8) )  # Parameters in [0, 1] constraint <- mle_constraint(   support = function(theta) all(theta >= 0 & theta <= 1),   project = function(theta) pmax(0, pmin(1, theta)) )  # No constraints (default) constraint <- mle_constraint()"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grad.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick gradient ascent with sensible defaults — mle_grad","title":"Quick gradient ascent with sensible defaults — mle_grad","text":"Convenience wrapper mle_gradient_ascent simplified interface. Automatically enables line search better convergence.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick gradient ascent with sensible defaults — mle_grad","text":"","code":"mle_grad(loglike, score, theta0, use_linesearch = TRUE, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick gradient ascent with sensible defaults — mle_grad","text":"loglike Log-likelihood function score Score function (gradient) theta0 Initial parameters use_linesearch Use backtracking line search (default: TRUE) ... Additional config parameters passed mle_config_linesearch mle_config_gradient","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick gradient ascent with sensible defaults — mle_grad","text":"mle_gradient_ascent object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quick gradient ascent with sensible defaults — mle_grad","text":"","code":"if (FALSE) { # \\dontrun{ # Quick usage with defaults result <- mle_grad(loglike, score, theta0 = c(0, 1))  # Override config parameters result <- mle_grad(   loglike, score, theta0 = c(0, 1),   max_iter = 200,   rel_tol = 1e-6 )  # Without line search result <- mle_grad(   loglike, score, theta0 = c(0, 1),   use_linesearch = FALSE,   eta = 0.1 ) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_gradient_ascent.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","title":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","text":"Performs gradient ascent optimization find MLE. method uses score function (gradient log-likelihood) iteratively improve parameter estimates.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_gradient_ascent.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","text":"","code":"mle_gradient_ascent(   loglike,   score,   theta0,   config = mle_config_gradient(),   constraint = mle_constraint() )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_gradient_ascent.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","text":"loglike Log-likelihood function taking theta input score Score function (gradient log-likelihood) taking theta input theta0 Initial parameter guess (numeric vector) config Configuration object (mle_config_gradient mle_config_linesearch). Use mle_config_linesearch() adaptive step sizes (recommended), mle_config_gradient() fixed step size. constraint Optional domain constraints (mle_constraint object)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_gradient_ascent.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","text":"mle_numerical object (algebraic.mle) class mle_gradient_ascent   containing standard mle fields plus: converged Convergence status (logical) sol Raw optimization result optim()-compatible fields:     par, value, convergence, iterations config Configuration used path Optimization path (trace=TRUE config)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_gradient_ascent.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum likelihood estimation via gradient ascent — mle_gradient_ascent","text":"","code":"if (FALSE) { # \\dontrun{ # Normal distribution MLE data <- rnorm(100, mean = 5, sd = 2)  loglike <- function(theta) {   sum(dnorm(data, mean = theta[1], sd = theta[2], log = TRUE)) }  score <- function(theta) {   mu <- theta[1]   sigma <- theta[2]   c(     sum((data - mu) / sigma^2),     sum((data - mu)^2 / sigma^3 - 1/sigma)   ) }  # With line search (recommended) result <- mle_gradient_ascent(   loglike = loglike,   score = score,   theta0 = c(0, 1),   config = mle_config_linesearch(max_step = 1.0) )  # With fixed step size result <- mle_gradient_ascent(   loglike = loglike,   score = score,   theta0 = c(0, 1),   config = mle_config_gradient(eta = 0.1) )  # With constraints (positive variance only) constraint <- mle_constraint(   support = function(theta) theta[2] > 0,   project = function(theta) c(theta[1], max(theta[2], 1e-8)) )  result <- mle_gradient_ascent(   loglike = loglike,   score = score,   theta0 = c(0, 1),   config = mle_config_linesearch(),   constraint = constraint )  # Check convergence print(result$converged) print(result$theta.hat) print(result$score)  # Should be near zero } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grid_search.html","id":null,"dir":"Reference","previous_headings":"","what":"MLE via grid search — mle_grid_search","title":"MLE via grid search — mle_grid_search","text":"Performs exhaustive grid search bounded parameter space. Optionally refines grid point using local solver.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grid_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLE via grid search — mle_grid_search","text":"","code":"mle_grid_search(loglike, lower, upper, grid_size, refine_solver = NULL, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grid_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLE via grid search — mle_grid_search","text":"loglike Log-likelihood function lower Lower bounds parameters (numeric vector) upper Upper bounds parameters (numeric vector) grid_size Grid resolution. Either single integer (resolution per dimension) vector integers (one per dimension). refine_solver Optional local solver refine grid point. NULL, evaluates loglike grid points without refinement. ... Additional arguments passed refine_solver","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grid_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLE via grid search — mle_grid_search","text":"mle object best solution found, including: theta.hat Best parameter estimate loglike Log-likelihood best point grid_size Grid resolution used n_evaluated Number grid points evaluated","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_grid_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MLE via grid search — mle_grid_search","text":"","code":"if (FALSE) { # \\dontrun{ # Simple grid search without refinement loglike <- function(theta) {   -(theta[1]^2 + theta[2]^2) }  result <- mle_grid_search(   loglike = loglike,   lower = c(-5, -5),   upper = c(5, 5),   grid_size = 20 )  # Grid search with local refinement score <- function(theta) {   -2 * theta }  result <- mle_grid_search(   loglike = loglike,   lower = c(-5, -5),   upper = c(5, 5),   grid_size = 10,   refine_solver = mle_gradient_ascent,   score = score,   config = mle_config_gradient(eta = 0.1, max_iter = 20) )  # Different resolution per dimension result <- mle_grid_search(   loglike = loglike,   lower = c(-5, -5),   upper = c(5, 5),   grid_size = c(20, 10)  # 20 points in dim 1, 10 in dim 2 ) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_local_search — mle_local_search","title":"mle_local_search — mle_local_search","text":"Performs local search find MLE, assuming MLE interior point support initial guess `theta0` near MLE provided. Use global search method like `sim_anneal` find good initial guess.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_local_search — mle_local_search","text":"","code":"mle_local_search(dir, theta0, loglike = NULL, options = list())"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mle_local_search — mle_local_search","text":"dir function, promising direction function theta0 numeric, initial guess options list, options local search, see function description.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mle_local_search — mle_local_search","text":"`mle` object additional attributes `iter` `converged`         optionally `path` `trace` TRUE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":"functions","dir":"Reference","previous_headings":"","what":"Functions","title":"mle_local_search — mle_local_search","text":"mle_local_search(): options","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_local_search.html","id":"fields","dir":"Reference","previous_headings":"","what":"Fields","title":"mle_local_search — mle_local_search","text":"sup function, domain support log-likelihood eta numeric, learning rate, defaults 1 max_iter integer, maximum number iterations, defaults 1000 max_iter_ls integer, maximum number iterations line search, defaults 1000 abs_tol numeric, tolerance convergence, defaults NULL (use rel_tol instead) rel_tol numeric, relative tolerance convergence, defaults 1e-5 r numeric, backtracking line search parameter, defaults 0.5 proj function, projection function enforce domain support norm function, distance measure convergence checks, defaults infinity norm. debug logical, output debugging information TRUE; default FALSE trace logical, TRUE store path search `path` attribute output; default FALSE line_search logical, TRUE, perform line search; default TRUE case, learning rate `eta` refers maximum step size can taken per iteration. debug_freq integer, frequency debug output, defaults 1","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_newton_raphson.html","id":null,"dir":"Reference","previous_headings":"","what":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","title":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","text":"Performs Newton-Raphson optimization find MLE. second-order method uses score (gradient) Fisher information matrix (Hessian) achieve faster convergence gradient ascent.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_newton_raphson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","text":"","code":"mle_newton_raphson(   loglike,   score,   fisher,   theta0,   config = mle_config_linesearch(),   constraint = mle_constraint(),   inverted = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_newton_raphson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","text":"loglike Log-likelihood function taking theta input score Score function (gradient log-likelihood) taking theta input fisher Fisher information matrix function. Either FIM inverse (covariance matrix), depending inverted parameter. theta0 Initial parameter guess (numeric vector) config Configuration object (typically mle_config_linesearch). Newton-Raphson benefits line search ensure stability. constraint Optional domain constraints (mle_constraint object) inverted Logical. TRUE, fisher covariance matrix (inverse FIM). FALSE (default), fisher FIM.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_newton_raphson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","text":"mle_numerical object (algebraic.mle) class mle_newton_raphson   containing standard mle fields plus: converged Convergence status (logical) sol Raw optimization result optim()-compatible fields config Configuration used path Optimization path (trace=TRUE config)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_newton_raphson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Maximum likelihood estimation via Newton-Raphson — mle_newton_raphson","text":"","code":"if (FALSE) { # \\dontrun{ # Normal distribution MLE with Newton-Raphson data <- rnorm(100, mean = 5, sd = 2)  loglike <- function(theta) {   sum(dnorm(data, mean = theta[1], sd = theta[2], log = TRUE)) }  score <- function(theta) {   mu <- theta[1]   sigma <- theta[2]   c(     sum((data - mu) / sigma^2),     sum((data - mu)^2 / sigma^3 - 1/sigma)   ) }  fisher <- function(theta) {   n <- length(data)   sigma <- theta[2]   matrix(c(     n / sigma^2, 0,     0, 2*n / sigma^2   ), nrow = 2) }  # Standard usage with FIM result <- mle_newton_raphson(   loglike = loglike,   score = score,   fisher = fisher,   theta0 = c(0, 1),   config = mle_config_linesearch() )  # Using inverted FIM (covariance matrix) covariance <- function(theta) {   MASS::ginv(fisher(theta)) }  result <- mle_newton_raphson(   loglike = loglike,   score = score,   fisher = covariance,   theta0 = c(0, 1),   inverted = TRUE )  # With constraints constraint <- mle_constraint(   support = function(theta) theta[2] > 0,   project = function(theta) c(theta[1], max(theta[2], 1e-8)) )  result <- mle_newton_raphson(   loglike = loglike,   score = score,   fisher = fisher,   theta0 = c(0, 1),   config = mle_config_linesearch(),   constraint = constraint )  # Faster convergence than gradient ascent print(result$iter)  # Typically fewer iterations print(result$score)  # Should be very close to zero } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_nr.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick Newton-Raphson with sensible defaults — mle_nr","title":"Quick Newton-Raphson with sensible defaults — mle_nr","text":"Convenience wrapper mle_newton_raphson simplified interface. Always uses line search stability (recommended Newton-Raphson).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_nr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick Newton-Raphson with sensible defaults — mle_nr","text":"","code":"mle_nr(loglike, score, fisher, theta0, inverted = FALSE, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_nr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick Newton-Raphson with sensible defaults — mle_nr","text":"loglike Log-likelihood function score Score function fisher Fisher information covariance function theta0 Initial parameters inverted fisher covariance matrix? (default: FALSE) ... Additional config parameters passed mle_config_linesearch","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_nr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick Newton-Raphson with sensible defaults — mle_nr","text":"mle_newton_raphson object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_nr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quick Newton-Raphson with sensible defaults — mle_nr","text":"","code":"if (FALSE) { # \\dontrun{ # Quick usage with Fisher information matrix result <- mle_nr(loglike, score, fisher, theta0 = c(0, 1))  # With covariance matrix (inverted FIM) result <- mle_nr(   loglike, score, covariance,   theta0 = c(0, 1),   inverted = TRUE )  # Override config result <- mle_nr(   loglike, score, fisher,   theta0 = c(0, 1),   max_iter = 50,   max_step = 0.5 ) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_numerical.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_numerical — mle_numerical","title":"mle_numerical — mle_numerical","text":"constructor mle_numerical class.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_numerical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_numerical — mle_numerical","text":"","code":"mle_numerical(theta.hat, loglike, score, info, sigma, iter, converged)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_optim.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_optim — mle_optim","title":"mle_optim — mle_optim","text":"function takes output `optim` turns `mle` object.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_optim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_optim — mle_optim","text":"","code":"mle_optim(sol)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_optim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mle_optim — mle_optim","text":"sol output `optim`","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_optim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"mle_optim — mle_optim","text":"`numerical_mle` object, specialized `optim` (stats package) solutions.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":null,"dir":"Reference","previous_headings":"","what":"Create an MLE Problem Specification — mle_problem","title":"Create an MLE Problem Specification — mle_problem","text":"Encapsulates maximum likelihood estimation problem, separating statistical specification optimization strategy.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create an MLE Problem Specification — mle_problem","text":"","code":"mle_problem(   loglike,   score = NULL,   fisher = NULL,   constraint = NULL,   theta_names = NULL,   n_obs = NULL,   cache_derivatives = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create an MLE Problem Specification — mle_problem","text":"loglike Log-likelihood function taking parameter vector theta score Score function (gradient log-likelihood). NULL, computed numerically via numDeriv::grad needed. fisher Fisher information matrix function. NULL, computed numerically via numDeriv::hessian needed. constraint Domain constraints mle_constraint object theta_names Character vector parameter names nice output n_obs Number observations (AIC/BIC computation) cache_derivatives Logical; TRUE score/fisher computed numerically, cache recent result avoid redundant computation. particularly useful line search point may evaluated multiple times. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create an MLE Problem Specification — mle_problem","text":"mle_problem object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Create an MLE Problem Specification — mle_problem","text":"problem object provides lazy evaluation derivatives. provide analytic score fisher functions, computed numerically requested. cache_derivatives = TRUE, numerical derivatives cached using single-value cache (stores recent theta result). efficient optimization consecutive calls often evaluate point (e.g., line search convergence checking). Use clear_cache manually clear cache needed.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_problem.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create an MLE Problem Specification — mle_problem","text":"","code":"# With analytic derivatives problem <- mle_problem(   loglike = function(theta) sum(dnorm(data, theta[1], theta[2], log = TRUE)),   score = function(theta) {     c(sum(data - theta[1]) / theta[2]^2,       -length(data)/theta[2] + sum((data - theta[1])^2) / theta[2]^3)   },   constraint = mle_constraint(     support = function(theta) theta[2] > 0,     project = function(theta) c(theta[1], max(theta[2], 1e-8))   ),   theta_names = c(\"mu\", \"sigma\") )  # Without analytic derivatives (computed numerically) problem <- mle_problem(   loglike = function(theta) sum(dnorm(data, theta[1], theta[2], log = TRUE)),   constraint = mle_constraint(     support = function(theta) theta[2] > 0   ) )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_restart.html","id":null,"dir":"Reference","previous_headings":"","what":"MLE via random restarts — mle_random_restart","title":"MLE via random restarts — mle_random_restart","text":"Attempts find global maximum running local solver multiple random starting points. helps escape local maxima find better solutions likelihood surface multimodal.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_restart.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"MLE via random restarts — mle_random_restart","text":"","code":"mle_random_restart(loglike, solver, theta0_sampler, n_trials = 100L, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_restart.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"MLE via random restarts — mle_random_restart","text":"loglike Log-likelihood function solver Solver function (e.g., mle_gradient_ascent, mle_newton_raphson). Must accept loglike, theta0, additional arguments. theta0_sampler Function generating random initial parameters. Called without arguments, must return valid theta0 vector. n_trials Number random trials perform (integer, default: 100) ... Additional arguments passed solver","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_restart.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"MLE via random restarts — mle_random_restart","text":"Best mle object found across trials, additional attribute   n_trials indicating number trials performed.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_restart.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"MLE via random restarts — mle_random_restart","text":"","code":"if (FALSE) { # \\dontrun{ # Multimodal likelihood with multiple local maxima loglike <- function(theta) {   # Mixture of two peaks   -((theta[1]-5)^2 + (theta[2]-5)^2) / 10 -    ((theta[1]+3)^2 + (theta[2]+3)^2) / 10 }  score <- function(theta) {   c(     -(theta[1]-5) / 5 - (theta[1]+3) / 5,     -(theta[2]-5) / 5 - (theta[2]+3) / 5   ) }  # Random sampler for initial points sampler <- function() {   runif(2, min = -10, max = 10) }  # Try 50 random starting points result <- mle_random_restart(   loglike = loglike,   solver = mle_gradient_ascent,   theta0_sampler = sampler,   n_trials = 50,   score = score,   config = mle_config_linesearch(max_iter = 50) )  print(result$theta.hat) print(result$loglike) print(result$n_trials) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_search.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_random_search — mle_random_search","title":"mle_random_search — mle_random_search","text":"MLE method using random search","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_random_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_random_search — mle_random_search","text":"","code":"mle_random_search(rtheta, loglike, options)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_sim_anneal.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_sim_anneal — mle_sim_anneal","title":"mle_sim_anneal — mle_sim_anneal","text":"function takes output `sim_anneal` turns `mle` object.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_sim_anneal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_sim_anneal — mle_sim_anneal","text":"","code":"mle_sim_anneal(theta0, loglike = NULL, options = list())"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_solve.html","id":null,"dir":"Reference","previous_headings":"","what":"mle_solve — mle_solve","title":"mle_solve — mle_solve","text":"Uses various functions algorithms find MLE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_solve.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"mle_solve — mle_solve","text":"","code":"mle_solve(options, theta0, method = c(\"optim\"), ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_solve.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"mle_solve — mle_solve","text":"theta0 numeric vector, initial guess MLE","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_trace.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a Trace Configuration — mle_trace","title":"Create a Trace Configuration — mle_trace","text":"Specifies information track optimization.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_trace.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a Trace Configuration — mle_trace","text":"","code":"mle_trace(   values = FALSE,   path = FALSE,   gradients = FALSE,   timing = FALSE,   every = 1L )"},{"path":"https://queelius.github.io/compositional.mle/reference/mle_trace.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a Trace Configuration — mle_trace","text":"values Track log-likelihood values iteration path Track parameter values iteration gradients Track gradient norms iteration timing Track wall-clock time every Record every nth iteration (1 = iterations)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_trace.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a Trace Configuration — mle_trace","text":"mle_trace configuration object","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/mle_trace.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create a Trace Configuration — mle_trace","text":"","code":"# Track everything trace <- mle_trace(values = TRUE, path = TRUE, gradients = TRUE)  # Minimal tracing (just convergence path) trace <- mle_trace(values = TRUE)  # Sample every 10th iteration for long runs trace <- mle_trace(values = TRUE, path = TRUE, every = 10)"},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":null,"dir":"Reference","previous_headings":"","what":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"Creates solver using Nelder-Mead simplex method via optim(). derivative-free method useful gradients unavailable unreliable.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"","code":"nelder_mead(max_iter = 500L, tol = 1e-08)"},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"max_iter Maximum number iterations tol Convergence tolerance","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"Nelder-Mead use gradient information, making robust potentially slower. useful fallback gradient-based methods fail, problems non-smooth likelihoods.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/nelder_mead.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Nelder-Mead Solver (Derivative-Free) — nelder_mead","text":"","code":"if (FALSE) { # \\dontrun{ # Use when gradients are problematic result <- nelder_mead()(problem, c(0, 1))  # Race against gradient methods strategy <- gradient_ascent() %|% nelder_mead() } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/new_trace_recorder.html","id":null,"dir":"Reference","previous_headings":"","what":"Create a trace recorder — new_trace_recorder","title":"Create a trace recorder — new_trace_recorder","text":"Internal function create mutable trace recorder.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/new_trace_recorder.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create a trace recorder — new_trace_recorder","text":"","code":"new_trace_recorder(trace, n_params)"},{"path":"https://queelius.github.io/compositional.mle/reference/new_trace_recorder.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create a trace recorder — new_trace_recorder","text":"trace mle_trace configuration n_params Number parameters (pre-allocation)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/new_trace_recorder.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create a trace recorder — new_trace_recorder","text":"trace recorder environment","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":null,"dir":"Reference","previous_headings":"","what":"Newton-Raphson Solver — newton_raphson","title":"Newton-Raphson Solver — newton_raphson","text":"Creates solver uses Newton-Raphson (second-order) optimization. Uses Fisher information matrix scale gradient faster convergence near optimum.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Newton-Raphson Solver — newton_raphson","text":"","code":"newton_raphson(   line_search = TRUE,   max_iter = 50L,   tol = 1e-08,   backtrack_ratio = 0.5,   min_step = 1e-12,   verbose = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Newton-Raphson Solver — newton_raphson","text":"line_search Use backtracking line search stability max_iter Maximum number iterations tol Convergence tolerance (parameter change) backtrack_ratio Step size reduction factor line search min_step Minimum step size giving verbose Logical; TRUE cli package installed, display progress optimization. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Newton-Raphson Solver — newton_raphson","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Newton-Raphson Solver — newton_raphson","text":"Newton-Raphson computes search direction \\((\\theta)^{-1} s(\\theta)\\) \\(\\) Fisher information \\(s\\) score. accounts parameter scaling typically converges faster gradient ascent near optimum. Requires problem Fisher information function (either analytic computed numerically).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/newton_raphson.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Newton-Raphson Solver — newton_raphson","text":"","code":"if (FALSE) { # \\dontrun{ # Basic usage solver <- newton_raphson() result <- solver(problem, c(0, 1))  # Often used after gradient ascent for refinement strategy <- gradient_ascent(max_iter = 50) %>>% newton_raphson(max_iter = 20) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/normal_sampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Normal Sampler Factory — normal_sampler","title":"Normal Sampler Factory — normal_sampler","text":"Creates sampler function use with_restarts generates normally distributed starting points around center.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/normal_sampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normal Sampler Factory — normal_sampler","text":"","code":"normal_sampler(center, sd = 1)"},{"path":"https://queelius.github.io/compositional.mle/reference/normal_sampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normal Sampler Factory — normal_sampler","text":"center Mean normal distribution sd Standard deviation (scalar vector)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/normal_sampler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normal Sampler Factory — normal_sampler","text":"sampler function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/normal_sampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Normal Sampler Factory — normal_sampler","text":"","code":"sampler <- normal_sampler(c(0, 1), sd = c(5, 0.5)) strategy <- with_restarts(gradient_ascent(), n = 20, sampler = sampler)"},{"path":"https://queelius.github.io/compositional.mle/reference/num_iterations.html","id":null,"dir":"Reference","previous_headings":"","what":"Get number of iterations — num_iterations","title":"Get number of iterations — num_iterations","text":"Get number iterations","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/num_iterations.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get number of iterations — num_iterations","text":"","code":"num_iterations(x, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/num_iterations.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get number of iterations — num_iterations","text":"x mle result object ... Additional arguments (unused)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/num_iterations.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get number of iterations — num_iterations","text":"Number iterations","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/optimization_path.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract Optimization Path as Data Frame — optimization_path","title":"Extract Optimization Path as Data Frame — optimization_path","text":"Converts trace data MLE result tidy data frame custom analysis plotting (e.g., ggplot2).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/optimization_path.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract Optimization Path as Data Frame — optimization_path","text":"","code":"optimization_path(x, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/optimization_path.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract Optimization Path as Data Frame — optimization_path","text":"x mle_numerical result object trace_data, mle_trace_data object ... Additional arguments (unused)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/optimization_path.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract Optimization Path as Data Frame — optimization_path","text":"data frame columns: iteration: Iteration number loglike: Log-likelihood value (traced) grad_norm: Gradient norm (traced) time: Elapsed time seconds (traced) theta_1, theta_2, ...: Parameter values (path traced)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/optimization_path.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract Optimization Path as Data Frame — optimization_path","text":"","code":"# \\donttest{ # Get optimization path as data frame problem <- mle_problem(   loglike = function(theta) -sum((theta - c(3, 2))^2),   constraint = mle_constraint(support = function(theta) TRUE) ) trace_cfg <- mle_trace(values = TRUE, path = TRUE) result <- gradient_ascent(max_iter = 30)(problem, c(0, 0), trace = trace_cfg)  path_df <- optimization_path(result) head(path_df) #>   iteration      loglike   theta_1   theta_2 #> 1         1 -13.00000000 0.0000000 0.0000000 #> 2         2  -6.78889745 0.8320503 0.5547002 #> 3         3  -2.57779490 1.6641006 1.1094004 #> 4         4  -0.36669235 2.4961509 1.6641006 #> 5         5  -0.15558980 3.3282012 2.2188008 #> 6         6  -0.01114107 2.9121760 1.9414507 # }"},{"path":"https://queelius.github.io/compositional.mle/reference/penalize_loglike.html","id":null,"dir":"Reference","previous_headings":"","what":"loglikelihood constructor\npenalizes — penalize_loglike","title":"loglikelihood constructor\npenalizes — penalize_loglike","text":"loglikelihood constructor penalizes","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalize_loglike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"loglikelihood constructor\npenalizes — penalize_loglike","text":"","code":"penalize_loglike(loglike, penalty, options)"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_elastic_net.html","id":null,"dir":"Reference","previous_headings":"","what":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","title":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","text":"Creates penalty combining L1 L2 norms. parameter alpha controls balance: alpha=1 pure LASSO, alpha=0 pure Ridge.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_elastic_net.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","text":"","code":"penalty_elastic_net(alpha = 0.5, weights = NULL)"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_elastic_net.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","text":"alpha Balance L1 L2 (numeric [0,1], default: 0.5) weights Optional parameter weights (default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_elastic_net.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","text":"Penalty function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_elastic_net.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Elastic net penalty (combination of L1 and L2) — penalty_elastic_net","text":"","code":"# Equal mix of L1 and L2 penalty <- penalty_elastic_net(alpha = 0.5)  # More L1 (more sparsity) penalty <- penalty_elastic_net(alpha = 0.9)  # More L2 (more shrinkage) penalty <- penalty_elastic_net(alpha = 0.1)"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l1.html","id":null,"dir":"Reference","previous_headings":"","what":"L1 penalty function (LASSO) — penalty_l1","title":"L1 penalty function (LASSO) — penalty_l1","text":"Creates penalty function computes L1 norm (sum absolute values). Used sparsity-inducing regularization.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l1.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L1 penalty function (LASSO) — penalty_l1","text":"","code":"penalty_l1(weights = NULL)"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l1.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L1 penalty function (LASSO) — penalty_l1","text":"weights Optional parameter weights (default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l1.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L1 penalty function (LASSO) — penalty_l1","text":"Penalty function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l1.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L1 penalty function (LASSO) — penalty_l1","text":"","code":"penalty <- penalty_l1() penalty(c(1, -2, 3))  # Returns 6 #> [1] 6  # Weighted L1 penalty <- penalty_l1(weights = c(1, 2, 1)) penalty(c(1, -2, 3))  # Returns 1*1 + 2*2 + 1*3 = 8 #> [1] 8"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l2.html","id":null,"dir":"Reference","previous_headings":"","what":"L2 penalty function (Ridge) — penalty_l2","title":"L2 penalty function (Ridge) — penalty_l2","text":"Creates penalty function computes L2 norm squared (sum squares). Used parameter shrinkage.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"L2 penalty function (Ridge) — penalty_l2","text":"","code":"penalty_l2(weights = NULL)"},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"L2 penalty function (Ridge) — penalty_l2","text":"weights Optional parameter weights (default: 1)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"L2 penalty function (Ridge) — penalty_l2","text":"Penalty function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/penalty_l2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"L2 penalty function (Ridge) — penalty_l2","text":"","code":"penalty <- penalty_l2() penalty(c(1, -2, 3))  # Returns 14 #> [1] 14  # Weighted L2 penalty <- penalty_l2(weights = c(1, 2, 1)) penalty(c(1, -2, 3))  # Returns 1^2 + (2*2)^2 + 3^2 = 26 #> [1] 26"},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Optimization Convergence — plot.mle_numerical","title":"Plot Optimization Convergence — plot.mle_numerical","text":"Visualizes optimization trajectory MLE result tracing enabled. Shows log-likelihood progression, gradient norm decay, optionally parameter path (2D problems).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Optimization Convergence — plot.mle_numerical","text":"","code":"# S3 method for class 'mle_numerical' plot(x, which = c(\"loglike\", \"gradient\"), main = NULL, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Optimization Convergence — plot.mle_numerical","text":"x mle_numerical result object trace_data Character vector specifying plots show: \"loglike\" (log-likelihood), \"gradient\" (gradient norm), \"path\" (2D parameter path) main Optional title ... Additional arguments passed plot","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Optimization Convergence — plot.mle_numerical","text":"Invisibly returns trace data","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Plot Optimization Convergence — plot.mle_numerical","text":"function requires solver run tracing enabled via mle_trace(). Without trace data, function warn return invisibly. \"path\" plot shown 2D parameter problems.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_numerical.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Optimization Convergence — plot.mle_numerical","text":"","code":"# \\donttest{ # Enable tracing when solving problem <- mle_problem(   loglike = function(theta) -sum((theta - c(3, 2))^2),   constraint = mle_constraint(support = function(theta) TRUE) ) trace_cfg <- mle_trace(values = TRUE, gradients = TRUE, path = TRUE) result <- gradient_ascent(max_iter = 50)(problem, c(0, 0), trace = trace_cfg)  # Plot convergence diagnostics plot(result)  # }"},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_trace_data.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Trace Data Directly — plot.mle_trace_data","title":"Plot Trace Data Directly — plot.mle_trace_data","text":"Plot Trace Data Directly","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_trace_data.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Trace Data Directly — plot.mle_trace_data","text":"","code":"# S3 method for class 'mle_trace_data' plot(x, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/plot.mle_trace_data.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Trace Data Directly — plot.mle_trace_data","text":"x mle_trace_data object ... Arguments passed plotting functions","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":null,"dir":"Reference","previous_headings":"","what":"Race Multiple Solvers — race","title":"Race Multiple Solvers — race","text":"Runs multiple solvers (optionally parallel) returns best result (highest log-likelihood). flexible %|% operator.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Race Multiple Solvers — race","text":"","code":"race(..., parallel = FALSE)"},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Race Multiple Solvers — race","text":"... Solver functions race parallel Logical; TRUE future package installed, solvers run parallel using current future plan. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Race Multiple Solvers — race","text":"new solver function races solvers picks best","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Race Multiple Solvers — race","text":"parallel = TRUE, solvers executed using future::future() results collected future::value(). current future plan determines parallelization happens (e.g., plan(multisession) multi-process execution). Failed solvers (throw errors) ignored. solvers fail, error thrown.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Race Multiple Solvers — race","text":"","code":"# Race three methods sequentially strategy <- race(gradient_ascent(), bfgs(), nelder_mead())  # Race with parallel execution (requires future package) if (FALSE) { # \\dontrun{ future::plan(future::multisession) strategy <- race(gradient_ascent(), bfgs(), nelder_mead(), parallel = TRUE) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":null,"dir":"Reference","previous_headings":"","what":"Parallel Solver Racing (Operator) — race_operator","title":"Parallel Solver Racing (Operator) — race_operator","text":"Runs multiple solvers returns best result (highest log-likelihood). Useful unsure method work best given problem.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parallel Solver Racing (Operator) — race_operator","text":"","code":"s1 %|% s2"},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parallel Solver Racing (Operator) — race_operator","text":"s1 First solver function s2 Second solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parallel Solver Racing (Operator) — race_operator","text":"new solver function runs picks best","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Parallel Solver Racing (Operator) — race_operator","text":"parallel execution 2 solvers, use race.","code":""},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/reference/race_operator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parallel Solver Racing (Operator) — race_operator","text":"","code":"# Race gradient-based vs derivative-free strategy <- gradient_ascent() %|% nelder_mead()  # Race multiple methods strategy <- gradient_ascent() %|% bfgs() %|% nelder_mead()"},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":null,"dir":"Reference","previous_headings":"","what":"Random Search Solver — random_search","title":"Random Search Solver — random_search","text":"Creates solver evaluates log-likelihood random points returns best. Useful high-dimensional problems grid search infeasible.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Random Search Solver — random_search","text":"","code":"random_search(sampler, n = 100L)"},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Random Search Solver — random_search","text":"sampler Function generating random parameter vectors n Number random points evaluate","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Random Search Solver — random_search","text":"solver function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Random Search Solver — random_search","text":"Unlike grid search, random search scales better high dimensions. sampler generate points reasonable region; points outside problem's constraint support skipped.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/random_search.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Random Search Solver — random_search","text":"","code":"# Create a random search solver with uniform sampling solver <- random_search(   sampler = uniform_sampler(c(-10, 0.1), c(10, 5)),   n = 100 )"},{"path":"https://queelius.github.io/compositional.mle/reference/record_iteration.html","id":null,"dir":"Reference","previous_headings":"","what":"Record an iteration to trace — record_iteration","title":"Record an iteration to trace — record_iteration","text":"Record iteration trace","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/record_iteration.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Record an iteration to trace — record_iteration","text":"","code":"record_iteration(recorder, theta, value = NULL, gradient = NULL)"},{"path":"https://queelius.github.io/compositional.mle/reference/record_iteration.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Record an iteration to trace — record_iteration","text":"recorder Trace recorder new_trace_recorder theta Current parameters value Current log-likelihood (NULL) gradient Current gradient (NULL)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulated Annealing Solver — sim_anneal","title":"Simulated Annealing Solver — sim_anneal","text":"Creates solver using simulated annealing global optimization. Simulated annealing can escape local optima probabilistically accepting worse solutions, acceptance probability decreasing time (controlled \"temperature\" parameter).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulated Annealing Solver — sim_anneal","text":"","code":"sim_anneal(   temp_init = 10,   cooling_rate = 0.95,   max_iter = 1000L,   neighbor_sd = 1,   min_temp = 1e-10,   verbose = FALSE )"},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulated Annealing Solver — sim_anneal","text":"temp_init Initial temperature (higher = exploration) cooling_rate Temperature reduction factor per iteration (0 < r < 1) max_iter Maximum number iterations neighbor_sd Standard deviation generating neighbor proposals min_temp Minimum temperature stopping verbose Logical; TRUE cli package installed, display progress optimization. Default FALSE.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulated Annealing Solver — sim_anneal","text":"solver function signature (problem, theta0, trace) -> mle_result","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Simulated Annealing Solver — sim_anneal","text":"iteration: 1. Generate neighbor adding Gaussian noise current parameters 2. neighbor improves objective, accept 3. neighbor worse, accept probability exp(delta / temp) 4. Reduce temperature: temp = temp * cooling_rate algorithm stochastic may find different solutions different runs. best results, use with_restarts() combine local optimizer via %>>%.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/sim_anneal.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Simulated Annealing Solver — sim_anneal","text":"","code":"# Basic simulated annealing solver <- sim_anneal()  # More exploration (higher initial temp, slower cooling) solver <- sim_anneal(temp_init = 100, cooling_rate = 0.999)  # Coarse global search, then local refinement strategy <- sim_anneal(max_iter = 500) %>>% gradient_ascent()"},{"path":"https://queelius.github.io/compositional.mle/reference/stochastic_loglike.html","id":null,"dir":"Reference","previous_headings":"","what":"stochastic loglikelihood constructor\ngood for large datasets. if applied to a gradient ascent method, this\nwill perform stochastic gradient ascent. — stochastic_loglike","title":"stochastic loglikelihood constructor\ngood for large datasets. if applied to a gradient ascent method, this\nwill perform stochastic gradient ascent. — stochastic_loglike","text":"stochastic loglikelihood constructor good large datasets. applied gradient ascent method, perform stochastic gradient ascent.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/stochastic_loglike.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"stochastic loglikelihood constructor\ngood for large datasets. if applied to a gradient ascent method, this\nwill perform stochastic gradient ascent. — stochastic_loglike","text":"","code":"stochastic_loglike(log.p, obs, options)"},{"path":"https://queelius.github.io/compositional.mle/reference/stochastic_loglike.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"stochastic loglikelihood constructor\ngood for large datasets. if applied to a gradient ascent method, this\nwill perform stochastic gradient ascent. — stochastic_loglike","text":"log.p log pdf (pmf) parametric model fit `obs` parameters. can also just proportional log pdf, since sometimes normalizing constant unknown hard compute. obs matrix, vector, data frame observations options list options","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/subdivide_region.html","id":null,"dir":"Reference","previous_headings":"","what":"subdivide_region — subdivide_region","title":"subdivide_region — subdivide_region","text":"subdivide_region","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/subdivide_region.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"subdivide_region — subdivide_region","text":"","code":"subdivide_region(lower, upper, grid_size)"},{"path":"https://queelius.github.io/compositional.mle/reference/subdivide_region.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"subdivide_region — subdivide_region","text":"lower lower bounds parameter support (vector) upper upper bounds parameter support (vector) grid_size maximum size dimension hypercube makes grid","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/uniform_sampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Uniform Sampler Factory — uniform_sampler","title":"Uniform Sampler Factory — uniform_sampler","text":"Creates sampler function use with_restarts generates uniformly distributed starting points.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/uniform_sampler.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Uniform Sampler Factory — uniform_sampler","text":"","code":"uniform_sampler(lower, upper)"},{"path":"https://queelius.github.io/compositional.mle/reference/uniform_sampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Uniform Sampler Factory — uniform_sampler","text":"lower Lower bounds parameter upper Upper bounds parameter","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/uniform_sampler.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Uniform Sampler Factory — uniform_sampler","text":"sampler function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/uniform_sampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Uniform Sampler Factory — uniform_sampler","text":"","code":"sampler <- uniform_sampler(c(-10, 0.1), c(10, 5)) strategy <- with_restarts(gradient_ascent(), n = 20, sampler = sampler)"},{"path":"https://queelius.github.io/compositional.mle/reference/unless_converged.html","id":null,"dir":"Reference","previous_headings":"","what":"Conditional Refinement — unless_converged","title":"Conditional Refinement — unless_converged","text":"Applies refinement solver first solver converge. refinement applied, trace data solvers merged.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/unless_converged.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Conditional Refinement — unless_converged","text":"","code":"unless_converged(solver, refinement)"},{"path":"https://queelius.github.io/compositional.mle/reference/unless_converged.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Conditional Refinement — unless_converged","text":"solver Primary solver function refinement Solver use primary converge","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/unless_converged.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Conditional Refinement — unless_converged","text":"new solver function conditional refinement","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/unless_converged.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Conditional Refinement — unless_converged","text":"","code":"# Use Newton-Raphson to refine if gradient ascent doesn't converge strategy <- unless_converged(gradient_ascent(max_iter = 50), newton_raphson())"},{"path":"https://queelius.github.io/compositional.mle/reference/update.mle_problem.html","id":null,"dir":"Reference","previous_headings":"","what":"Update an mle_problem — update.mle_problem","title":"Update an mle_problem — update.mle_problem","text":"Create new problem fields updated.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/update.mle_problem.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Update an mle_problem — update.mle_problem","text":"","code":"# S3 method for class 'mle_problem' update(object, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/update.mle_problem.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Update an mle_problem — update.mle_problem","text":"object mle_problem ... Named arguments update","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/update.mle_problem.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Update an mle_problem — update.mle_problem","text":"New mle_problem","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/verbose-utils.html","id":null,"dir":"Reference","previous_headings":"","what":"Verbose Output Utilities — verbose-utils","title":"Verbose Output Utilities — verbose-utils","text":"Internal functions progress reporting optimization.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_constraint.html","id":null,"dir":"Reference","previous_headings":"","what":"Quick constrained optimization — with_constraint","title":"Quick constrained optimization — with_constraint","text":"Convenience wrapper constrained optimization simplified interface. Automatically creates constraint object support projection functions.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_constraint.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Quick constrained optimization — with_constraint","text":"","code":"with_constraint(solver, support, project, ...)"},{"path":"https://queelius.github.io/compositional.mle/reference/with_constraint.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Quick constrained optimization — with_constraint","text":"solver Solver function (e.g., mle_grad, mle_nr) support Support function (returns TRUE theta valid) project Projection function (maps invalid theta valid theta) ... Arguments passed solver","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_constraint.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Quick constrained optimization — with_constraint","text":"mle object solver","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_constraint.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Quick constrained optimization — with_constraint","text":"","code":"if (FALSE) { # \\dontrun{ # Constrain parameters to be positive result <- with_constraint(   solver = mle_grad,   support = function(theta) all(theta > 0),   project = function(theta) pmax(theta, 1e-8),   loglike = loglike,   score = score,   theta0 = c(1, 1) ) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/with_penalty.html","id":null,"dir":"Reference","previous_headings":"","what":"Add penalty term to log-likelihood — with_penalty","title":"Add penalty term to log-likelihood — with_penalty","text":"Transforms log-likelihood subtracting penalty term. Useful regularized estimation (e.g., LASSO, Ridge regression).","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_penalty.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add penalty term to log-likelihood — with_penalty","text":"","code":"with_penalty(loglike, penalty, lambda = 1)"},{"path":"https://queelius.github.io/compositional.mle/reference/with_penalty.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add penalty term to log-likelihood — with_penalty","text":"loglike Base log-likelihood function penalty Penalty function taking theta returning numeric lambda Penalty weight (non-negative numeric, default: 1.0)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_penalty.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add penalty term to log-likelihood — with_penalty","text":"Transformed log-likelihood function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_penalty.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add penalty term to log-likelihood — with_penalty","text":"","code":"if (FALSE) { # \\dontrun{ # Regression with L2 penalty (Ridge) loglike <- function(theta) {   # ... likelihood calculation ... }  # Add L2 penalty loglike_penalized <- with_penalty(   loglike,   penalty = penalty_l2(),   lambda = 0.1 )  # Combine with stochastic subsampling loglike_final <- loglike %>%   with_subsampling(data, 100) %>%   with_penalty(penalty_l1(), lambda = 0.01) } # }"},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":null,"dir":"Reference","previous_headings":"","what":"Multiple Random Restarts — with_restarts","title":"Multiple Random Restarts — with_restarts","text":"Runs solver multiple starting points returns best result. Essential problems multiple local optima.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Multiple Random Restarts — with_restarts","text":"","code":"with_restarts(solver, n, sampler, max_reject = 100L)"},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Multiple Random Restarts — with_restarts","text":"solver solver function n Number restarts (including provided theta0) sampler Function generates random starting points. Called arguments, return parameter vector. Samples automatically constrained using problem$constraint. max_reject Maximum rejection attempts per sample projection","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Multiple Random Restarts — with_restarts","text":"new solver function restart capability","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Multiple Random Restarts — with_restarts","text":"sampler generates candidate starting points, automatically filtered/projected using problem's constraint. means samplers can simple distributions without constraint awareness.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_restarts.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Multiple Random Restarts — with_restarts","text":"","code":"# 20 random restarts - constraint applied automatically from problem sampler <- uniform_sampler(c(-10, 0), c(10, 5)) strategy <- with_restarts(gradient_ascent(), n = 20, sampler = sampler)  # Can also compose with other operators strategy <- with_restarts(gradient_ascent(), n = 10, sampler = sampler) %>>%   newton_raphson()"},{"path":"https://queelius.github.io/compositional.mle/reference/with_subsampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Create stochastic log-likelihood with subsampling — with_subsampling","title":"Create stochastic log-likelihood with subsampling — with_subsampling","text":"Transforms log-likelihood function use random subsample observations. Useful stochastic gradient ascent large datasets.","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_subsampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Create stochastic log-likelihood with subsampling — with_subsampling","text":"","code":"with_subsampling(loglike, data, subsample_size, replace = FALSE)"},{"path":"https://queelius.github.io/compositional.mle/reference/with_subsampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Create stochastic log-likelihood with subsampling — with_subsampling","text":"loglike Base log-likelihood function. accept theta data. data Observations (vector, matrix, data.frame) subsample_size Number observations sample per evaluation replace Sample replacement (logical, default: FALSE)","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_subsampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Create stochastic log-likelihood with subsampling — with_subsampling","text":"Transformed log-likelihood function","code":""},{"path":"https://queelius.github.io/compositional.mle/reference/with_subsampling.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Create stochastic log-likelihood with subsampling — with_subsampling","text":"","code":"if (FALSE) { # \\dontrun{ # Original likelihood uses all data data <- rnorm(10000, mean = 5, sd = 2)  loglike <- function(theta, obs = data) {   sum(dnorm(obs, mean = theta[1], sd = theta[2], log = TRUE)) }  # Stochastic version uses random subsample loglike_stoch <- with_subsampling(   loglike,   data = data,   subsample_size = 100 )  # Each call uses different random subsample loglike_stoch(c(5, 2)) loglike_stoch(c(5, 2))  # Different value } # }"},{"path":[]},{"path":"https://queelius.github.io/compositional.mle/news/index.html","id":"new-features-0-2-0","dir":"Changelog","previous_headings":"","what":"New Features","title":"compositional.mle 0.2.0","text":"Simulated annealing solver (sim_anneal()) Coordinate ascent solver (coordinate_ascent()) race() function explicit parallel solver racing future support chain() function sequential composition early stopping Convergence diagnostics: plot.mle_numerical() optimization_path() Derivative caching mle_problem() avoid redundant computation Verbose/progress output via cli long-running solvers Trace aggregation merge_traces() across composed solvers","code":""},{"path":"https://queelius.github.io/compositional.mle/news/index.html","id":"documentation-0-2-0","dir":"Changelog","previous_headings":"","what":"Documentation","title":"compositional.mle 0.2.0","text":"Four vignettes: getting-started, theory--intuition, case-studies, strategy-design pkgdown site https://queelius.github.io/compositional.mle/","code":""},{"path":"https://queelius.github.io/compositional.mle/news/index.html","id":"bug-fixes-0-2-0","dir":"Changelog","previous_headings":"","what":"Bug Fixes","title":"compositional.mle 0.2.0","text":"Fixed R CMD check issues (missing imports, example errors) Fixed LICENSE copyright holder","code":""},{"path":"https://queelius.github.io/compositional.mle/news/index.html","id":"compositionalmle-010","dir":"Changelog","previous_headings":"","what":"compositional.mle 0.1.0","title":"compositional.mle 0.1.0","text":"Initial release core solver factories composition operators Solvers: gradient_ascent, newton_raphson, bfgs, lbfgsb, nelder_mead, grid_search, random_search Composition: %>>% (sequential), %|% (racing), with_restarts(), unless_converged() Problem specification mle_problem() constraint support Tracing system optimization iteration recording Penalty/regularization transformers (L1, L2, elastic net)","code":""}]
