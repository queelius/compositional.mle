<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Automatic Differentiation with dualr • compositional.mle</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Automatic Differentiation with dualr">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-primary" data-bs-theme="dark" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">compositional.mle</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.2.0</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html">Reference</a></li>
<li class="active nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-articles" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true">Articles</button>
  <ul class="dropdown-menu" aria-labelledby="dropdown-articles">
<li><a class="dropdown-item" href="../articles/getting-started.html">Getting Started</a></li>
    <li><a class="dropdown-item" href="../articles/theory-and-intuition.html">Theory and Intuition</a></li>
    <li><a class="dropdown-item" href="../articles/case-studies.html">Case Studies</a></li>
    <li><a class="dropdown-item" href="../articles/strategy-design.html">Strategy Design</a></li>
    <li><a class="dropdown-item" href="../articles/automatic-differentiation.html">Automatic Differentiation</a></li>
  </ul>
</li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/queelius/compositional.mle/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">

      <h1>Automatic Differentiation with dualr</h1>
                        <h4 data-toc-skip class="author">Alexander
Towell</h4>
            
            <h4 data-toc-skip class="date">2026-01-31</h4>
      
      <small class="dont-index">Source: <a href="https://github.com/queelius/compositional.mle/blob/HEAD/vignettes/automatic-differentiation.Rmd" class="external-link"><code>vignettes/automatic-differentiation.Rmd</code></a></small>
      <div class="d-none name"><code>automatic-differentiation.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="why-automatic-differentiation">Why Automatic Differentiation?<a class="anchor" aria-label="anchor" href="#why-automatic-differentiation"></a>
</h2>
<p>Maximum likelihood estimation requires derivatives of the
log-likelihood: the <strong>score</strong> (gradient) for first-order
methods and the <strong>Hessian</strong> (or observed information) for
second-order methods like Newton-Raphson. There are three ways to supply
these:</p>
<table class="table">
<colgroup>
<col width="28%">
<col width="28%">
<col width="22%">
<col width="20%">
</colgroup>
<thead><tr class="header">
<th>Approach</th>
<th>Accuracy</th>
<th>Effort</th>
<th>Speed</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Numerical (<code>numDeriv</code>)</td>
<td>
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>h</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(h^2)</annotation></semantics></math>
truncation error</td>
<td>None (default)</td>
<td>Slow (extra evaluations)</td>
</tr>
<tr class="even">
<td>Hand-coded analytic</td>
<td>Exact</td>
<td>High (error-prone)</td>
<td>Fast</td>
</tr>
<tr class="odd">
<td>Automatic differentiation (<code>dualr</code>)</td>
<td>Exact (to machine precision)</td>
<td>Low</td>
<td>Moderate</td>
</tr>
</tbody>
</table>
<p>Following the SICP principle that <em>the specification should be
separate from the mechanism</em>, the log-likelihood function is the
specification of our statistical model. Derivatives are mechanical
consequences of that specification—they should be derived automatically
rather than hand-coded.</p>
<p>The <a href="https://github.com/queelius/dualr" class="external-link"><code>dualr</code></a> package
provides forward-mode automatic differentiation for R via dual numbers,
giving exact derivatives with minimal code changes.</p>
</div>
<div class="section level2">
<h2 id="setup">Setup<a class="anchor" aria-label="anchor" href="#setup"></a>
</h2>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/compositional.mle" class="external-link">compositional.mle</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/queelius/dualr" class="external-link">dualr</a></span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Attaching package: 'dualr'</span></span>
<span><span class="co">#&gt; The following object is masked from 'package:stats':</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     deriv</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="the-three-approaches">The Three Approaches<a class="anchor" aria-label="anchor" href="#the-three-approaches"></a>
</h2>
<p>Consider a Poisson model. The log-likelihood for
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>λ</mi><annotation encoding="application/x-tex">\lambda</annotation></semantics></math>
given data
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>,</mo><mi>…</mi><mo>,</mo><msub><mi>x</mi><mi>n</mi></msub></mrow><annotation encoding="application/x-tex">x_1, \ldots, x_n</annotation></semantics></math>
is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ℓ</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>λ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mrow><mo stretchy="true" form="prefix">(</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>x</mi><mi>i</mi></msub><mo stretchy="true" form="postfix">)</mo></mrow><mo>log</mo><mi>λ</mi><mo>−</mo><mi>n</mi><mi>λ</mi></mrow><annotation encoding="application/x-tex">\ell(\lambda) = \left(\sum_{i=1}^n x_i\right) \log \lambda - n\lambda</annotation></semantics></math></p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html" class="external-link">rpois</a></span><span class="op">(</span><span class="fl">100</span>, lambda <span class="op">=</span> <span class="fl">3.5</span><span class="op">)</span></span></code></pre></div>
<p>We define the log-likelihood once:</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ll_poisson</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">lambda</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span></span>
<span>  <span class="co"># Accumulate sum in a loop for dualr compatibility</span></span>
<span>  <span class="va">sx</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_along</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="va">sx</span> <span class="op">&lt;-</span> <span class="va">sx</span> <span class="op">+</span> <span class="va">x</span><span class="op">[</span><span class="va">i</span><span class="op">]</span></span>
<span>  <span class="va">sx</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">lambda</span><span class="op">)</span> <span class="op">-</span> <span class="va">n</span> <span class="op">*</span> <span class="va">lambda</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p>Now we create three problem specifications using different derivative
strategies:</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># 1. No derivatives — numDeriv fallback (the default)</span></span>
<span><span class="va">p_numerical</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_problem.html">mle_problem</a></span><span class="op">(</span>loglike <span class="op">=</span> <span class="va">ll_poisson</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 2. Hand-coded analytical derivatives</span></span>
<span><span class="va">p_analytic</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_problem.html">mle_problem</a></span><span class="op">(</span></span>
<span>  loglike <span class="op">=</span> <span class="va">ll_poisson</span>,</span>
<span>  score <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>,</span>
<span>  fisher <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html" class="external-link">sum</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span><span class="op">^</span><span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># 3. Automatic differentiation via dualr</span></span>
<span><span class="va">p_ad</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_problem.html">mle_problem</a></span><span class="op">(</span></span>
<span>  loglike <span class="op">=</span> <span class="va">ll_poisson</span>,</span>
<span>  score <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/score.html" class="external-link">score</a></span><span class="op">(</span><span class="va">ll_poisson</span>, <span class="va">theta</span><span class="op">)</span>,</span>
<span>  fisher <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/observed_information.html" class="external-link">observed_information</a></span><span class="op">(</span><span class="va">ll_poisson</span>, <span class="va">theta</span><span class="op">)</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p_numerical</span></span>
<span><span class="co">#&gt; MLE Problem</span></span>
<span><span class="co">#&gt;   Parameters: unnamed </span></span>
<span><span class="co">#&gt;   Score: numerical </span></span>
<span><span class="co">#&gt;   Fisher: numerical </span></span>
<span><span class="co">#&gt;   Constraints: yes</span></span>
<span><span class="va">p_ad</span></span>
<span><span class="co">#&gt; MLE Problem</span></span>
<span><span class="co">#&gt;   Parameters: unnamed </span></span>
<span><span class="co">#&gt;   Score: analytic </span></span>
<span><span class="co">#&gt;   Fisher: analytic </span></span>
<span><span class="co">#&gt;   Constraints: yes</span></span></code></pre></div>
<p>Notice that both the AD and analytic problems report “analytic” score
and Fisher information. From the solver’s perspective, they are
identical—the solver doesn’t know (or care) whether the derivatives were
hand-coded or computed by AD. This is the power of the
<code>mle_problem</code> abstraction: derivatives are pluggable.</p>
</div>
<div class="section level2">
<h2 id="comparison">Comparison<a class="anchor" aria-label="anchor" href="#comparison"></a>
</h2>
<p>Let’s run the same solver on all three:</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">solver</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/bfgs.html">bfgs</a></span><span class="op">(</span>max_iter <span class="op">=</span> <span class="fl">200</span><span class="op">)</span></span>
<span></span>
<span><span class="va">r_num</span> <span class="op">&lt;-</span> <span class="fu">solver</span><span class="op">(</span><span class="va">p_numerical</span>, theta0 <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">r_ana</span> <span class="op">&lt;-</span> <span class="fu">solver</span><span class="op">(</span><span class="va">p_analytic</span>, theta0 <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span><span class="va">r_ad</span>  <span class="op">&lt;-</span> <span class="fu">solver</span><span class="op">(</span><span class="va">p_ad</span>, theta0 <span class="op">=</span> <span class="fl">1</span><span class="op">)</span></span>
<span></span>
<span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span></span>
<span>  Method     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"numDeriv"</span>, <span class="st">"Analytic"</span>, <span class="st">"dualr AD"</span><span class="op">)</span>,</span>
<span>  Estimate   <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">r_num</span><span class="op">$</span><span class="va">theta.hat</span>, <span class="va">r_ana</span><span class="op">$</span><span class="va">theta.hat</span>, <span class="va">r_ad</span><span class="op">$</span><span class="va">theta.hat</span><span class="op">)</span>,</span>
<span>  LogLik     <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">r_num</span><span class="op">$</span><span class="va">loglike</span>, <span class="va">r_ana</span><span class="op">$</span><span class="va">loglike</span>, <span class="va">r_ad</span><span class="op">$</span><span class="va">loglike</span><span class="op">)</span>,</span>
<span>  Converged  <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">r_num</span><span class="op">$</span><span class="va">converged</span>, <span class="va">r_ana</span><span class="op">$</span><span class="va">converged</span>, <span class="va">r_ad</span><span class="op">$</span><span class="va">converged</span><span class="op">)</span>,</span>
<span>  Iterations <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="va">r_num</span><span class="op">$</span><span class="va">iterations</span>, <span class="va">r_ana</span><span class="op">$</span><span class="va">iterations</span>, <span class="va">r_ad</span><span class="op">$</span><span class="va">iterations</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span><span class="va">results</span></span>
<span><span class="co">#&gt;     Method Estimate   LogLik Converged Iterations</span></span>
<span><span class="co">#&gt; 1 numDeriv     3.64 106.2821      TRUE         21</span></span>
<span><span class="co">#&gt; 2 Analytic     3.64 106.2821      TRUE         23</span></span>
<span><span class="co">#&gt; 3 dualr AD     3.64 106.2821      TRUE         23</span></span></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"True MLE (sample mean):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; True MLE (sample mean): 3.64</span></span></code></pre></div>
<p>All three converge to the same estimate. The key differences are:</p>
<ul>
<li>
<strong>numDeriv</strong> introduces small
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mrow><mo stretchy="true" form="prefix">(</mo><msup><mi>h</mi><mn>2</mn></msup><mo stretchy="true" form="postfix">)</mo></mrow></mrow><annotation encoding="application/x-tex">O(h^2)</annotation></semantics></math>
errors in the gradient, which may cause minor differences in iteration
paths (usually negligible)</li>
<li>
<strong>Analytic</strong> and <strong>dualr AD</strong> provide
exact gradients, leading to identical optimization paths</li>
<li>
<strong>dualr AD</strong> requires no manual derivative
derivation</li>
</ul>
</div>
<div class="section level2">
<h2 id="multivariate-example-normal-distribution">Multivariate Example: Normal Distribution<a class="anchor" aria-label="anchor" href="#multivariate-example-normal-distribution"></a>
</h2>
<p>For the
Normal<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo>,</mo><mi>σ</mi><mo stretchy="true" form="postfix">)</mo></mrow><annotation encoding="application/x-tex">(\mu, \sigma)</annotation></semantics></math>
model, we have two parameters and a positivity constraint on
<math display="inline" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mi>σ</mi><annotation encoding="application/x-tex">\sigma</annotation></semantics></math>.
The log-likelihood is:</p>
<p><math display="block" xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>ℓ</mo><mrow><mo stretchy="true" form="prefix">(</mo><mi>μ</mi><mo>,</mo><mi>σ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mo>=</mo><mo>−</mo><mi>n</mi><mo>log</mo><mi>σ</mi><mo>−</mo><mfrac><mn>1</mn><mrow><mn>2</mn><msup><mi>σ</mi><mn>2</mn></msup></mrow></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msup><mrow><mo stretchy="true" form="prefix">(</mo><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mi>μ</mi><mo stretchy="true" form="postfix">)</mo></mrow><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\ell(\mu, \sigma) = -n \log \sigma - \frac{1}{2\sigma^2}\sum_{i=1}^n (y_i - \mu)^2</annotation></semantics></math></p>
<div class="sourceCode" id="cb8"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">200</span>, mean <span class="op">=</span> <span class="fl">5</span>, sd <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb9"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Log-likelihood with loop-based sum for dualr Hessian support</span></span>
<span><span class="va">ll_normal</span> <span class="op">&lt;-</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="op">{</span></span>
<span>  <span class="va">mu</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span></span>
<span>  <span class="va">sigma</span> <span class="op">&lt;-</span> <span class="va">theta</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span></span>
<span>  <span class="va">n</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span></span>
<span>  <span class="va">ss</span> <span class="op">&lt;-</span> <span class="fl">0</span></span>
<span>  <span class="kw">for</span> <span class="op">(</span><span class="va">i</span> <span class="kw">in</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html" class="external-link">seq_along</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span></span>
<span>    <span class="va">ss</span> <span class="op">&lt;-</span> <span class="va">ss</span> <span class="op">+</span> <span class="op">(</span><span class="va">y</span><span class="op">[</span><span class="va">i</span><span class="op">]</span> <span class="op">-</span> <span class="va">mu</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span>  <span class="op">}</span></span>
<span>  <span class="op">-</span><span class="va">n</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html" class="external-link">log</a></span><span class="op">(</span><span class="va">sigma</span><span class="op">)</span> <span class="op">-</span> <span class="fl">0.5</span> <span class="op">*</span> <span class="va">ss</span> <span class="op">/</span> <span class="va">sigma</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="op">}</span></span></code></pre></div>
<p><strong>Note:</strong> We use a loop-based sum instead of vectorized
<code>sum((y - mu)^2)</code>. This is because <code>dualr</code>’s
Hessian computation currently requires scalar accumulation when mixing
dual numbers with data vectors. The score function works either way, but
the Hessian needs this pattern. This is a minor syntactic cost for exact
second derivatives.</p>
<div class="sourceCode" id="cb10"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># AD-powered problem with box constraints via L-BFGS-B</span></span>
<span><span class="va">p_normal</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/mle_problem.html">mle_problem</a></span><span class="op">(</span></span>
<span>  loglike <span class="op">=</span> <span class="va">ll_normal</span>,</span>
<span>  score <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/score.html" class="external-link">score</a></span><span class="op">(</span><span class="va">ll_normal</span>, <span class="va">theta</span><span class="op">)</span>,</span>
<span>  fisher <span class="op">=</span> <span class="kw">function</span><span class="op">(</span><span class="va">theta</span><span class="op">)</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/observed_information.html" class="external-link">observed_information</a></span><span class="op">(</span><span class="va">ll_normal</span>, <span class="va">theta</span><span class="op">)</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="va">solver</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/lbfgsb.html">lbfgsb</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">Inf</span>, <span class="cn">Inf</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">result</span> <span class="op">&lt;-</span> <span class="fu">solver</span><span class="op">(</span><span class="va">p_normal</span>, theta0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb11"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Estimated mu:   "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Estimated mu:    4.9829</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Estimated sigma:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">result</span><span class="op">$</span><span class="va">theta.hat</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Estimated sigma: 1.8816</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Converged:      "</span>, <span class="va">result</span><span class="op">$</span><span class="va">converged</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Converged:       TRUE</span></span>
<span></span>
<span><span class="co"># Compare with true MLE</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nTrue MLE mu:   "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/mean.html" class="external-link">mean</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; True MLE mu:    4.9829</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"True MLE sigma:"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/sd.html" class="external-link">sd</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">y</span><span class="op">)</span><span class="op">)</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; True MLE sigma: 1.8816</span></span></code></pre></div>
<p>The Hessian matrix from dualr provides the full curvature
information:</p>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">H</span> <span class="op">&lt;-</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/hessian.html" class="external-link">hessian</a></span><span class="op">(</span><span class="va">ll_normal</span>, <span class="va">result</span><span class="op">$</span><span class="va">theta.hat</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Hessian at MLE:\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Hessian at MLE:</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">H</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;        [,1]    [,2]</span></span>
<span><span class="co">#&gt; [1,] -56.49    0.00</span></span>
<span><span class="co">#&gt; [2,]   0.00 -112.98</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nObserved information at MLE:\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Observed information at MLE:</span></span>
<span><span class="va">I_obs</span> <span class="op">&lt;-</span> <span class="fu">dualr</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/dualr/man/observed_information.html" class="external-link">observed_information</a></span><span class="op">(</span><span class="va">ll_normal</span>, <span class="va">result</span><span class="op">$</span><span class="va">theta.hat</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">I_obs</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;       [,1]   [,2]</span></span>
<span><span class="co">#&gt; [1,] 56.49   0.00</span></span>
<span><span class="co">#&gt; [2,]  0.00 112.98</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"\nApproximate standard errors (from observed information):\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Approximate standard errors (from observed information):</span></span>
<span><span class="va">se</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html" class="external-link">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/diag.html" class="external-link">diag</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/solve.html" class="external-link">solve</a></span><span class="op">(</span><span class="va">I_obs</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"  SE(mu):   "</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">se</span><span class="op">[</span><span class="fl">1</span><span class="op">]</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   SE(mu):    0.133</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"  SE(sigma):"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">se</span><span class="op">[</span><span class="fl">2</span><span class="op">]</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt;   SE(sigma): 0.0941</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="composition-with-ad">Composition with AD<a class="anchor" aria-label="anchor" href="#composition-with-ad"></a>
</h2>
<p>The real power emerges when combining AD with solver composition.
Because <code>dualr</code>-derived derivatives are just functions, they
compose seamlessly:</p>
<div class="sourceCode" id="cb13"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Coarse grid search, then refine with L-BFGS-B</span></span>
<span><span class="va">strategy</span> <span class="op">&lt;-</span> <span class="fu"><a href="../reference/grid_search.html">grid_search</a></span><span class="op">(</span></span>
<span>  lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">10</span>, <span class="fl">5</span><span class="op">)</span>, n <span class="op">=</span> <span class="fl">5</span></span>
<span><span class="op">)</span> <span class="op"><a href="../reference/grapes-greater-than-greater-than-grapes.html">%&gt;&gt;%</a></span> <span class="fu"><a href="../reference/lbfgsb.html">lbfgsb</a></span><span class="op">(</span>lower <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="op">-</span><span class="cn">Inf</span>, <span class="fl">1e-4</span><span class="op">)</span>, upper <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="cn">Inf</span>, <span class="cn">Inf</span><span class="op">)</span><span class="op">)</span></span>
<span></span>
<span><span class="va">result_composed</span> <span class="op">&lt;-</span> <span class="fu">strategy</span><span class="op">(</span><span class="va">p_normal</span>, theta0 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Grid -&gt; L-BFGS-B estimate:"</span>,</span>
<span>    <span class="fu"><a href="https://rdrr.io/r/base/Round.html" class="external-link">round</a></span><span class="op">(</span><span class="va">result_composed</span><span class="op">$</span><span class="va">theta.hat</span>, <span class="fl">4</span><span class="op">)</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Grid -&gt; L-BFGS-B estimate: 4.9829 1.8816</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/cat.html" class="external-link">cat</a></span><span class="op">(</span><span class="st">"Converged:"</span>, <span class="va">result_composed</span><span class="op">$</span><span class="va">converged</span>, <span class="st">"\n"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Converged: TRUE</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="when-to-use-what">When to Use What<a class="anchor" aria-label="anchor" href="#when-to-use-what"></a>
</h2>
<table class="table">
<colgroup>
<col width="34%">
<col width="40%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th>Situation</th>
<th>Recommended</th>
<th>Reason</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Quick prototyping</td>
<td>
<code>numDeriv</code> (default)</td>
<td>Zero effort, just write the log-likelihood</td>
</tr>
<tr class="even">
<td>Production / accuracy-critical</td>
<td><code>dualr</code></td>
<td>Exact derivatives, minimal code overhead</td>
</tr>
<tr class="odd">
<td>Maximum performance on simple models</td>
<td>Hand-coded</td>
<td>Avoids AD overhead for trivial derivatives</td>
</tr>
<tr class="even">
<td>Complex models (mixtures, hierarchical)</td>
<td><code>dualr</code></td>
<td>Hand-coding is error-prone and tedious</td>
</tr>
<tr class="odd">
<td>Derivative-free problems</td>
<td><code><a href="../reference/nelder_mead.html">nelder_mead()</a></code></td>
<td>When the log-likelihood isn’t differentiable</td>
</tr>
</tbody>
</table>
<p>The general recommendation is to <strong>start with the
default</strong> (no explicit derivatives) during model development,
then <strong>switch to <code>dualr</code></strong> when you need
accuracy or performance for production use. Hand-coding is only
worthwhile for very simple models where the derivatives are obvious.</p>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Alexander Towell.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
